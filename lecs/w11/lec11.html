<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>lec11 – CSC477 - Fall 2024</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-3610b36fc08898c07d6e0ffcd4000319.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-69b08db278f499bc7d235ce342f73d67.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-3610b36fc08898c07d6e0ffcd4000319.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta property="og:title" content="CSC477 - Fall 2024">
<meta property="og:description" content="Homepage for CSC477/CSC2630: Introduction to Mobile Robotics, Fall 2024">
<meta property="og:site_name" content="CSC477 - Fall 2024">
<meta name="twitter:title" content="CSC477 - Fall 2024">
<meta name="twitter:description" content="Homepage for CSC477/CSC2630: Introduction to Mobile Robotics, Fall 2024">
<meta name="twitter:card" content="summary">
</head>

<body class="quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>





<p>CSC477 Introduction to Mobile Robotics</p>
<p>Florian Shkurti</p>
<p>Weeks #11 &amp; #12: Multiview Geometry, Visual Odometry, Visual SLAM</p>
<p>Depth perception can be ambiguous from just a single image</p>
<p>What do humans see?</p>
<p>Visual saccades</p>
<p>To avoid thinking about image inversion</p>
<p>Point aperture → nearly every pixel in the image is in focus</p>
<p>To avoid thinking about image inversion</p>
<p>Some times called the thin-lens model</p>
<p>Focal plane</p>
<p>Point aperture → nearly every pixel in the image is in focus → almost infinite depth of field</p>
<p>Aperture of nonzero diameter → only pixels corresponding to objects on the focal plane are in focus → narrow depth of field</p>
<p>Chromatic aberration Failure of a lens to focus all colors to the same convergence point. Due to difference wavelengths having different refractive indeces</p>
<p>How do we project 3D points to pixels? What is the measurement model?</p>
<p>From 3D points to pixels: pinhole camera</p>
<ol type="1">
<li><p>Perspective projection</p></li>
<li><p>Conversion from metric to pixel coordinates</p></li>
</ol>
<p>z=f</p>
<p>represent number of pixels per mm for the two axes</p>
<p>Perspective projection [x,y] = 𝜋(X,Y,Z)</p>
<p>By similar triangles: x/f = X/Z</p>
<p>So, x = f * X/Z and similarly y = f * Y/Z</p>
<p>Problem: we just lost depth (Z) information by doing this projection, i.e. depth is now uncertain.</p>
<p>http://www.cim.mcgill.ca/%7Elanger/558.html</p>
<p>From 3D points to pixels: pinhole camera</p>
<ol type="1">
<li><p>Perspective projection</p></li>
<li><p>Conversion from metric to pixel coordinates</p></li>
</ol>
<p>z=f</p>
<p>From 3D points to pixels: pinhole camera</p>
<ol type="1">
<li><p>Perspective projection</p></li>
<li><p>Conversion from metric to pixel coordinates</p></li>
</ol>
<p>z=f</p>
<p>Usually presented as</p>
<p>Unknown depth/scale</p>
<p>Camera calibration matrix</p>
<p>From 3D points to pixels: thin lens camera</p>
<ol type="1">
<li><p>Perspective projection</p></li>
<li><p>Lens distortion</p></li>
<li><p>Conversion from metric to pixel coordinates</p></li>
</ol>
<p>(2) Lens distortion [x<em>, y</em>] = D(x,y)</p>
<p>(2) Estimating parameters of lens distortion: [x<em>, y</em>] = D(x,y)</p>
<p>From 3D points to pixels: thin lens camera</p>
<ol type="1">
<li><p>Perspective projection</p></li>
<li><p>Lens distortion</p></li>
<li><p>Conversion from metric to pixel coordinates</p></li>
</ol>
<p>If we have access to camera calibration parameters we can undo the lens distortion, and treat the measurement model as in the pinhole camera → single-camera image rectification</p>
<p>Shape from shading</p>
<p>“Numerical schemes for advanced reflectance models for Shape from Shading”, Vogel, Cristiani</p>
<p>Structure from Motion</p>
<p>“SFMedu: A Structure from Motion System for Education”, Jianxiong Xiao</p>
<p>Many depth from X methods. We are going to focus on structure from motion and stereo → part of multiple-view geometry</p>
<p>• Visual SLAM</p>
<p>• Localization and mapping with measurements usually coming from tracking image features:</p>
<p>• keypoints/corners • edges •</p>
<p>image intensity patches • Can use one or more cameras</p>
<p>• Visual Odometry</p>
<p>• Real-time localization with measurements usually coming from tracking image features:</p>
<p>• keypoints/corners • edges •</p>
<p>image intensity patches • Can use one or more cameras</p>
<p>A.k.a. mapping</p>
<p>3D point coordinates are unknown and to be estimated</p>
<p>Camera frame transformations are known</p>
<p>3D point coordinates are unknown, but we won’t try to estimate them</p>
<p>Camera frame transformations are unknown and to be estimated</p>
<p>3D point coordinates are unknown, but we won’t try to estimate them</p>
<p>Camera frame transformations are unknown, but we won’t try to estimate them</p>
<p>We are estimating pixel displacement from one image to the next</p>
<p>Basic underlying component in many of these problems: keypoint detection and matching across images</p>
<p>Ideally, we want the descriptor to be invariant (i.e.&nbsp;little to no change) when there are</p>
<ul>
<li><p>viewpoint changes (small rotation or translation of the camera)</p></li>
<li><p>scale-changes</p></li>
<li><p>illumination changes</p></li>
</ul>
<p>Corner detectors</p>
<p>• Harris • FAST • Laplacian of Gaussian detector • SUSAN • Forstner</p>
<p>Scale-space representation</p>
<p>Feature detection:</p>
<p>search for “corners”/keypoints across many scales, and return a list of (x, y, scale) keypoints</p>
<p>Many other local descriptors</p>
<p>• ORB • BRIEF • FREAK • RootSIFT-PCA</p>
<p>Feature matching</p>
<p>Problem #1: landmark triangulation</p>
<p>A.k.a. mapping</p>
<p>3D point coordinates are unknown and to be estimated</p>
<p>Camera frame transformations are known</p>
<p>In metric, not in pixel coordinates. To convert to pixel coordinates need to use elements of the camera calibration matrix.</p>
<p>Conclusion: if you have a well-calibrated and rectified (parallel) stereo camera you do not need to do least squares triangulation.</p>
<p>You can estimate depth via the disparity map.</p>
<p>3 x 7 = 21 variables to be estimated</p>
<p>7 pixel observations in each camera, so 21 pixel observations across all cameras</p>
<p>→ 42 constraints in total</p>
<p>Triangulation as a least squares problem</p>
<p>Actual pixel observation of a keypoint by camera frame</p>
<p>Expected pixel observation of 3D point by camera frame</p>
<p>Triangulation as a least squares problem</p>
<p>Enumerate all cameras that observed the keypoint.</p>
<p>The only term to be optimized. The rest are known.</p>
<p>Triangulation as a least squares problem</p>
<p>3D point expressed in the frame of camera k</p>
<p>Triangulation as a least squares problem</p>
<p>Reprojection error of point</p>
<p>into camera k’s frame</p>
<p>Triangulation as a least squares problem</p>
<p>Triangulation as a least squares problem</p>
<p>Triangulation as a least squares problem</p>
<p>Note: unconstrained optimization does not guarantee that the solution will be in the camera’s field of view. For example, it could happen that it returns which is an invalid solution (i.e.&nbsp;behind the camera)</p>
<p>Potential pitfalls with triangulation: near parallel rays</p>
<p>“point at infinity”</p>
<p>Intersection point is too far away, dominated by noise and insufficient image resolution. Triangulating these points is typically impossible without sufficient baseline between camera frames.</p>
<p>Problem #2: camera localization/visual odometry</p>
<p>3D point coordinates are unknown, but we won’t try to estimate them</p>
<p>Camera frame transformations are unknown and to be estimated</p>
<p>Camera localization as a least squares problem?</p>
<p>The only terms to be optimized.</p>
<p>But, 3D position is unknown!</p>
<p>So, we cannot solve the problem using the reprojection error unless we know the 3D position corresponding to the keypoint.</p>
<p>Let’s restrict the discussion to two cameras only</p>
<p>“5-point algorithm” by David Nister computes essential matrix and then decomposes it into rotation and translation.</p>
<p>After estimating the essential matrix, we extract t, R.</p>
<p>However, the translation t, is only estimated up to a multiplicative scale.</p>
<p>→ Translation is not fully observable with a single camera.</p>
<p>→ To make it observable we need stereo</p>
<p>Visual odometry with a single camera: translation is recovered only up to a scale</p>
<p>• Scale = multiplier between real-world metric distance units and</p>
<p>estimated map distance units</p>
<p>Camera placements (1) and (2) generate the same observation of P. In fact, infinitely many possible placements of the two camera frames along their projection rays could have generated the same measurement.</p>
<ol type="1">
<li></li>
<li></li>
</ol>
<p>Visual odometry with a single camera: translation is recovered only up to a scale</p>
<p>• Scale = multiplier between real-world metric distance units and</p>
<p>estimated map distance units</p>
<p>Q: Is there a way to obtain true metric distances only with a single camera?</p>
<p>A: The only way is to have an object of known metric dimensions in the observed scene. For example if you know distances AB, BC, CA then you can recover true translation. This is commonly referred to as the Perspective-3-Point (P3P), or in General, the Perspective-n-Point (PnP) problem.</p>
<p>Visual odometry with a single camera: translation is recovered only up to a scale</p>
<p>• Scale = multiplier between real-world metric distance units and</p>
<p>estimated map distance units</p>
<p>Q: Does scale remain constant throughout the trajectory of a single camera?</p>
<p>A: No, there is scale drift, which is most apparent during in-place rotations (i.e.&nbsp;pure rotation, no translation), because depth estimation for 3D points is unconstrained, so it is easily misestimated.</p>
<p>Point in 3D</p>
<p>Camera at t = 0</p>
<p>Are points-at-infinity useful for localization?</p>
<p>Points-at-infinity can help estimate the camera’s rotation, similarly to how we use stars for navigation, without estimating how far they are.</p>
<p>For estimating translation, most likely no. For estimating rotation, yes. Look up “Inverse Depth Parameterization for Monocular SLAM” for more info.</p>
<p>Problem #3: Visual SLAM</p>
<p>Structure from Motion</p>
<p>How can we estimate both 3D point positions and the relative camera transformations?</p>
<p>Sometimes also called bundle adjustment</p>
<p>Q: Why is it different than SLAM?</p>
<p>Structure from Motion</p>
<p>How can we estimate both 3D point positions and the relative camera transformations?</p>
<p>Sometimes also called bundle adjustment</p>
<p>Q: Why is it different than SLAM?</p>
<p>A: SLAM potentially includes</p>
<ul>
<li></li>
<li></li>
<li></li>
</ul>
<p>loop closure dynamics constraints velocities, accelerations</p>
<p>Loop Closure in Visual SLAM</p>
<p>ORB-SLAM, Mur-Artal, Tardos, Montiel, Galvez-Lopez</p>
<p>Bundler (bundle adjustment/structure from motion)</p>
<p>Structure from Motion as Least Squares</p>
<p>Indicates the frame of the k-th camera.</p>
<p>Structure from Motion as Least Squares</p>
<p>Expected pixel projection of 3D point onto camera k</p>
<p>Actual pixel measurement of 3D point from camera k</p>
<p>Structure from Motion as Least Squares</p>
<p>Q: Is the scale of these two estimates accurate/unambiguous when measurements are done from a monocular (single) camera in motion? I.e. is it observable?</p>
<p>Note: scale = relationship between real-world metric distances and estimated map distances. I.e. relationship between distance units.</p>
<p>Structure from Motion as Least Squares</p>
<p>Q: Is the scale of these two estimates accurate/unambiguous when measurements are done from a monocular (single) camera in motion? I.e. is it observable?</p>
<p>A: No, regardless of how many common keypoints are matched in between camera frames. Without external reference distance, e.g.&nbsp;stereo baseline, or real size of observed object, the scale is ambiguous and unobservable, just as it was in Visual Odometry.</p>
<p>Structure from Motion as Least Squares</p>
<p>Q: Is the scale of these two estimates constant during the entire experiment, if we use a monocular camera?</p>
<p>Structure from Motion as Least Squares</p>
<p>Q: Is the scale of these two estimates constant during the entire experiment, if we use a monocular camera?</p>
<p>A: No.&nbsp;During in-place rotations there is not enough baseline between camera frames to triangulate new points. So, error in structure and in motion accumulates → scale drift</p>
<p>Similarly to visual odometry with a single camera.</p>
<p>Problem #4: optical flow</p>
<p>3D point coordinates are unknown, but we won’t try to estimate them</p>
<p>Camera frame transformations are unknown, but we won’t try to estimate them</p>
<p>We are estimating pixel displacement from one image to the next</p>
<p>http://tcr.amegroups.com/article/viewFile/3200</p>
<p>Motion Applications: Segmentation of video</p>
<p>• Background subtraction</p>
<p>• A static camera is observing a scene • Goal: separate the static background from the moving foreground</p>
<p>Motion Applications: Segmentation of video</p>
<p>• Shot boundary detection in edited video</p>
<p>• Edited video is usually composed of shots or sequences showing the same objects or scene</p>
<p>• Goal: segment video into shots for summarization and browsing (each shot can be</p>
<p>represented by a single keyframe in a user interface)</p>
<p>• Difference from background subtraction: the camera is not necessarily stationary</p>
<p>Motion Applications: Segmentation of video</p>
<p>• Background subtraction • Shot boundary detection • Motion segmentation</p>
<p>• Segment the video into multiple coherently moving objects</p>
<p>Motion and perceptual organization</p>
<p>• Sometimes, motion is the only cue</p>
<p>Motion and perceptual organization</p>
<p>• Sometimes, motion is the only cue</p>
<p>Motion and perceptual organization</p>
<p>Experimental study of apparent behavior. Fritz Heider &amp; Marianne Simmel. 1944</p>
<p>From Taylor expansion of I</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/csc477\.github\.io\/website_fall24");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, Florian Shkurti</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions"><ul><li><a href="https://github.com/csc477/website_fall24/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with ❤️, <a href="https://quarto.org/">Quarto</a> and inspiration from <a href="https://sta210-s22.github.io/website/">STA210</a>.</p>
</div>
  </div>
</footer>




</body></html>