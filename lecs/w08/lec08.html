<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.31">

  <meta name="author" content="Florian Shkurti">
  <title>CSC477 - Fall 2024 – CSC477 Introduction to Mobile Robotics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link rel="stylesheet" href="../style.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="CSC477 Introduction to Mobile Robotics – CSC477 - Fall 2024">
<meta property="og:description" content="Week #8: Bayes’ Filters and Kalman Filter">
<meta property="og:site_name" content="CSC477 - Fall 2024">
<meta name="twitter:title" content="CSC477 Introduction to Mobile Robotics – CSC477 - Fall 2024">
<meta name="twitter:description" content="Week #8: Bayes’ Filters and Kalman Filter">
<meta name="twitter:card" content="summary">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">CSC477 Introduction to Mobile Robotics</h1>
  <p class="subtitle">Week #8: Bayes’ Filters and Kalman Filter</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Florian Shkurti 
</div>
</div>
</div>

</section>
<section id="recommended-reading" class="slide level2">
<h2>Recommended reading</h2>
<ul>
<li><p>Chapters 2 and 3.2 from Probabilistic Robotics</p></li>
<li><p>Chapters 4.9 and 8.3 from Computational Principles of Mobile Robotics</p></li>
<li><p>Lesson 2 in <a href="https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373" class="uri">https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373</a></p></li>
<li><p>This illustrative blog post: <a href="http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" class="uri">http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</a></p>
<p>Careful: the figure between equations (9) and (10) is wrong. The blue Gaussian should be taller and peakier than the other two Gaussians, the prior and the measurement models. This is not fixed as of March 15, 2017.</p></li>
</ul>
</section>
<section id="filtering-vs.-smoothing" class="slide level2">
<h2>Filtering vs.&nbsp;Smoothing</h2>
<ul>
<li>Smoothing/Batch Estimation</li>
</ul>
<p><span class="math display">\[p(\mathbf{x}_{0:T} \mid \mathbf{z}_{0:T}, \mathbf{u}_{0:T-1})\]</span></p>
<p><img data-src="img/filtering-smoothing.png" class="absolute" style="left: 300px; bottom: 43%; width: 500px; "></p>
<p><br><br></p>
<ul>
<li>Filtering Estimation</li>
</ul>
<p><span class="math display">\[p(\mathbf{x}_t \mid \mathbf{z}_{0:t}, \mathbf{u}_{0:t-1})\]</span></p>
</section>
<section id="whats-the-difference" class="slide level2">
<h2>What’s the difference?</h2>
<ul>
<li>Smoothing/Batch Estimation</li>
</ul>
<p><span class="math display">\[p(\mathbf{x}_{0:T} \mid \mathbf{z}_{0:T}, \mathbf{u}_{0:T-1})\]</span></p>
<p><span class="red-annotation absolute" style="top: 150px; right: 50px; ">All measurements and<br>
controls are known<br>
in advance</span></p>
<p><br></p>
<ul>
<li>Filtering Estimation</li>
</ul>
<p><span class="math display">\[p(\mathbf{x}_t \mid \mathbf{z}_{0:t}, \mathbf{u}_{0:t-1})\]</span></p>
<p><span class="red-annotation absolute" style="bottom: 200px; right: 50px; ">Measurements and controls<br>
are processed online as they come.<br>
Future measurements are unknown.</span></p>
</section>
<section id="why-do-we-use-filtering" class="slide level2">
<h2>Why do we use filtering?</h2>
<ul>
<li>Online belief updates: filters provide a principled way to incorporate noisy information from sensor measurements, which can change our prior belief, in an online fashion.</li>
</ul>
<p><br></p>
<ul>
<li>Sensor fusion: filters enable us to combine measurements from multiple different noisy sensors into one coherent state estimate. E.g. camera + laser, camera + IMU, multiple cameras, sonar and IMU, GPS and IMU etc.</li>
</ul>
<p><span class="red-annotation absolute" style="bottom: 300px; right: 0px; ">Technically speaking, this is also<br>
true for smoothing estimators.</span></p>
</section>
<section id="bayes-filter" class="slide level2">
<h2>Bayes’ Filter</h2>
<ul>
<li>A generic class of filters that make use of Bayes’ rule and assume the following:
<ul>
<li><p><strong>Markov Assumption For Dynamics</strong> : the state <span class="math inline">\(x_t\)</span> is conditionally independent of past states and controls, given the previous state <span class="math inline">\(x_{t-1}\)</span> In other words, the dynamics model is assumed to satisfy <span class="math display">\[p(x_{t}|x_{0:t-1}, u_{0:t-1}) = p(x_{t}|x_{t-1}, u_{t-1})\]</span></p></li>
<li><p><strong>Static World Assumption</strong>: the current observation is conditionally independent of past observations and controls, given the current state</p>
<p><span class="math display">\[p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) = p(z_t|x_t)\]</span></p></li>
</ul></li>
</ul>
<div class="fragment">
<p><span class="red-annotation">Note: the Markov assumption is<br>
more general than what we have<br>
presented here.</span></p>
</div>
</section>
<section id="bayes-filter-derivation" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns medium-font">
<div class="column" style="width:60%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\ &amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1})
\end{align*}\]</span></p>
<p><br></p>
<p><img data-src="img/uparrow.png" class="absolute" style="top: 150px; left: 143px; height: 80px; "></p>
<p><span class="red-annotation">Normalizing factor that makes the integral/sum of the numerator in Bayes’ Rule be 1.</span></p>
</div><div class="column medium-font" style="width:40%;">
<p><span class="red">Conditional Bayes’ Rule</span></p>
<p><br><br><br><br></p>
<p><span class="math inline">\(p(A|B,C) = \frac{p(C|A,B)p(A|B)}{p(C|B)}\)</span></p>
<p><img data-src="img/bayes-filter.png" class="absolute" style="bottom: 300px; width: 230px; "></p>
</div></div>
</section>
<section id="bayes-filter-derivation-1" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1})
\end{align*}\]</span></p>
</div><div class="column" style="width:35%;">
<p><br><br></p>
<p><span class="red-annotation">Static World Assumption</span></p>
</div></div>
</section>
<section id="bayes-filter-derivation-2" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1}
\end{align*}\]</span></p>
</div><div class="column red semi-tiny-font" style="width:35%;">
<p><br></p>
<p><br><br></p>
<p><br><br></p>
<p>Marginalization, or law of total probability</p>
<p><span class="math inline">\(\color{black}p(A) = \sum_{B_{i}}p(A,B_{i})\)</span></p>
<p>where the sum enumerates all possibilities over the variable Bi. If we see Bi as a set, then the collection of Bi’s must be pairwise disjoint. I.e. the collection of subsets Bi must be a partition of the sample space.</p>
<p><img data-src="img/Lecture8_22.jpg"></p>
</div></div>
</section>
<section id="bayes-filter-derivation-3" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1}
\end{align*}\]</span></p>
</div><div class="column red semi-tiny-font" style="width:35%;">
<p><br></p>
<p><br><br></p>
<p><br><br></p>
<p>Marginalization, or law of total probability</p>
<p><span class="math inline">\(\color{black}p(A) = \sum_{B_{i}}p(A,B_{i})\)</span></p>
<p>Here we are actually using the law of total probability for conditional distributions, so</p>
<p><span class="math inline">\(\color{black}p(A|C) = \sum_{B_{i}}p(A,B_{i}|C)\)</span></p>
</div></div>
</section>
<section id="bayes-filter-derivation-4" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t, x_t|u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1}
\end{align}\]</span></p>
</div><div class="column red semi-tiny-font right-align" style="width:35%;">
<p><br><br><br><br><br></p>
<p><br><br></p>
<p>Definition of conditional distribution</p>
<p><span class="math inline">\(\color{black}p(A, B|C) = p(A|B, C)p(B|C)\)</span></p>
</div></div>
</section>
<section id="bayes-filter-derivation-5" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\ &amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\ &amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\ &amp;= \eta p(z_t|x_t) \int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\ &amp;= \eta p(z_t|x_t) \int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\ &amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \end{align*}\]</span></p>
</div><div class="column red semi-tiny-font" style="width:35%;">
<p><span class="absolute" style="bottom: 320px; right: 50px; ">Markov assumption for dynamics</span></p>
</div></div>
</section>
<section id="bayes-filter-derivation-6" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-2}) dx_{t-1}
\end{align*}\]</span></p>
<p><img data-src="img/bayes-filter-annotation.png" class="absolute" style="left: 220px; bottom: 45px; height: 200px; "></p>
</div><div class="column" style="width:35%;">
<p><img data-src="img/bayes-filter-deriv.png" class="absolute" style="bottom: 60px; width: 250px; "></p>
<p><span class="red semi-tiny-font absolute" style="bottom: 30px; right: 50px; ">Control at time t-1 only affects state at time t</span></p>
</div></div>
</section>
<section id="bayes-filter-derivation-7" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}
\end{align*}\]</span></p>
</section>
<section id="bayes-filter-derivation-8" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<p><span class="math display">\[\begin{align}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta \, p(z_t|x_t) \underbrace{\int p(x_t|u_{t-1}, x_{t-1}) \, bel(x_{t-1}) \, dx_{t-1}}_{\begin{subarray}{c} \text{Computes the probability density of reaching state} \\ \text{$x_t$ from any possible previous state $x_{t-1}$} \\ \text{via the command $u_{t-1}$} \end{subarray}}
\end{align}\]</span></p>
<!-- $$\begin{align*}
bel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\
&= \eta p(z_t|x_t) \quad \int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1} \\
\underbrace{\phantom{\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}}}_{\text{Computes the probability density of reaching state } x_t \text{ from any possible previous state } x_{t-1} \text{ via the command } u_{t-1}}
\end{align*}
$$ -->
</section>
<section id="bayes-filter-derivation-9" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<p><span class="math display">\[\begin{align}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \underbrace{\eta \, p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) \, bel(x_{t-1}) \, dx_{t-1}}_{\begin{subarray}{c} \text{Computes the probability density of reaching state} \\ \text{$x_t$ from any possible previous state $x_{t-1}$} \\ \text{via the command $u_{t-1}$ and observing $z_t$} \end{subarray}}
\end{align}\]</span></p>
</section>
<section id="bayes-filter-derivation-10" class="slide level2">
<h2>Bayes’ Filter: Derivation</h2>
<p><span class="math display">\[\begin{align}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \underbrace{\eta \, p(z_t|x_t) \underbrace{\int p(x_t|u_{t-1}, x_{t-1}) \, bel(x_{t-1}) \, dx_{t-1}}_{\text{Belief after prediction step}}}_{\text{Belief after update step}}
\end{align}\]</span></p>
</section>
<section id="kalman-filter-an-instance-of-bayes-filter" class="slide level2">
<h2><span class="medium-font">Kalman Filter: an instance of Bayes’ Filter</span></h2>
<p><span class="math display">\[\begin{align}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta \, p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) \, bel(x_{t-1}) \, dx_{t-1}
\end{align}\]</span></p>
<p><img data-src="img/kalman-annot1.png" class="absolute" style="top: 190px; left: 240px; height: 250px; "></p>
<p><span class="semi-tiny-font absolute" style="left: 300px; bottom: 200px; "><span class="math inline">\(z_t = Hx_t + n_t\)</span><br>
<span class="math inline">\(\qquad\)</span> with noise <span class="math inline">\(n_t \sim \mathcal{N}(0, R)\)</span></span></p>
<p><img data-src="img/kalman-filter-annot2.png" class="absolute" style="top: 195px; right: 310px; height: 150px; "></p>
<p><span class="semi-tiny-font absolute" style="bottom: 300px; right: 320px; "><span class="math inline">\(x_{t} = Ax_{t-1}+Bu_{t-1}+Gw_{t-1}\)</span><br>
<span class="math inline">\(\qquad\)</span> with noise <span class="math inline">\(w_{t-1} \sim \mathcal{N}(0, Q)\)</span></span></p>
<p><img data-src="img/kalman-annot3.png" class="absolute" style="bottom: 150px; right: 150px; width: 200px; "></p>
<p><span class="semi-tiny-font absolute" style="bottom: 130px; right: 140px; "><span class="math inline">\(bel(x_0) \sim \mathcal{N}(\mu_0, \Sigma_0)\)</span></span></p>
</section>
<section id="kalman-filter-assumptions" class="slide level2">
<h2>Kalman Filter: assumptions</h2>
<ul>
<li><p>Two assumptions inherited from Bayes’ Filter</p></li>
<li><p>Linear dynamics and observation models</p></li>
<li><p>Initial belief is Gaussian</p></li>
<li><p>Noise variables and initial state <span class="math display">\[x_0, w_0, w_1, \ldots, \eta_0, \eta_1, \ldots\]</span> are jointly Gaussian and independent</p></li>
<li><p>Noise variables <span class="math inline">\(w_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, Q)\)</span></p></li>
<li><p>Noise variables <span class="math inline">\(n_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, R)\)</span></p></li>
</ul>
</section>
<section id="kalman-filter-why-so-many-assumptions" class="slide level2">
<h2><span class="medium-font">Kalman Filter: why so many assumptions?</span></h2>
<ul>
<li><p>Two assumptions inherited from Bayes’ Filter</p></li>
<li><p>Linear dynamics and observation models</p></li>
<li><p>Initial belief is Gaussian</p></li>
<li><p>Noise variables and initial state <span class="math display">\[x_0, w_0, w_1, \ldots, \eta_0, \eta_1, \ldots\]</span> are jointly Gaussian and independent</p></li>
<li><p>Noise variables <span class="math inline">\(w_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, Q)\)</span></p></li>
<li><p>Noise variables <span class="math inline">\(n_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, R)\)</span></p></li>
</ul>
<p><img data-src="img/red-box.png" class="absolute" style="top: 125px; width: 650px; height: 100px; "></p>
<div class="red-annotation absolute" style="top: 100px; right: 0px; ">
<p>Without linearity there is no closed<br>
form solution for the posterior<br>
belief in the Bayes’ Filter. Recall that<br>
if X is Gaussian then Y=AX+b is also<br>
Gaussian. This is not true in general<br>
if Y=h(X).</p>
<p>Also, we will see later that applying<br>
Bayes’ rule to a Gaussian prior and a<br>
Gaussian measurement likelihood<br>
results in a Gaussian posterior.</p>
</div>
</section>
<section id="kalman-filter-why-so-many-assumptions-1" class="slide level2">
<h2><span class="medium-font">Kalman Filter: why so many assumptions?</span></h2>
<ul>
<li><p>Two assumptions inherited from Bayes’ Filter</p></li>
<li><p>Linear dynamics and observation models</p></li>
<li><p>Initial belief is Gaussian</p></li>
<li><p>Noise variables and initial state <span class="math display">\[x_0, w_0, w_1, \ldots, \eta_0, \eta_1, \ldots\]</span> are jointly Gaussian and independent</p></li>
<li><p>Noise variables <span class="math inline">\(w_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, Q)\)</span></p></li>
<li><p>Noise variables <span class="math inline">\(n_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, R)\)</span></p></li>
</ul>
<p><img data-src="img/red-box2.png" class="absolute" style="top: 130px; width: 650px; height: 260px; "></p>
<div class="red-annotation absolute" style="top: 150px; right: 0px; ">
<p>This results in the belief remaining Gaussian<br>
after each propagation and update step.<br>
This means that we only have to worry<br>
about how the mean and the covariance<br>
of the belief evolve recursively with<br>
each prediction step and update step<br>
-&gt; COOL!</p>
</div>
</section>
<section id="kalman-filter-why-so-many-assumptions-2" class="slide level2">
<h2><span class="medium-font">Kalman Filter: why so many assumptions?</span></h2>
<ul>
<li><p>Two assumptions inherited from Bayes’ Filter</p></li>
<li><p>Linear dynamics and observation models</p></li>
<li><p>Initial belief is Gaussian</p></li>
<li><p>Noise variables and initial state <span class="math display">\[x_0, w_0, w_1, \ldots, \eta_0, \eta_1, \ldots\]</span> are jointly Gaussian and independent</p></li>
<li><p>Noise variables <span class="math inline">\(w_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, Q)\)</span></p></li>
<li><p>Noise variables <span class="math inline">\(n_t\)</span> are independent and identically distributed <span class="math inline">\(\mathcal{N}(0, R)\)</span></p></li>
</ul>
<p><img data-src="img/red-box3.png" class="absolute" style="bottom: 185px; "></p>
<div class="red-annotation" data-right="30%" data-bottom="150">
<p>This makes the recursive updates of the mean and covariance much simpler.</p>
</div>
</section>
<section id="kalman-filter-an-instance-of-bayes-filter-1" class="slide level2">
<h2><span class="medium-font">Kalman Filter: an instance of Bayes’ Filter</span></h2>
<p><span class="math display">\[\begin{align*}
\text{bel}(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) \text{bel}(x_{t-1}) dx_{t-1}
\end{align*}\]</span></p>
<p><img data-src="img/kalman-filter2-annot1.png" class="absolute" style="top: 140px; left: 160px; height: 350px; "></p>
<p><img data-src="img/kalman-filter2-annot2.png" class="absolute" style="top: 200px; right: 55px; height: 200px; "></p>
<p><img data-src="img/kalman-filter2-annot3.png" class="absolute" style="top: 163px; right: 128px; height: 160px; "></p>
</section>
<section id="kalman-filter-an-instance-of-bayes-filter-2" class="slide level2">
<h2><span class="medium-font">Kalman Filter: an instance of Bayes’ Filter</span></h2>
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= p(x_t|u_{0:t-1}, z_{0:t}) \\
&amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \overline{bel}(x_t)
\end{align*}\]</span></p>
<div class="absolute" style="top: 270px; left: 50%; ">
<p><img data-src="img/red-left-arrow.png" width="70"> <span class="red semi-tiny-font">Belief after prediction step (to simplify notation)</span></p>
</div>
<p><span class="red-annotation">So, under the Kalman Filter assumptions we get</span></p>
<p><span class="math inline">\(bel(x_{t-1}) \sim \mathcal{N}(\mu_{t-1|t-1}, \Sigma_{t-1|t-1})\)</span></p>
<p><span class="math inline">\(\overline{bel}(x_t) \sim \mathcal{N}(\mu_{t|t-1}, \Sigma_{t|t-1})\)</span></p>
<p><span class="math inline">\(bel(x_t) \sim \mathcal{N}(\mu_{t|t}, \Sigma_{t|t})\)</span></p>
<div class="absolute right-align" style="bottom: 70px; right: 150px; ">
<p><span class="red semi-tiny-font"><img data-src="img/red-left-arrow.png" width="175"> Notation: estimate at time t given history of observations and<br>
controls up to time t-1</span></p>
</div>
</section>
<section id="kalman-filter-an-instance-of-bayes-filter-3" class="slide level2">
<h2><span class="medium-font">Kalman Filter: an instance of Bayes’ Filter</span></h2>
<p><span class="math display">\[\begin{align*}
bel(x_t) &amp;= \eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\
&amp;= \eta p(z_t|x_t) \int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1} \\
&amp;= \eta p(z_t|x_t) \overline{bel}(x_t)
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p><span class="red-annotation">So, under the Kalman Filter assumptions we get</span></p>
<p><span class="math inline">\(bel(x_{t-1}) \sim \mathcal{N}(\mu_{t-1|t-1}, \Sigma_{t-1|t-1})\)</span></p>
<p><span class="math inline">\(\qquad\qquad \color{red}\downarrow\)</span></p>
<p><span class="math inline">\(\overline{bel}(x_t) \sim \mathcal{N}(\mu_{t|t-1}, \Sigma_{t|t-1})\)</span></p>
<p><span class="math inline">\(\qquad\qquad \color{red}\downarrow\)</span></p>
<p><span class="math inline">\(bel(x_{t}) \sim \mathcal{N}(\mu_{t|t}, \Sigma_{t|t})\)</span></p>
</div><div class="column red-annotation">
<p>Two main questions:</p>
<p><br></p>
<ol type="1">
<li>How to get prediction mean and covariance from prior mean and covariance?</li>
</ol>
<p><br></p>
<ol start="2" type="1">
<li>How to get posterior mean and covariance from prediction mean and covariance?</li>
</ol>
<p>These questions were answered in the 1960s. The resulting algorithm was used in the Apollo missions to the moon, and in almost every system in which there is a noisy sensor involved  COOL!</p>
</div></div>
</section>
<section id="kalman-filter-with-1d-state" class="slide level2">
<h2>Kalman Filter with 1D state</h2>
<ul>
<li>Let’s start with the update step recursion. Here’s an example:</li>
</ul>
<div class="columns">
<div class="column">
<p><img data-src="img/kalman-1dstate.png"></p>
</div><div class="column medium-font">
<p>Suppose your measurement model is <span class="math inline">\(z_t = x_t + n_t\)</span> with <span class="math inline">\(n_t \sim \mathcal{N}(0, 1^2)\)</span></p>
<p>Suppose your belief after the prediction step is <span class="math inline">\(\overline{bel}(x_{t})=\mathcal{N}(0,2^{2})\)</span></p>
<p>Suppose your first noisy measurement is <span class="math inline">\(z_0 = 5\)</span></p>
<p>Q: What is the mean and covariance of <span class="math inline">\(bel(x_t)\)</span> ?</p>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1dstep-update.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})\)</span></p>
<p><span class="math inline">\(\sigma^{2}=\sigma_{B}^{2}-\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}\sigma_{B}^{2}\)</span></p>
</div></div>
<p><img data-src="img/red-box-w-arrow.png" class="absolute" style="bottom: 280px; right: 210px; width: 180px; "></p>
<div class="red semi-tiny-font right-align absolute" style="bottom: 90px; right: 0px; ">
<p>Prediction residual/error between<br>
actual observation and expected<br>
observation.</p>
<p>You expected the measured mean<br>
to be 0, according to your prediction<br>
prior, but you actually observed 5.</p>
<p>The smaller this prediction error is the better<br>
your estimate will be, or the better it will agree<br>
with the measurements.</p>
</div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-1" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1dstep-update.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})\)</span></p>
<p><span class="math inline">\(\sigma^{2}=\sigma_{B}^{2}-\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}\sigma_{B}^{2}\)</span></p>
</div><p><img data-src="img/kalman-filter-box-arrow.png" class="absolute" style="bottom: 190px; right: 253px; height: 140px; "></p><div class="column red semi-tiny-font right-align absolute" style="bottom: 190px; right: 50px; ">
<p>Kalman Gain: specifies<br>
how much effect will the<br>
measurement have in the<br>
posterior, compared to the<br>
prediction prior. Which one do you<br>
trust more, your prior <span class="math inline">\(\color{black}\overline{bel}(x_t)\)</span><br>
or your measurement <span class="math inline">\(\color{black}p(z_t | x_t)\)</span> ?</p>
</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-2" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1dstep-update.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})\)</span></p>
<p><span class="math inline">\(\sigma^{2}=\sigma_{B}^{2}-\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}\sigma_{B}^{2}\)</span></p>
</div><p><img data-src="img/kalman-filter-box-arrow2.png" class="absolute" style="bottom: 266px; right: 255px; width: 200px; "></p><div class="column red semi-tiny-font right-align absolute" style="bottom: 230px; right: 50px; ">
<p>The measurement is more confident<br>
(lower variance) than the prior, so<br>
the posterior mean is going to be<br>
closer to 5 than to 0.</p>
</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-3" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1dstep-update.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})\)</span></p>
<p><img data-src="img/1dstate-equation1.png"></p>
</div><!-- ![](img/small-box-arrow.png) --><div class="column">

</div></div>
</div></div>
<div class="red semi-tiny-font absolute" style="bottom: 170px; right: 0px; ">
<p>No matter what happens, the variance of the<br>
posterior is going to be reduced. I.e. new<br>
measurement increases confidence no matter<br>
how noisy it is.</p>
</div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-4" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1dstep-update.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})\)</span></p>
<p><img data-src="img/1dstate-eq2.png"></p>
</div><div class="column">

</div></div>
</div></div>
<div class="red semi-tiny-font absolute" style="bottom: 130px; right: 0px; ">
<p>In fact you can write this as<br>
<span class="math inline">\(\color{black}\frac{1}{\sigma^{2}}=\frac{1}{\sigma_{A}^{2}}+\frac{1}{\sigma_{B}^{2}}\)</span><br>
so <span class="math inline">\(\color{black}\sigma &lt; \sigma_A\)</span> and <span class="math inline">\(\color{black}\sigma &lt; \sigma_B\)</span><br>
I.e. the posterior is more confident than both<br>
the prior and the measurement.</p>
</div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-5" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/kalman-filter-1d-state-diagram.png"></p>
</div><div class="column medium-font" style="width:55%;">
<p>From Bayes’ Filter we get <span class="math inline">\(bel(x_t) = \eta p(z_t|x_t) \overline{bel}(x_t)\)</span> so</p>
<p><span class="math display">\[\begin{align*}
p(z_t|x_t) \overline{bel}(x_t) &amp;= \mathcal{N}(\mu_A, \sigma_A^2)\mathcal{N}(\mu_B, \sigma_B^2) \\
&amp;= \dots \\
&amp;= \text{see Appendix 1 for proof} \\
&amp;= \dots \\
&amp;= \mathcal{N}(\mu, \sigma^2)/\eta
\end{align*}\]</span></p>
<div class="columns">
<div class="column">
<p>In this example:</p>
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})= 4\)</span></p>
<p><span class="math inline">\(\sigma^{2}=\sigma_{B}^{2}-\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}\sigma_{B}^{2} = 4/5\)</span></p>
</div><div class="column">

</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-6" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<div class="columns">
<div class="column">
<p><img data-src="img/kalman-filter-1dstate-diagram2.png"></p>
</div><div class="column medium-font">
<p>Another example:</p>
<p><span class="math inline">\(\mu=\mu_{B}+\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}(\mu_{A}-\mu_{B})= 5\)</span></p>
<p><span class="math inline">\(\sigma^{2}=\sigma_{B}^{2}-\frac{\sigma_{B}^{2}}{\sigma_{A}^{2}+\sigma_{B}^{2}}\sigma_{B}^{2} = \sigma^2_B / 2 = 2\)</span></p>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-update-step-7" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the update step</span></h2>
<p>Take-home message: new observations, no matter how noisy, always <strong>reduce </strong> <strong>uncertainty</strong> in the posterior. The mean of the posterior, on the other hand, only changes when there is a nonzero prediction residual.</p>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:60%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><img data-src="img/3-arrows.png" class="absolute" style="top: 310px; right: 210px; width: 150px; height: 250px; "></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
<div class="red semi-tiny-font absolute" style="bottom: 50px; right: -20px; ">
<p>Recall: this notation means<br>
expected value with respect to<br>
conditional expectation, i.e<br>
</p>
<p><span class="math inline">\(\color{black}\int x_{t}p(x_{t}|z_{0:t-1},u_{0:t-1})dx_{t}\)</span></p>
<p><span class="math inline">\(\color{black}= \int x_{t} \overline{bel}(x_{t}) dx_{t}\)</span></p>
<p>Control is a constant with<br>
respect to the distribution</p>
<p><span class="math inline">\(\color{black}\overline{bel}(x_{t})\)</span></p>
<p>Dynamics noise is zero mean,<br>
and independent of observations<br>
and controls</p>
</div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-1" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
<p><img data-src="img/propagation-prediction-annot.png" class="absolute" style="bottom: 80px; right: 0px; width: 300px; "></p>
<p><span class="medium-font"><span class="math inline">\(\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] = \mathbb{E}[x_t^2|z_{0:t-1}, u_{0:t-1}] - (\mathbb{E}[x_t|z_{0:t-1}, u_{0:t-1}])^2\)</span></span></p>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-2" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
<div class="right-align absolute red semi-tiny-font" style="bottom: 56px; right: -40px; ">
<p><span class="math inline">\(\xleftarrow{\hspace{1cm}}\)</span> Recall: covariance neglects addition<br>
of constant terms, i.e.&nbsp;<br>
Cov(X+b) = Cov(X)</p>
</div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-3" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
<p><img data-src="img/propagation-predicton-annot2.png" class="absolute" style="bottom: 50px; right: -50px; width: 100%; "></p>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-4" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
<p><img data-src="img/propagation-prediction-annot3.png" class="absolute" style="bottom: 50px; right: -50px; width: 60%; "></p>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-5" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \text{Cov}[w_{t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-6" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \text{Cov}[w_{t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-2}] + \text{Cov}[w_{t-1}]
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-7" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="img/propagation-prediction.png"></p>
</div><div class="column small-font" style="width:55%;">
<p>Suppose that the dynamics model is</p>
<p><span class="math inline">\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \text{ with } w_{t-1} \sim \mathcal{N}(0, q^2)\)</span></p>
<p>and you applied the command <span class="math inline">\(u_{t-1} = 10\)</span> Then</p>
<div class="columns">
<div class="column medium-font" style="width:65%;">
<p><span class="math display">\[\begin{align*}
\mu &amp;= \mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\
&amp;= \mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\
&amp;= \mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\
&amp;= \mu_C + u_{t-1}
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp;= \text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \text{Cov}[w_{t-1}] \\
&amp;= \text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-2}] + \text{Cov}[w_{t-1}] \\
&amp;= \sigma_{C}^{2} + q^{2}
\end{align}\]</span></p>
</div><div class="column" style="width:35%;">

</div></div>
</div></div>
</section>
<section id="kalman-filter-with-1d-state-the-propagationprediction-step-8" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 1D state: the propagation/prediction step</span></h2>
<p>Take home message: uncertainty <strong>increases</strong> after the prediction step,</p>
<p>because we are speculating about the future.</p>
</section>
<section id="kalman-filter-with-2d-state" class="slide level2">
<h2>Kalman Filter with 2D state</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="img/kalman-2dstate-diagram.png"></p>
</div><div class="column medium-font" style="width:60%;">
<p>Suppose we have a robot that moves on a 1D line, but we also want to estimate its velocity. Then the 2D state vector is <span class="math inline">\(x_t = [p, v]^T\)</span></p>
<p>Suppose we do not have any control over this robot, i.e. we are just trying to estimate its state through <strong>observations of the position only</strong> . I.e.:</p>
<p><span class="math inline">\(z_t = Hx_t + n_t = [1, 0]x_t + n_t \quad \text{with} \quad n_t \sim \mathcal{N}(0, r^2)\)</span></p>
<p>Also suppose that we predict zero acceleration in the near future, so</p>
<p><span class="math inline">\(p_{t+1} = p_{t} + v_{t}\delta t + w_{p}(t)\)</span></p>
<p><span class="math inline">\(v_{t+1} = v_{t} + w_{v}(t)\)</span></p>
<p>which in vector form is expressed as</p>
<p><span class="math display">\[x_{t+1} = Ax_t + w_t \qquad
\begin{align}
A &amp;= \begin{bmatrix} 1 &amp; \delta t \\ 0 &amp; 1 \end{bmatrix} \\
w_t &amp;= \begin{bmatrix} w_p(t) \\ w_v(t) \end{bmatrix} \sim \mathcal{N}(0_{2 \times 1}, Q)
\end{align}\]</span></p>
</div></div>
</section>
<section id="kalman-filter-with-2d-state-1" class="slide level2">
<h2>Kalman Filter with 2D state</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="img/kalman-2dstate-diagram.png"></p>
</div><div class="column medium-font" style="width:60%;">
<p>Suppose we have a robot that moves on a 1D line, but we also want to estimate its velocity. Then the 2D state vector is <span class="math inline">\(x_t = [p, v]^T\)</span></p>
<p>Suppose we do not have any control over this robot, i.e. we are just trying to estimate its state through <strong>observations of the position only</strong> . I.e.:</p>
<p><span class="math inline">\(\qquad z_t = Hx_t + n_t = [1, 0]x_t + n_t \quad \text{with} \quad n_t \sim \mathcal{N}(0, r^2)\)</span></p>
<p>Also suppose that we predict zero acceleration in the near future, so</p>
<p><span class="math inline">\(p_{t+1} = p_{t} + v_{t}\delta t + w_{p}(t)\)</span></p>
<p><span class="math inline">\(v_{t+1} = v_{t} + w_{v}(t)\)</span></p>
<p>which in vector form is expressed as</p>
<p><span class="math display">\[x_{t+1} = Ax_t + w_t \qquad
\begin{align}
A &amp;= \begin{bmatrix} 1 &amp; \delta t \\ 0 &amp; 1 \end{bmatrix} \\
w_t &amp;= \begin{bmatrix} w_p(t) \\ w_v(t) \end{bmatrix} \sim \mathcal{N}(0_{2 \times 1}, Q)
\end{align}\]</span></p>
</div></div>
<p><img data-src="img/kalman-filter-2d-annot.png" class="absolute" style="bottom: 50px; right: 0px; height: 320px; "></p>
</section>
<section id="kalman-filter-with-2d-state-2" class="slide level2">
<h2>Kalman Filter with 2D state</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="img/kalman-2dstate-diagram.png"></p>
</div><div class="column medium-font" style="width:60%;">
<p>Suppose that at time t the state is distributed as <span class="math inline">\(p(x_{t}|z_{0:t})=\mathcal{N}(\mu_{t|t},\Sigma_{t|t})\)</span> with</p>
<p><span class="math display">\[\mu_{t|t} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \quad \Sigma_{t|t} = \begin{bmatrix} \sigma_p^2 &amp; \sigma_{pv} \\ \sigma_{pv} &amp; \sigma_v^2 \end{bmatrix} = \begin{bmatrix} 1^2 &amp; 0 \\ 0 &amp; 10^2 \end{bmatrix}\]</span></p>
<p>In other words, we are confident that in the beginning the position is with high probability (~0.997) within range <span class="math inline">\(3\sigma_{v}=3\)</span> of the mean position, 0.</p>
<p>We are not very confident in the velocity, however. We just know a priori that with high probability (~0.997) it is within range <span class="math inline">\(3\sigma_{v}=30\)</span> of the mean velocity 1.</p>
<p><span class="red-annotation fragment">Notice that when the cross-correlation terms <span class="math inline">\(\sigma_{pv} = 0\)</span> then the ellipse is axis-aligned. This means that the position and velocity are initially uncorrelated.</span></p>
</div></div>
</section>
<section id="kalman-filter-with-2d-state-the-propagationprediction-step" class="slide level2">
<h2>Kalman Filter with 2D state: the propagation/prediction step</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/2d-propagation-diagram.png"></p>
</div><div class="column medium-font" style="width:65%;">
<p>After the prediction step the state is distributed as <span class="math inline">\(p(x_{t+1}|z_{0:t})=\mathcal{N}(\mu_{t+1|t},\Sigma_{t+1|t})\)</span> with</p>
<div class="columns">
<div class="column medium-font">
<p><span class="math display">\[\begin{align}
\mu_{t+1|t} &amp;= \mathbb{E}[x_{t+1}|z_{0:t}] \\
&amp;= \mathbb{E}[Ax_t + w_t|z_{0:t}] \\
&amp;= A\mathbb{E}[x_t + w_t|z_{0:t}] \\
&amp;= A\mathbb{E}[x_t|z_{0:t}] \\
&amp;= A\mu_{t|t} \\
&amp;= \begin{bmatrix} 1 &amp; 1 \\ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align*}
\Sigma_{t+1|t} &amp;= \text{Cov}[x_{t+1}|z_{0:t}] \\
&amp;= \text{Cov}[Ax_t + w_t|z_{0:t}] \\
&amp;= \text{Cov}[Ax_t|z_{0:t}] + \text{Cov}[w_t|z_{0:t}] - 2\text{Cov}[Ax_t, w_t|z_{0:t}] \\
&amp;= A\text{Cov}[x_t|z_{0:t}]A^T + \text{Cov}[w_t] \\
&amp;= A\Sigma_{t|t}A^T + Q \\
&amp;= \begin{bmatrix} 1 &amp; 1 \\ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 1^2 &amp; 0 \\ 0 &amp; 10^2 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} + \begin{bmatrix} 1^2 &amp; 0 \\ 0 &amp; 1^2 \end{bmatrix} = \begin{bmatrix} 102 &amp; 100 \\ 100 &amp; 101 \end{bmatrix}
\end{align*}\]</span></p>
</div><div class="column" style="width:50%;">

</div></div>
</div></div>
<div class="red semi-tiny-font absolute fragment" style="bottom: 25px; right: -80px; ">
<p>Many things to notice here:</p>
<p><br></p>
<p>The covariance has nonzero<br>
off- diagonal terms, so the<br>
position and velocity are<br>
now correlated. This is why<br>
the orange ellipse<br>
is rotated.</p>
<p><br></p>
<p>Also, the orange ellipse is<br>
“larger” than the initial<br>
blue ellipse,which means<br>
that our uncertainty has<br>
increased by speculating<br>
for future outcomes.</p>
<p><br></p>
<p>There is now large uncertainty<br>
in the predicted position,<br>
since there was large<br>
uncertainty in the velocity.</p>
</div>
</section>
<section id="kalman-filter-with-2d-state-the-update-step" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 2D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/2d-update-diagram.png"></p>
</div><div class="column small-font" style="width:65%;">
<p>Before the update step the state is distributed as <span class="math inline">\(p(x_{t+1}|z_{0:t})=\mathcal{N}(\mu_{t+1|t},\Sigma_{t+1|t})\)</span> with $<span class="math inline">\(\mu_{t+1|t}=[1,1]^{T}\)</span> and <span class="math inline">\(\Sigma_{t+1|t} = \begin{bmatrix} 102 &amp; 100 \\ 100 &amp; 101 \end{bmatrix}\)</span></p>
<p>At this point we predict that the next measurement of the position is going to be <span class="math inline">\(\mu_{z_{t+1}}=H\mu_{t+1|t}=[1,0]\mu_{t+1|t}=1\)</span> with uncertainty <span class="math inline">\(s_{t+1}^2\)</span> which depends on previous uncertainty and measurement uncertainty.</p>
<p>Suppose that we actually measure <span class="math inline">\(\overline{z}_{t+1}=5\)</span> which means that our mean estimate of the velocity was way off (it was 1). Therefore, there is a prediction residual/error <span class="math inline">\(\delta z=\overline{z}_{t+1}-z_{t+1}\sim\mathcal{N}(4,s_{t+1}^{2})\)</span></p>
<p>How confident are we about this residual?</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math display">\[\begin{align}
s_{t+1}^2 &amp;= \text{Cov}[\bar{z}_{t+1} - z_{t+1}|z_{0:t}] \\
&amp;= \text{Cov}[z_{t+1}|z_{0:t}] \\
&amp;= \text{Cov}[Hx_{t+1} + n_{t+1}|z_{0:t}] \\
&amp;= HCov[x_{t+1}|z_{0:t}]H^T + \text{Cov}[n_{t+1}|z_{0:t}] \\
&amp;= HCov[x_{t+1}|z_{0:t}]H^T + \text{Cov}[n_{t+1}] \\
&amp;= H\Sigma_{t+1|t}H^T + r^2 = 102 + 1^2 = 103
\end{align}\]</span></p>
</div><div class="column" style="width:50%;">

</div></div>
</div></div>
<div class="fragment">
<div class="red-annotation absolute" style="bottom: 70px; right: 0px; ">
<p>This means that our<br>
measurement was within<br>
a range of <span class="math inline">\(3\sqrt{103}\)</span> from the<br>
true position with high<br>
probability (~0.997)</p>
</div>
</div>
</section>
<section id="kalman-filter-with-2d-state-the-update-step-1" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 2D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/2d-update-diagram.png"></p>
</div><div class="column" style="width:10%;">
<p><img data-src="img/2d-update-annot.png" class="absolute" style="top: 210px; left: 330px; height: 220px; "></p>
</div><div class="column small-font" style="width:50%;">
<p>How do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is <span class="math inline">\(p(x_{t+1}|z_{0:t+1})=\mathcal{N}(\mu_{t+1|t+1},\Sigma_{t+1|t+1})\)</span> with</p>
<p><span class="math inline">\(K_{t+1} = \Sigma_{t+1|t} H^T s_{t+1}^{-2} = \begin{bmatrix} 102 &amp; 100 \\ 100 &amp; 101 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} 103^{-1} = \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\mu_{t+1|t+1} = \mu_{t+1|t} + K_{t+1} \mu_{\delta x} = \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix} 4 = \begin{bmatrix} 4.96 \\ 4.88 \end{bmatrix}\)</span></p>
<div class="quarto-layout-panel" data-layout="[50, -50]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><span class="math display">\[\begin{align}
\Sigma_{t+1|t+1} &amp;= \Sigma_{t+1|t} - K H \Sigma_{t+1|t} \\
&amp;= \Sigma_{t+1|t} - \frac{102}{103} \Sigma_{t+1|t} \\
&amp;= \frac{1}{103} \Sigma_{t+1|t} \\
&amp;= \begin{bmatrix} 0.99 &amp; 0.97 \\ 0.97 &amp; 0.98 \end{bmatrix}\end{align}\]</span></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
</div></div>
</section>
<section id="kalman-filter-with-2d-state-the-update-step-2" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 2D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/2d-update-diagram.png"></p>
</div><div class="column" style="width:10%;">
<p><img data-src="img/2d-update-annot.png" class="absolute" style="top: 210px; left: 330px; height: 220px; "></p>
</div><div class="column small-font" style="width:50%;">
<p>How do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is <span class="math inline">\(p(x_{t+1}|z_{0:t+1})=\mathcal{N}(\mu_{t+1|t+1},\Sigma_{t+1|t+1})\)</span> with</p>
<p><span class="math inline">\(K_{t+1} = \Sigma_{t+1|t} H^T s_{t+1}^{-2} = \begin{bmatrix} 102 &amp; 100 \\ 100 &amp; 101 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} 103^{-1} = \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\mu_{t+1|t+1} = \mu_{t+1|t} + K_{t+1} \mu_{\delta x} = \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix} 4 = \begin{bmatrix} 4.96 \\ 4.88 \end{bmatrix}\)</span></p>
<div class="quarto-layout-panel" data-layout="[50, 50]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><span class="math display">\[\begin{align}
\Sigma_{t+1|t+1} &amp;= \Sigma_{t+1|t} - K H \Sigma_{t+1|t} \\
&amp;= \Sigma_{t+1|t} - \frac{102}{103} \Sigma_{t+1|t} \\
&amp;= \frac{1}{103} \Sigma_{t+1|t} \\
&amp;= \begin{bmatrix} 0.99 &amp; 0.97 \\ 0.97 &amp; 0.98 \end{bmatrix}\end{align}\]</span></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><span class="red medium-font"><br><br> After the measurement the covariance was reduced. We are now more confident than both the measurement and the prediction estimate.</span></p>
</div>
</div>
</div>
</div></div>
</section>
<section id="kalman-filter-with-2d-state-the-update-step-3" class="slide level2">
<h2><span class="medium-font">Kalman Filter with 2D state: the update step</span></h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/2d-update-diagram.png"></p>
</div><div class="column" style="width:10%;">

</div><div class="column small-font" style="width:50%;">
<p>How do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is <span class="math inline">\(p(x_{t+1}|z_{0:t+1})=\mathcal{N}(\mu_{t+1|t+1},\Sigma_{t+1|t+1})\)</span> with</p>
<p><span class="math inline">\(K_{t+1} = \Sigma_{t+1|t} H^T s_{t+1}^{-2} = \begin{bmatrix} 102 &amp; 100 \\ 100 &amp; 101 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} 103^{-1} = \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix}\)</span></p>
<p><span class="math inline">\(\mu_{t+1|t+1} = \mu_{t+1|t} + K_{t+1} \mu_{\delta x} = \begin{bmatrix} 1 \\ 1 \end{bmatrix} + \begin{bmatrix} 102/103 \\ 100/103 \end{bmatrix} 4 = \begin{bmatrix} 4.96 \\ 4.88 \end{bmatrix}\)</span></p>
<div class="quarto-layout-panel" data-layout="[50, 50]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><span class="math display">\[\begin{align}
\Sigma_{t+1|t+1} &amp;= \Sigma_{t+1|t} - K H \Sigma_{t+1|t} \\
&amp;= \Sigma_{t+1|t} - \frac{102}{103} \Sigma_{t+1|t} \\
&amp;= \frac{1}{103} \Sigma_{t+1|t} \\
&amp;= \begin{bmatrix} 0.99 &amp; 0.97 \\ 0.97 &amp; 0.98 \end{bmatrix}\end{align}\]</span></p>
</div>
</div>
</div>
</div></div>
<div class="red-annotation absolute" style="left: 250px; bottom: 50px; ">
<p>Also, notice how we MEASURED<br>
position, and through correlation,<br>
we were able to INFER velocity.<br>
This is not always possible.</p>
</div>
</section>
<section id="qquadquad-kalman-filter-in-n-dimensions" class="slide level2">
<h2><span class="math inline">\(\qquad\quad\)</span> <span class="medium-font">Kalman Filter in N dimensions</span></h2>
<div class="semi-tiny-font absolute" style="top: 0px; left: 0px; ">
<p>Dynamics<br>
<span class="math inline">\(x_{t+1} = Ax_t + Bu_t + Gw_t\)</span><br>
<span class="math inline">\(w_t \sim \mathcal{N}(0, Q)\)</span></p>
</div>
<div class="semi-tiny-font absolute" style="top: 0px; right: 0px; ">
<p>Measurements<br>
<span class="math inline">\(z_t = Hx_t + n_t\)</span><br>
<span class="math inline">\(n_t \sim \mathcal{N}(0, R)\)</span></p>
</div>
<div class="center-align medium-font">
<p><strong>Init</strong> <span class="math display">\[bel(x_0) \sim \mathcal{N}(\mu_{0|0}, \Sigma_{0|0})\]</span></p>
<p><strong>Prediction Step</strong> <span class="math display">\[\mu_{t+1|t} = A\mu_{t|t} + Bu_t\]</span> <span class="math display">\[\Sigma_{t+1|t} = A\Sigma_{t|t}A^T + GQG^T\]</span></p>
<p><strong>Update Step</strong></p>
<p>Received measurement <span class="math inline">\(\tilde{z}_{t+1}\)</span> but expected to receive <span class="math inline">\(\mu_{z_{t+1}} = H\mu_{t+1|t}\)</span></p>
<p>Prediction residual is a Gaussian random variable <span class="math inline">\(\delta z \sim \mathcal{N}(\tilde{z}_{t+1} - \mu_{z_{t+1}}, S_{t+1})\)</span><br>
where the covariance of the residual is <span class="math inline">\(S_{t+1} = H\Sigma_{t+1|t}H^T + R\)</span></p>
<p>Kalman Gain (optimal correction factor): <span class="math inline">\(K_{t+1} = \Sigma_{t+1|t}H^T S_{t+1}^{-1}\)</span></p>
<p><span class="math display">\[\mu_{t+1|t+1} = \mu_{t+1|t} + K_{t+1}(\tilde{z}_{t+1} - \mu_{z_{t+1}})\]</span></p>
<p><span class="math display">\[\Sigma_{t+1|t+1} = \Sigma_{t+1|t} - K_{t+1}H\Sigma_{t+1|t}\]</span></p>
</div>
<div class="fragment">
<div class="red semi-tiny-font absolute right-align" style="bottom: 68px; right: 0px; ">
<p>Potentially<br>
<span class="math inline">\(\xleftarrow{\hspace{1.5cm}}\)</span> expensive and<br>
error-prone<br>
operation: matrix<br>
inversion O(|z|^2.4)</p>
</div>
</div>
</section>
<section id="quadqquad-kalman-filter-in-n-dimensions" class="slide level2">
<h2><span class="math inline">\(\quad\qquad\)</span> <span class="medium-font">Kalman Filter in N dimensions</span></h2>
<div class="semi-tiny-font absolute" style="top: 0px; left: 0px; ">
<p>Dynamics<br>
<span class="math inline">\(x_{t+1} = Ax_t + Bu_t + Gw_t\)</span><br>
<span class="math inline">\(w_t \sim \mathcal{N}(0, Q)\)</span></p>
</div>
<div class="semi-tiny-font absolute" style="top: 0px; right: 0px; ">
<p>Measurements<br>
<span class="math inline">\(z_t = Hx_t + n_t\)</span><br>
<span class="math inline">\(n_t \sim \mathcal{N}(0, R)\)</span></p>
</div>
<div class="center-align medium-font">
<p><strong>Init</strong> <span class="math display">\[bel(x_0) \sim \mathcal{N}(\mu_{0|0}, \Sigma_{0|0})\]</span></p>
<p><strong>Prediction Step</strong> <span class="math display">\[\mu_{t+1|t} = A\mu_{t|t} + Bu_t\]</span> <span class="math display">\[\Sigma_{t+1|t} = A\Sigma_{t|t}A^T + GQG^T\]</span></p>
<p><strong>Update Step</strong></p>
<p>Received measurement <span class="math inline">\(\tilde{z}_{t+1}\)</span> but expected to receive <span class="math inline">\(\mu_{z_{t+1}} = H\mu_{t+1|t}\)</span></p>
<p>Prediction residual is a Gaussian random variable <span class="math inline">\(\delta z \sim \mathcal{N}(\tilde{z}_{t+1} - \mu_{z_{t+1}}, S_{t+1})\)</span><br>
where the covariance of the residual is <span class="math inline">\(S_{t+1} = H\Sigma_{t+1|t}H^T + R\)</span></p>
<p>Kalman Gain (optimal correction factor): <span class="math inline">\(K_{t+1} = \Sigma_{t+1|t}H^T S_{t+1}^{-1}\)</span></p>
<p><span class="math display">\[\mu_{t+1|t+1} = \mu_{t+1|t} + K_{t+1}(\tilde{z}_{t+1} - \mu_{z_{t+1}})\]</span></p>
<p><span class="math display">\[\Sigma_{t+1|t+1} = \Sigma_{t+1|t} - K_{t+1}H\Sigma_{t+1|t}\]</span></p>
</div>
<div class="red semi-tiny-font absolute right-align" style="bottom: -40px; right: 0px; ">
<p>Numerical errors may make the<br>
covariance non-symmetric at<br>
some point. In practice, we<br>
either force symmetry, or we<br>
decompose the covariance<br>
during the update.<br>
</p>
<p><img data-src="img/left-down-arrow.png" width="90"> See “Factorization methods<br>
for discrete sequential<br>
estimation” by Gerald Bierman<br>
for more info.</p>
</div>
</section>
<section id="kalman-filter-with-4d-state" class="slide level2">
<h2>Kalman Filter with 4D state</h2>
<div class="semi-tiny-font">
<p>Suppose a cannonball is shot from a cannon, and assume we can somehow measure its position in flight.</p>
<p>Assuming zero drag and resistance from the air, the only force acting on the ball after it is ejected is its weight (suppose mass=1kg).</p>
<p>Then the continuous dynamics of the system are given by <span class="math inline">\(\ddot{p}_x = w_x\)</span> <span class="math inline">\(\ddot{p}_y = -g + w_y\)</span> where <span class="math inline">\(w\)</span> is noise in the acceleration.</p>
<p>The discrete-time version of this dynamics model is</p>
<p><span class="math display">\[\begin{align}
p_x(t + 1) &amp;= p_x(t) + v_x(t)\delta t + w_x(t)\delta t^2/2 \\
p_y(t + 1) &amp;= p_y(t) + v_y(t)\delta t + (-g + w_y(t))\delta t^2/2 \\
v_x(t + 1) &amp;= v_x(t) + w_x(t)\delta t \\
v_y(t + 1) &amp;= v_y(t) + (-g + w_y(t))\delta t
\end{align}\]</span></p>
<p>which can be expressed in matrix form as <span class="math inline">\(x_{t+1} = Ax_t + Bu_t + Gw_t \quad\)</span> where <span class="math inline">\(\quad x_t = [p_x(t), p_y(t), v_x(t), v_y(t)]^T\)</span></p>
<p><span class="math display">\[A = \begin{bmatrix} 1 &amp; 0 &amp; \delta t &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; \delta t \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \quad B = I_{4 \times 4} \quad u_t = \begin{bmatrix} 0 \\ -g\delta t^2/2 \\ 0 \\ -g\delta t \end{bmatrix} \quad G = \begin{bmatrix} \delta t^2/2 &amp; 0 \\ 0 &amp; \delta t^2/2 \\ \delta t &amp; 0 \\ 0 &amp; \delta t \end{bmatrix} \quad w_t \sim \mathcal{N}(0_{2 \times 1}, Q) \quad g = 9.81 m/s^2\]</span></p>
<p>Since we can measure its position the measurement model is <span class="math inline">\(z_t = Hx_t + n_t\)</span> where <span class="math inline">\(H = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \end{bmatrix}\)</span> and <span class="math inline">\(n_t \sim \mathcal{N}(0_{2 \times 1}, R)\)</span></p>
<div class="fragment">
<p><img data-src="img/uparrow-4dstate.png" class="absolute" style="left: 352px; bottom: 127px; height: 100px; "></p>
<div class="quarto-layout-panel" data-layout="[-15, 85]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 15.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 85.0%;justify-content: flex-start;">
<p><span class="red">Notice here that we don’t actually control the system,<br>
but we include <span class="math inline">\(u_t\)</span> to account for additive constants in the dynamics.</span></p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="kalman-filter-with-4d-state-1" class="slide level2">
<h2>Kalman Filter with 4D state</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/Lecture8_342.png" class="quarto-figure quarto-figure-center" height="550"></p>
</figure>
</div>
<div class="semi-tiny-font blue quarto-layout-panel" data-layout="[15, -70]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 17.7%;justify-content: flex-start;">
<p><span class="absolute" style="left: 0px; bottom: 150px; ">This is the <span class="math inline">\(3\sigma_{py}\)</span> uncertainty around the mean estimate. With probability ~0.997 the true <span class="math inline">\(p_y\)</span> should be within these bounds, as long as the system has been initialized close enough to the true initial state, and as long as the KF assumptions hold.</span></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 82.4%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
<p><span class="absolute" style="left: 130px; bottom: 370px; "><span class="math inline">\(\color{blue}\xrightarrow{\hspace{2cm}}\)</span></span></p>
</section>
<section id="kalman-filter-with-4d-state-2" class="slide level2">
<h2>Kalman Filter with 4D state</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/Lecture8_342.png" class="quarto-figure quarto-figure-center" height="550"></p>
</figure>
</div>
<div class="semi-tiny-font blue quarto-layout-panel" data-layout="[15, -70]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 17.7%;justify-content: flex-start;">
<p><span class="absolute" style="left: 0px; bottom: 150px; ">We initialized the KF estimated mean position to be [0, 2] when the true value was [0, 0] and we assigned high uncertainty in the initial position estimate, which was reduced after the first few measurements.</span></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 82.4%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
<p><img data-src="img/blue-steep-arrow.png" class="absolute" style="left: 185px; bottom: 180px; height: 140px; "></p>
</section>
<section id="kalman-filter-with-4d-state-3" class="slide level2">
<h2>Kalman Filter with 4D state</h2>
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="img/Lecture8_346.png" class="quarto-figure quarto-figure-right" width="900" height="550"></p>
</figure>
</div>
<div class="semi-tiny-font blue quarto-layout-panel" data-layout="[15, -70]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 17.7%;justify-content: flex-start;">
<p><span class="absolute" style="left: 0px; bottom: 150px; ">We initialized the KF estimated mean y-velocity to be 5 when the true value was 10 and we assigned high uncertainty in the initial y-velocity estimate.<br>
<br> Even though we do not measure the velocity directly, through correlation with position, the KF is able to INFER it and the initially large uncertainty shrinks as more measurements are received.</span></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 82.4%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
</section>
<section id="kalman-filter-with-4d-state-4" class="slide level2">
<h2>Kalman Filter with 4D state</h2>
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="img/Lecture8_346.png" class="quarto-figure quarto-figure-right" width="900" height="550"></p>
</figure>
</div>
<div class="tiny-font absolute" style="bottom: 0px; right: 0px; ">
<p><span class="red">Parameters and code to reproduce this can be found at</span> <a href="https://github.com/florianshkurti/comp417/tree/master/filtering_examples" class="uri">https://github.com/florianshkurti/comp417/tree/master/filtering_examples</a></p>
</div>
<div class="semi-tiny-font blue quarto-layout-panel" data-layout="[15, -70]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 17.7%;justify-content: flex-start;">
<p><span class="absolute" style="left: 0px; bottom: 150px; ">We initialized the KF estimated mean y-velocity to be 5 when the true value was 10 and we assigned high uncertainty in the initial y-velocity estimate.<br>
<br> Even though we do not measure the velocity directly, through correlation with position, the KF is able to INFER it and the initially large uncertainty shrinks as more measurements become are received.</span></p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 82.4%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
</section>
<section id="appendix-1" class="slide level2">
<h2>Appendix 1</h2>
<div class="small-font">
<div class="quarto-layout-panel" data-layout="[40,60]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<p>Claim <span class="math inline">\(\mathcal{N}(\mu_A, \sigma_A^2) \mathcal{N}(\mu_B, \sigma_B^2) \propto \mathcal{N}(\mu, \sigma^2)\)</span></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 60.0%;justify-content: flex-start;">
<p>where <span class="math inline">\(\mu = \mu_B + \frac{\sigma_B^2}{\sigma_A^2 + \sigma_B^2}(\mu_A - \mu_B) \qquad \sigma^2 = \sigma_B^2 - \frac{\sigma_B^2}{\sigma_A^2 + \sigma_B^2} \sigma_B^2\)</span></p>
</div>
</div>
</div>
<p>Proof:</p>
<p><span class="math display">\[\mathcal{N}(\mu_A, \sigma_A^2) \mathcal{N}(\mu_B, \sigma_B^2) = \frac{1}{2\pi\sigma_A\sigma_B} \exp\{-0.5(x - \mu_A)^2/\sigma_A^2 - 0.5(x - \mu_B)^2/\sigma_B^2\}\]</span></p>
</div>
<div class="columns small-font">
<div class="column" style="width:50%;">
<p>Define <span class="math inline">\(\quad \beta = \frac{(x - \mu_A)^2}{2\sigma_A^2} + \frac{(x - \mu_B)^2}{2\sigma_B^2}\)</span></p>
<p><span class="math display">\[\begin{align}
\beta &amp;= \frac{(\sigma_A^2 + \sigma_B^2)x^2 - 2(\mu_A\sigma_B^2 + \mu_B\sigma_A^2)x + \mu_A^2\sigma_B^2 + \mu_B^2\sigma_A^2}{2\sigma_A^2\sigma_B^2} \\
\beta &amp;= \frac{x^2 - 2\frac{\mu_A\sigma_B^2 + \mu_B\sigma_A^2}{\sigma_A^2 + \sigma_B^2}x + \frac{\mu_A^2\sigma_B^2 + \mu_B^2\sigma_A^2}{\sigma_A^2 + \sigma_B^2}}{2\frac{\sigma_A^2\sigma_B^2}{\sigma_A^2 + \sigma_B^2}} \\
\beta &amp;= \frac{x^2 - 2\mu x + \mu^2}{2\sigma^2} = \frac{(x - \mu)^2}{2\sigma^2}
\end{align}\]</span></p>
</div><div class="column" style="width:50%;">
<p><br><br><br><br></p>
<p>where</p>
<p><span class="math display">\[\begin{align}
\mu &amp;= \mu_A \frac{\sigma_B^2}{\sigma_A^2 + \sigma_B^2} + \mu_B \frac{\sigma_A^2}{\sigma_A^2 + \sigma_B^2} = \mu_B + \frac{\sigma_B^2}{\sigma_A^2 + \sigma_B^2}(\mu_A - \mu_B) \\
\sigma^2 &amp;= \frac{\sigma_A^2\sigma_B^2}{\sigma_A^2 + \sigma_B^2} = \sigma_B^2 - \frac{\sigma_B^2}{\sigma_A^2 + \sigma_B^2}\sigma_B^2
\end{align}\]</span></p>
</div></div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="https://csc477.github.io/website_fall24" target="_blank" style="font-size:0.8em; bottom: -5px;">↩︎ Back to Course Website</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":2,"chalkWidth":2,"chalkEffect":1},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/csc477\.github\.io\/website_fall24");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>