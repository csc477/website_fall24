---
title: "CSC477 Introduction to Mobile Robotics"
subtitle: "Week #6: Mapping"
author: "Florian Shkurti"
format: 
  revealjs:
    slide-number: true
    smaller: true
    footer: '<a href="https://csc477.github.io/website_fall24" target="_blank" style="font-size:0.8em; bottom: -5px;">↩ Back to Course Website</a>'
    css: ../style.css
    chalkboard:
      buttons: true
      boardmarker-width: 2
      chalk-width: 2
      chalk-effect: 1.0
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

## Today’s agenda

::::: columns
::: {.column width="70%"}
- How to represent maps

- Probabilistic occupancy grid mapping
:::

::: {.column width="30%"}
![](img/Lecture6_1.png)
:::
:::::


## Categories of maps

-   Metric
    -   Map accurately represents lengths and angles
-   Topological
    -   Map is reduced to a graph representation of the structure of free space
-   Topometric
    -   Atlas: a combination of local metric maps (nodes) connected via edges
-   Sequence of raw time-series observations (e.g. video)
    -   No metric or topological information directly represented by the map 
    
    
## Typical operations on maps

- Distance and direction to closest obstacle
- Collision detection: is a given robot configuration in free space?
- Map merging / alignment
- Occupancy updates
- Raytracing

. . . 

:::{.absolute .red-annotation bottom="57%" right=200}
Common operations in \
computer graphics 
:::

## Metric Maps {.center}

## Occupancy Grids

::: {.columns}
::: {.column width="33%"}
![](img/Lecture6_2.png)

![](img/Lecture6_5.png)
:::

::: {.column width="33%"}
![](img/Lecture6_3.gif)

![](img/Lecture6_4.png)
:::

::: {.column width="33%" .medium-font}

:::{.fragment}
[Advantages: \
• O(1) occupancy lookup and update \
• Supports image operations]{.green}

[Disadvantages:\
• Doesn’t scale well in higher dimensions]{.red}
:::

<br> 

Each cell contains either:

- unknown/unexplored (grey)
- probability of occupation
:::
::: 


## Quadtrees

:::{layout-ncol="3"}

![](img/Lecture6_10.gif)

![](img/Lecture6_11.png)

![](img/Lecture6_12.png)
:::

Each node represents a square. If the node is fully empty or fully occupied it has no children.

If it is partially occupied it has four children. Subdivision stops after some minimal square size.

## Octrees

:::{layout="[40, -20, 40]"}
![](img/Lecture6_13.jpg)

![](img/Lecture6_14.jpg)
:::

Each node represents a cube. If the node is fully empty or fully occupied it has no children.

If it is partially occupied it has eight children. Subdivision stops after some minimal cube size.

## Octrees
:::{layout="[33, 33, 33]"}
![](img/Lecture6_13.jpg)

[[Problem 1]{.underline}: quadtrees and octrees are not 
balanced trees. So, in the worst case an 
occupancy query could be O(n) in the 
number of nodes. ]{.red-annotation} 


![](img/Lecture6_14.jpg)
:::

Each node represents a cube. If the node is fully empty or fully occupied it has no children.

If it is partially occupied it has eight children. Subdivision stops after some minimal cube size.


## Octrees

::: {.columns}
::: {.column width="33%"}
![](img/Lecture6_13.jpg)
:::

::: {.column width="33%" .red-annotation}
[Problem 1]{.underline}: quadtrees and octrees are not 
balanced trees. So, in the worst case an 
occupancy query could be O(n) in the 
number of nodes. 

[Problem 2]{.underline}: quadtrees and octrees are 
sensitive to small changes in the location 
of obstacles.
:::

::: {.column width="33%"}
![](img/Lecture6_14.jpg)
:::
::: 


Each node represents a cube. If the node is fully empty or fully occupied it has no children.

If it is partially occupied it has eight children. Subdivision stops after some minimal cube size.


## Octree Example: Octomap


{{< video https://www.youtube.com/watch?v=0sFyyKEoB4o width=600 height="400" >}}

Open source as a ROS package

## Implicit Surface Definitions: Signed Distance Function

![](img/Lecture6_20.png){fig-align="center"}

[This distance function \
is defined over any point \
in 3D space. ]{.red-annotation .absolute left=0 bottom="40%"}

![](img/arrow1.png){.absolute left=0 bottom="14%" width=170}


## SDF Example

{{< video https://www.youtube.com/watch?v=MzLdRFSrtuI width=600 height="400" >}}


## Pointclouds

![](img/Lecture6_22.jpg){fig-align="center"}

## Pointclouds

::: {.columns}
::: {.column width="40%" .medium-font}

:::{.green}
Advantages: 

- can make local changes to the map without affecting the pointcloud globally
- can align pointclouds 
- nearest neighbor queries are easy with kd-trees or locality-sensitive hashing
:::
	

:::{.red}
Disadvantages:

- need to segment objects in the map
- raytracing is approximate and nontrivial 
:::

:::
::: {.column width="60%"}
![](img/Lecture6_22.jpg)
:::
:::


## Topological Maps {.center}

Topology: study of spatial properties that are preserved under continuous deformations of the space.

## Generalized Voronoi Graph (GVG)

![](img/Lecture6_24.png){fig-align="center"}

## Deformation Retraction: GVG in Plane

[GVG nodes: points that are equidistant to 3 or more obstacle points]{.blue .small-font} 

![](img/Lecture6_25.png){fig-align="center" width="73%" height=400}

[Retractions are \
also called \
roadmaps.]{.red-annotation .absolute left=0 bottom=35%}

## Roadmap: Voronoi diagrams 

::: {.columns}
::: {.column width="40%"}
- GVG is formed by paths equidistant from the two closest objects
- maximizing the clearance between the obstacles.
:::

::: {.column width="60%"}
![](img/Lecture6_26.png)
:::
::: 

- This generates a very safe roadmap which avoids obstacles as much as possible

## Generalized Voronoi Graphs (GVG)

![](img/Lecture6_27.png){fig-align="center"}

Turns comparison between pixels to comparison between graphs.

## GVG: sensitivity

![](img/Lecture6_28.png){fig-align="center"}

The skeleton is sensitive to small changes in the object's boundary.

## GVG: advantages

![](img/Lecture6_29.png){fig-align="center"}

[Can specify whether we pass on the “left” or “right” of each obstacle \
on our way to the goal.]{.red}

## GVG: advantages
![](img/Lecture6_30.png){fig-align="center"}

## How a curve winds around an obstacle

![](img/Lecture6_31.png){fig-align="center"}

. . . 

[Note: winding angle of a path \
can be more than 360 degrees]{.red-annotation .absolute left=0 top="30%"}

## Homotopy classes

::: {.columns}
::: {.column width="40%" .small-font}
Two paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:

:::{layout="[5, 90]"}
with 

$$
\begin{align}
\tau_1 : [0, T] &\to \mathbb{R}^2 \\
\tau_2 : [0, T] &\to \mathbb{R}^2 \\
\tau_1(0) &= \tau_2(0) \\
\tau_1(T) &= \tau_2(T)
\end{align}
$$

:::

are homotopic iff there exists a continuous function

$$H : [0, 1] \times [0, T] \to \mathbb{R}^2$$

such that for any time t:

$$
\begin{align}
H(0, t) &= \tau_1(t) \\
H(1, t) &= \tau_2(t)
\end{align}
$$

:::

::: {.column width="60%"}
![](img/Lecture6_33.png)
:::
::: 



## Homotopy functions for deformations


::: {.columns}
::: {.column width="40%" .small-font}
Two paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:

:::{layout="[10, 90]"}
with 

$$
\begin{align}
\tau_1 : [0, T] &\to \mathbb{R}^2 \\
\tau_2 : [0, T] &\to \mathbb{R}^2 \\
\tau_1(0) &= \tau_2(0) \\
\tau_1(T) &= \tau_2(T)
\end{align}
$$

:::

are homotopic iff there exists a continuous function

$$H : [0, 1] \times [0, T] \to \mathbb{R}^2$$

such that for any time t:

$$
\begin{align}
H(0, t) &= \tau_1(t) \\
H(1, t) &= \tau_2(t)
\end{align}
$$

:::

::: {.column width="60%"}
![](img/homotopy-func.png)
:::
::: 


## Topometric maps {.center}

## Topometric maps
![](img/Lecture6_56.jpg){fig-align="center"}

:::{layout-ncol="3"}
Occupancy grid

Topological map

Topometric map
:::


## Topometric maps

[Edges: rotations and \
translations between \
local maps, but also topological \
connectivity]{.medium-font .absolute right=0 top="10%"}

![](img/topo-maps.png){fig-align="center" width=70% height=80% .bg-img}


[Main advantage: \
allows us combine accurate local \
maps into a global, **typically** \
**inconsistent** map that nevertheless \
provides sufficient navigation information.]{.medium-font .absolute left=20 bottom=50}


## Maps of Raw Observations{.center}

## Main Idea

-   Map = entire (unprocessed) sequence of observations, e.g. video.
-   Do not try to support distance, collision, and raytracing queries.
-   Instead, provide only a similarity/nearest neighbors query
    -   “Find the image in the video that is most similar to the one I’m seeing now.”
-   History of observations determines a (set of) location(s) in the map 


## Metric Map Alignment{.center}

a.k.a. scan matching, a.k.a. iterative closest point (ICP), a.k.a. registration

## Problem definition

::: {.columns}
::: {.column width="70%"}
-   Given
    -   two pointclouds or
    -   a (local) laser scan and a pointcloud (global map) or
    -   two maps

    find the rotation and translation that aligns them
:::

::: {.column width="30%"}
![](img/Lecture6_58.png)
:::
::: 

. . .

-   Assumption: We are assuming in these slides for simplicity that that rigid-body transformations are sufficient to align the scans. They might not be. We might need to also model scaling, non-uniform stretching and other nonlinear transformations.

## Scan alignment with known correspondences

[If the correct correspondences are known, the correct relative rotation/translation can be calculated in closed form.]{.medium-font}

![](img/scan-alignment.png){width="60%" height="50%" .absolute bottom=200 right=150}

. . .

[When correct correspondences \
are known we say that **data** \
**association** is known/unambiguous.]{.medium-font .absolute bottom=150 left=0}


[In general, data association is a real \
and hairy problem in robotics.]{.medium-font .absolute bottom=50 left=0}

## Scan alignment with known correspondences

::: {.columns}
::: {.column .medium-font}

Find the 3D rotation matrix R and the 3D translation
vector t that will best align the corresponding points

$$
\text{error}(R, t) = \frac{1}{N} \sum_{i=1}^{N} ||\mathbf{p}_i - (R\mathbf{q}_i + t)||^2
$$

$$
R^*, t^* = \operatorname*{argmin}_{R,t} \text{error}(R, t)
$$

:::{.fragment}
[Q: How do we minimize this error? \
A: Turns out it has a closed-form solution.]{.red }
:::

:::

::: {.column}
![](img/scan-alignment.png)
:::
:::

## [Closed form solution of scan alignment with known correspondences]{.medium-font}

::: {.columns}
::: {.column .small-font}

Find the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points

$$
\text{error}(R, t) = \frac{1}{N} \sum_{i=1}^{N} ||\mathbf{p}_i - (R\mathbf{q}_i + t)||^2
$$

$$
R^*, t^* = \operatorname*{argmin}_{R,t} \text{error}(R, t)
$$

Step 1: compute the means of the two scans

$$
\mu_p = \frac{1}{N} \sum_{i=1}^{N} \mathbf{p}_i \qquad\qquad \mu_q = \frac{1}{N} \sum_{i=1}^{N} \mathbf{q}_i
$$

Step 2: subtract the means from the scans

$\qquad \bar{\mathbf{p}}_i = \mathbf{p}_i - \mu_p \qquad\qquad \bar{\mathbf{q}}_i = \mathbf{q}_i - \mu_q$

Step 3: form the matrix

$$W = \sum_{i=1}^{N} \bar{\mathbf{p}}_i \bar{\mathbf{q}}_i^T$$

:::

::: {.column .small-font}
![](img/scan-alignment.png)

:::
:::


## [Closed form solution of scan alignment with known correspondences]{.medium-font}

::: {.columns}
::: {.column .small-font}

Find the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points

$$
\text{error}(R, t) = \frac{1}{N} \sum_{i=1}^{N} ||\mathbf{p}_i - (R\mathbf{q}_i + t)||^2
$$

$$
R^*, t^* = \operatorname*{argmin}_{R,t} \text{error}(R, t)
$$

Step 1: compute the means of the two scans

$$
\mu_p = \frac{1}{N} \sum_{i=1}^{N} \mathbf{p}_i \qquad\qquad \mu_q = \frac{1}{N} \sum_{i=1}^{N} \mathbf{q}_i
$$

Step 2: subtract the means from the scans

$\qquad \bar{\mathbf{p}}_i = \mathbf{p}_i - \mu_p \qquad\qquad \bar{\mathbf{q}}_i = \mathbf{q}_i - \mu_q$

Step 3: form the matrix

$$W = \sum_{i=1}^{N} \bar{\mathbf{p}}_i \bar{\mathbf{q}}_i^T$$

:::

::: {.column .small-font}
![](img/scan-alignment.png)

Step 4: compute the SVD of the matrix W

$\qquad W = U\Sigma V^T$

Step 5: if rank(W)=3, optimal solution is unique:

$\qquad R^* = UV^T \qquad\qquad t^* = \mu_p - R^* \mu_q$

:::
:::


## [Closed form solution of scan alignment with known correspondences]{.medium-font}

::: {.columns}
::: {.column .small-font}

Find the 3D rotation matrix R and the 3D translation
vector t that will best align the corresponding points

$$
\text{error}(R, t) = \frac{1}{N} \sum_{i=1}^{N} ||p_i - (Rp_i + t)||^2
$$

$$
R^*, t^* = \operatorname*{argmin}_{R,t} \text{error}(R, t)
$$

<br><br>

[If you’re interested, the proof of the closed-form solution can be found in: \
K. S. Arun, T. S. Huang, and S. D. Blostein. Least square fitting of two 3-d point sets. \
IEEE Transactions on Pattern Analysis and Machine Intelligence, 9(5):698 – 700, 1987]{.small-font}

:::

::: {.column}
![](img/scan-alignment.png)
:::
:::



## Scan alignment with unknown correspondences

If correct correspondences are not known, it is generally impossible to determine the optimal relative rotation/ translation in one step

![](img/Lecture6_160.png){fig-align="center"}

## Scan alignment with unknown correspondences

::: {.columns}
::: {.column}
![](img/Lecture6_161.png)
:::

::: {.column}
Main idea for data association:

- associate each point in the source scan to its nearest neighbor in the target scan

    Find optimal rotation and translation for this correspondence.


Repeat until no significant drop in error.
:::
:::


## libpointmatcher

{{< video https://youtu.be/jlAArM_6N-I?si=Bg8swXnIk8EkUuAs width=600 height="400" >}}



## Today’s agenda

::::: columns
::: {.column width="70%"}
- How to represent maps

- Probabilistic occupancy grid mapping
:::

::: {.column width="30%"}
![](img/Lecture6_1.png)
:::
:::::

## What we want to do

{{< video https://youtu.be/HGt3XpclMa8?si=H2UeSP9hhIqujbqI width=600 height="400" >}}


## Terminology

- Pose: the rotation and translation of a robot
- Odometry: the transformation of the body frame with respect to its initial pose (fixed frame of reference).

$$
_B_{t}^{B_0}T
$$

- Dynamics model: what is the next state given current state and control?

$$
x_{t+1} = f(x_t, u_t)
$$

- Sensor measurement model: what is the expected measurement given the robot’s current state?

$$z_t = h(x_t)$$


## Perfect models vs. Reality

![](img/perfect-model.png)

:::{layout-ncol="2"}
$x_{t+1} = f(x_t, u_t)$ 

$x_{t+1} = f(x_t, u_t) + w_t$
:::


![](img/noise-as-rand-var.png){.width=80 .absolute right=0 top=25%}

## Perfect models vs. Reality

:::{layout="[25, 25, -50]"}
Sensor \
Measurements

$z_t = h(x_t)$
:::

::: {.columns}
::: {.column width="25%"}
e.g. GPS (simplified)
:::

::: {.column width="25%"}
$z_t = x_t$
![](img/Lecture6_181.jpg)
:::

::: {.column width="50%"}
$z_t = x_t + v_t, \quad v_t \sim \mathcal{N}(0, \sigma^2I)$

![](img/Lecture6_178.png)
:::
::: 

## Perfect models vs. Reality

::: {.columns}
::: {.column width="25%"}
Dynamics 

<br>

Sensor
Measurements

<br> 

e.g. GPS (simplified)
:::

::: {.column width="25%"}
$x_{t+1} = f(x_t, u_t)$

![](img/perfect-model-1.png)


$z_t = h(x_t)$


$z_t = x_t$
![](img/Lecture6_181.jpg)
:::

::: {.column width="25%"}

![](img/perfect-model-diaagram.png)


![](img/Lecture6_178.png)
:::

::: {.column width="25%"}
$p(x_{t+1} | x_t, u_t)$

probabilistic
dynamics model


$p(z_t| x_t)$

probabilistic
measurement model
:::
::: 


## Why is mapping a problem?
[Don’t we have all the information we need to build a map?]{.small-font}

-   Two main sources of uncertainty:
    -   accumulating uncertainty in the dynamics

:::{layout-ncol="4"}
$p(x_{t+1} | x_t, u_t)$

![](img/perfect-model-diaagram.png)

![](img/mapping-problem.png)

[Uncertainty in the dynamics compounds into increasing uncertainty in odometry, as time passes.]{.small-font}
:::

## Why is mapping a problem?
[Don’t we have all the information we need to build a map?]{.small-font}

-   Two main sources of uncertainty:
    -   uncertainty in the dynamics $p(x_{t+1} | x_t, u_t)$
    -   uncertainty in sensor measurements

. . .

![](img/mapping-problem-diagram.png)


## Why is mapping a problem?
[Don’t we have all the information we need to build a map?]{.small-font}

-   If we had no uncertainty, i.e. $x_{t+1} = f(x_t, u_t)$ and $z_t = h(x_t)$ then mapping would be trivial.
-   Today we will assume perfect dynamics and odometry, but noisy sensor measurements. $p(z_t | x_t)$
-   We are also going to assume a static map, no moving objects


## Defining the problem

- The occupancy grid map is a binary random variable

$$m = {m_{ij} \in {0, 1}^{W \times H}}$$

[![](img/left-arrow.png) width = #columns \
height = #rows \
of the occupancy grid]{.red-annotation .absolute right=50 top=200}


- The path of the robot up to time t is a sequence of random variables $x_{1:t} = x_1, . . ., x_t$ with $x_i = (x_i, y_i, \theta_i)$

[Odometry coordinates ]{.red-annotation .absolute bottom=50% right=50%}


- At each time step the robot makes a measurement (sonar/laser). Measurements up to time t are a sequence of random variables $z_{1:t} = z_1, . . ., z_t$ with $z_i = {(r_i, \psi_i)}^K$

[![](img/left-arrow.png) K = #beams, or \ 
#points in the scan]{.red-annotation .absolute right=50 bottom=150}

[(range, angle) in \
the laser’s local \
coordinates ]{.red-annotation .absolute bottom=100 left="50%"}


## The goal of mapping

- To estimate the probability of any map, given path and measurements 

$$
belief_{t}(m) = p(m|z_{1:t}, x_{1:t})
$$

:::{.red-annotation .absolute right=250 bottom="60%"}
![](img/up-arrow.png){width="70"} \
Sensor \
Measurements
:::

:::{.red-annotation .absolute right=180 bottom="65%"}
![](img/uparrow2.png){width="70"}
Odometry / Robot Poses
:::

## The goal of mapping
- To estimate the probability of any map, given path and measurements

$$
p(m|z_{1:t}, x_{1:t})
$$

- This is intractable. E.g. for a 100 x 100 grid there are $2^{1000}$ possible binary maps.


- We can approximate $p(m|z_{1:t}, x_{1:t}) \simeq \prod_{i,j}p(m_{ij} | z_{1:t}, x_{1:t}) $

[Approximation ignores all dependencies \
between map cells, given known info. \
Assumes (for tractability) that cells are \
independent given path and measurements ]{.red-annotation .absolute bottom=20 right=200}

## Why is it an approximation?

![](img/Lecture6_224.png){fig-align="center"}

:::{layout-ncol="4" .red-annotation}
Scenario

Nearby \
measurements

Resulting map when \
considering cells \
independently

Resulting map when \
considering cells \
jointly
:::

## Evaluating the occupancy of a map cell

- How do we evaluate $p(m_{ij} = 1 | z_{1:t}, x_{1:t})$ ?

<!-- . . . -->

::: {.columns}
::: {.column width="70%"}
<!-- .fragment -->
- Using conditional Bayes’ rule we get

$p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) = \frac{p(z_t|z_{1:t-1}, x_{1:t}, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t})}{p(z_t|z_{1:t-1}, x_{1:t})}$

:::
::: {.column width="30%" .bordered-box}
Bayes’ Rule

$p(A|B) = \frac{p(B|A)p(A)}{p(B)}$

Conditional Bayes’ Rule

$p(A|B, C) = \frac{p(B|A, C)p(A|C)}{p(B|C)}$
:::
:::

## Evaluating the occupancy of a map cell

- How do we evaluate $p(m_{ij} = 1 | z_{1:t}, x_{1:t})$ ?

- Using conditional Bayes’ rule we get

::: {.columns}
::: {.column width="70%"}

$p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) = \frac{p(z_t|z_{1:t-1}, x_{1:t}, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t})}{p(z_t|z_{1:t-1}, x_{1:t})}$

- And we simplify

$$p(m_{ij} = 1|z_{1:t}, x_{1:t}) = \frac{p(z_t|x_t, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t-1})}{p(z_t|z_{1:t-1}, x_{1:t})}$$

:::
::: {.column width="30%" .bordered-box}

If C is independent of A \
given B, then C provides \
no extra information \
about A after we know B \
$p(A|B, C) = p(A | B)$
:::
:::


![](img/red-blue-arrows.png){width="50%" .absolute bottom=10% left="300"}


## Evaluating the occupancy of a map cell

- How do we evaluate $p(m_{ij} = 1 | z_{1:t}, x_{1:t})$ ?

- Using conditional Bayes’ rule we get

$p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) = \frac{p(z_t|z_{1:t-1}, x_{1:t}, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t})}{p(z_t|z_{1:t-1}, x_{1:t})}$

- And we simplify

$$p(m_{ij} = 1|z_{1:t}, x_{1:t}) = \frac{p(z_t|x_t, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t-1})}{p(z_t|z_{1:t-1}, x_{1:t})}$$


![](img/red-blue-arrows.png){width="50%" .absolute bottom=10% left="300"}

[Current measurement \
only depends on current \
state and map cell ]{.red-annotation .absolute bottom="25%" right="35%"}

[Current state without \
current measurement provides \
no additional information \
about the occupancy of the map cell]{.blue .small-font .absolute bottom="25%" right="15%"}


## Evaluating the occupancy of a map cell

- And we simplify:

$p(m_{ij} = 1|z_{1:t}, x_{1:t}) = \frac{p(z_t|x_t, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t-1})}{p(z_t|z_{1:t-1}, x_{1:t})}$

- Another way to write this:

$belief_t(m_{ij} = 1) = \eta \, p(z_t|x_t, m_{ij} = 1) \, belief_{t-1}(m_{ij} = 1)$

- Belief at time t-1 was updated to belief at time t based on likelihood of measurement received at time t.

## Evaluating the occupancy of a map cell

- And we simplify:

$p(m_{ij} = 1|z_{1:t}, x_{1:t}) = \frac{p(z_t|x_t, m_{ij} = 1)p(m_{ij} = 1|z_{1:t-1}, x_{1:t-1})}{p(z_t|z_{1:t-1}, x_{1:t})}$

::: {.columns}
::: {.column width="70%"}
- Another way to write this:

$belief_t(m_{ij} = 1) = \eta \, p(z_t|x_t, m_{ij} = 1) \, belief_{t-1}(m_{ij} = 1)$
:::

::: {.column width="30%" .red-annotation}
So, as long as we can evaluate
the measurement likelihood
$\color{black}p(z_t | x_t, m_{ij} = 1)$

and the normalization factor
$\color{black}\eta = 1/p(z_t | z_{1: t-1}, x_{1:t})$

we can do the belief update.
:::
::: 

:::{.blue .small-font .absolute bottom=80 right=200}
<!-- .fragment -->
![](img/blue-arrow.png){width=100} \
Problem: this is hard to \
compute. How can we avoid it?
:::

## The log-odds trick for binary random variables

- We showed $belief_t(m_{ij} = 1) = \eta p(\mathbf{z_t}|\mathbf{x_t}, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)$ (1)

- Define the log odds ratio $l_t^{(ij)} = \log \frac{p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})}{p(m_{ij} = 0|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})} = \log \frac{belief_t(m_{ij} = 1)}{belief_t(m_{ij} = 0)}$

. . .

- Then (1) becomes $l_t^{(ij)} = \log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}$

. . .

- We can recover the original belief as 

$\text{belief}_t(m_{ij} = 1) = 1 - \frac{1}{1 + \exp(l_t^{(ij)})}$


## The log-odds trick for binary random variables

- We showed $belief_t(m_{ij} = 1) = \eta p(\mathbf{z_t}|\mathbf{x_t}, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)$ (1)

- Define the log odds ratio $l_t^{(ij)} = \log \frac{p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})}{p(m_{ij} = 0|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})} = \log \frac{belief_t(m_{ij} = 1)}{belief_t(m_{ij} = 0)}$

- Then (1) becomes $l_t^{(ij)} = \log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}$

:::{.red-annotation .center-align}
So, as long as we can evaluate \
the log odds ratio for the measurement likelihood: \
$\color{black}\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)}$ \
we can do the belief update.
:::


## Log-odds ratio for the measurement likelihood

- We want to compute $\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)}$ to do the belief update

- We apply conditional Bayes’ rule again: $p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1) = \frac{p(m_{ij} = 1 | \mathbf{z}_t, \mathbf{x}_t) p(\mathbf{z}_t | \mathbf{x}_t)}{p(m_{ij} = 1 | \mathbf{x}_t)}$

. . .

- If we take the log-odds ratio: $\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} = \log\frac{p(m_{ij}=1|\mathbf{z}_{t},\mathbf{x}_{t})}{p(m_{ij}=0|\mathbf{z}_{t},\mathbf{x}_{t})}+\log\frac{p(m_{ij}=0|\mathbf{x}_{t})}{p(m_{ij}=1|\mathbf{x}_{t})}$

. . .

<br> 

- We can simplify further: $\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} = \log\frac{p(m_{ij}=1|\mathbf{z}_{t},\mathbf{x}_{t})}{p(m_{ij}=0|\mathbf{z}_{t},\mathbf{x}_{t})}+\log\frac{p(m_{ij}=0)}{p(m_{ij}=1)}$


[Knowing the current state provides no 
information about whether cell is 
occupied, if there are no observations]{.red-annotation .absolte right=100 bottom=20%}

![](img/arrow2.png){height=100 .absolute right=80 bottom=250}


[Prior probability of cell being occupied. \
Can choose uniform distribution, for example.]{.red-annotation .absolte right=100 bottom=20%}

![](img/red-arrow3.png){width="60" .absolte right=70 bottom=140}

[Inverse measurement model: \
what is the likelihood of the map \
cell being occupied given the current \
state and current measurement?]{.red-annotation .absolte right=400 bottom=30%}

![](img/arrow-circle.png){width="160" .absolte right=100 bottom=340}



## Summary: Log-odds ratio for the measurement likelihood

- We want to compute $\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)}$ but it’s hard

- Instead, we can compute the log-odds ratio of the measurement likelihood in terms of the inverse measurement model:

$$\log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} = \log\frac{p(m_{ij}=1|\mathbf{z}_{t},\mathbf{x}_{t})}{p(m_{ij}=0|\mathbf{z}_{t},\mathbf{x}_{t})}+\log\frac{p(m_{ij}=0)}{p(m_{ij}=1)}$$

![](img/summary.png){.absolute bottom="40%" right=200}


## Inverse sensor measurement model

::: {.columns}
::: {.column width="30%"}
![$p(m_{ij} = 1 | z_t, x_t)$](img/inverse-sensor.png)
:::

::: {.column width="70%"}
Given map cell $(i, j)$ , the robot’s state $x = (x, y, \theta)$, and beams $z = {(r_k, \psi_k)}$

Find index k of sensor beam that is closest in heading to the cell $(i,j)$

:::{.fragment fragment-index=2}
If the cell $(i, j)$ is sufficiently farther than $r_k$ or out of the field of view

[// We don’t have enough information to decide whether cell is occupied]{.small-font}

Return prior occupation probability $p(m_{ij} = 1)$
:::


:::{.fragment fragment-index=3}
If the cell $(i, j)$ is nearly as far as the measurement $r_k$

[// Cell is most likely occupied]{.small-font}

Return $p_{\text{occupied}}$ that is well above 0.5
:::


:::{.fragment fragment-index=1}
If the cell $(i, j)$ is sufficiently closer than $r_k$ \
[// Cell is most likely free]{.small-font}
Return $p_{\text{occupied}}$ that is well below 0.5
:::

:::
::: 


## inverse_sensor_measurement_model($(i,j), \mathbf{x} = (x, y, \theta), \mathbf{z} = \{(r_k, \psi_k)\}$)
[From Probabilistic Robotics, chapter 9.2]{.small-font}

-   Let $(x_i, y_i)$ be the center of the cell $(i, j)$
-   Let $r = \|(x_i, y_i) - (x, y)\|$
-   Let $\phi = \operatorname{atan2}(y_i - y, x_i - x) - \theta$ // Might need to ensure this angle difference is in $[-\pi, \pi]$
-   The index of the closest-in-heading beam to $(x_i, y_i)$ is $k^* = \mathbf{\operatorname*{argmin}_{k}\left|\phi - \psi_{k}\right|}$
-   If $r > \min\{r_{\max}, r_k + \alpha/2\}$ or $|\phi - \psi_k| > \beta/2$
    -   Return the log odds ratio of the prior occupancy $\log \frac{p(m_{ij}=1)}{p(m_{ij}=0)}$
-   If $r_k < r_{\max}$ and $|r - r_k| < \alpha/2$
    -   Return the log odds ratio of being occupied (corresponding to occupation probability \> 0.5)
-   If $r \le r_k$
    -   Return the log odds ratio of being free (corresponding to occupation probability \< 0.5)


## Recap

- We wanted to compute the likelihood of any map based on known states and observations

$$p(\mathbf{m}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) \simeq \prod_{i,j} p(m_{ij}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})$$

## Recap

- We wanted to compute the likelihood of any map based on known path and observations

$$p(\mathbf{m}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) \simeq \prod_{i,j} p(m_{ij}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})$$

- To evaluate $p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) = \text{belief}_t(m_{ij} = 1)$ we had to apply Bayes’ theorem, which revealed a way to recursively update the belief

$$belief_t(m_{ij} = 1) = \eta p(\mathbf{z}_t|\mathbf{x}_t, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)$$

[Very frequent \
reasoning in \ 
probabilistic \
robotics]{.red-annotation .absolute right=0 bottom=50 .fragment .fade-out}

:::{.fragment}
- To avoid evaluating $\eta$ we used the log odds ratio 

$$l_t^{(ij)} = \log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}$$

[Can do this for binary \
random variables]{.red-annotation .absolute right=0 bottom=30%}
:::

## Recap

- We wanted to compute the likelihood of any map based on known path and observations

$$p(\mathbf{m}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) \simeq \prod_{i,j} p(m_{ij}|\mathbf{z}_{1:t}, \mathbf{x}_{1:t})$$

- To evaluate $p(m_{ij} = 1|\mathbf{z}_{1:t}, \mathbf{x}_{1:t}) = \text{belief}_t(m_{ij} = 1)$ we had to apply Bayes’ theorem, which revealed a way to recursively update the belief

$$belief_t(m_{ij} = 1) = \eta p(\mathbf{z}_t|\mathbf{x}_t, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)$$

- To avoid evaluating $\eta$ we used the log odds ratio 

$$l_t^{(ij)} = \log \frac{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 1)}{p(\mathbf{z}_t | \mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}$$


- Computing the forward measurement model $p(\mathbf{z}_{t}|\mathbf{x}_{t}, m_{ij}=1)$ was hard, so we applied Bayes’ rule again, to get an inverse measurement model $p(m_{ij}=1|\mathbf{z}_t, \mathbf{x}_t)$ and an easier-to-compute log-odds ratio:

$$l_{t}^{(ij)}=l_{t-1}^{(ij)}+\log\frac{p(m_{ij}=1|\mathbf{z}_{t},\mathbf{x}_{t})}{p(m_{ij}=0|\mathbf{z}_{t},\mathbf{x}_{t})}-\log\frac{p(m_{ij}=1)}{p(m_{ij}=0)}$$

## Occupancy Grid Algorithm

- Upon reception of a new laser/sonar/scan measurement $\mathbf{z}_t = \{(r_k, \psi_k)\}$

- Let the robot’s current state be $\mathbf{x}_t = (x_t, y_t, \theta_t)$

- Let the previous log-odds ratio of the occupancy belief be the 2D array $l_{t}^{(ij)}$ where i is a row, j is a column 

    In the beginning we set the prior $l_{0}^{(ij)}=\log\frac{p(m_{ij}=1)}{p(m_{ij}=0)}$ where the occupancy probability is a design decision.

. . .

-   For all cells (i,j) in the grid
    -   If the cell (i,j) is in the field of view of the robot’s sensor at state $\mathbf{x}_t$ $$l_t^{(ij)} = _{t-1}^{(ij)} + \text{inverse-sensor-measurement-model}((i,j), \mathbf{x}_t, \mathbf{z}_t) - l_0^{(ij)}$$

    -   Else $$l_{t}^{(ij)} = l_{t-1}^{(ij)}$$
-   If asked, return the following 2D matrix of occupancy probabilities:
    $$\text{belief}_t(m_{ij} = 1) = 1 - \frac{1}{1 + \exp(l_t^{(ij)})}$$


## Results
![](img/results-diagram.png)

The maximum likelihood map is obtained by clipping the occupancy grid map at a threshold of 0.5

##

![](img/Lecture6_373.png){fig-align="center"}