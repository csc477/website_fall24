[
  {
    "objectID": "course-grading.html",
    "href": "course-grading.html",
    "title": "Grading Scheme",
    "section": "",
    "text": "Assignment 1\n15%\n\n\nAssignment 2\n15%\n\n\nPanel Discussion\n10%\n\n\nProject Proposal\n10%\n\n\nProject Presentation\n25%\n\n\nFinal Project Report\n25%\n\n\n\n\nMarking rubric for panel discussion\nEvery week we will reserve 20-30 mins for a panel discussion based on the assigned reading for that day (4-5 papers). This discussion will include three types of roles: panel members, audience members, and a moderator. Each panel discussion will include 4 panel members, 1 moderator, and audience members. Panel members are responsible for answering questions, the audience is responsible for asking questions, and the moderator is responsible for steering the discussion and having backup questions if the audience is not asking any.\n\nPanel member evaluation\n\nAnswering questions from the moderator and the audience correctly / well (6 pts)\nEngaging with points of other panelists (1 pts)\nKeeping answers brief / allowing other people time to speak (2 pts)\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (1 pts)\n\n\n\nAudience member evaluation\n\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (10 pts)\n\n\n\nModerator evaluation\n\nSteering the discussion in terms of groups / themes of questions (2 pts)\nEnsuring there is time for every panel member to speak (4 pts)\nEngaging the audience / ensuring the audience has enough time to ask questions (3 pts)\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (1 pts)\n\n\n\n\nMarking rubric for the project proposal\n\nIntroduction (1 pts), which states the proposed problem being solved and any applications / implications.\nFigure or diagram (1 pts), showing an overview of your proposed solution, i.e. shows the overall idea in a way that is easily understandable without even reading the rest of the report.\nRelated work (1 pts) and bibliography. Highlight how your method is different from other approaches. Present other approaches in the proper light without diminishing their contributions.\nMethodology (2 pts). Describe your proposed methodology as well as any assumptions it relies on. Explain prerequisite concepts clearly and succinctly.\nEvaluation (2 pts). What experiments are you planning to do and why? What are the questions you want to answer through these experiments?\nTimeline (1 pts). What are the milestones required to complete your project and by when do you plan to complete them?\nAnticipated risks and mitigation plan (2 pts). What issues might arise with your proposed project and timeline and how will you address these issues if they occur?\n\n\n\nMarking rubric for the project presentation\n\nQuality of presentation\n\nSlide design (2 pts)\nDelivery of presentation (3 pts)\nRespecting time constraints (2 pts)\nResponse to questions (3 pts)\n\n\n\nTechnical content\n\nMotivation and definition of the problem (2 pts)\nPutting prior work into context (3 pts)\nMethodology explanation (3 pts)\nDiscussion of experiments (5 pts)\nDiscussion of limitations (2 pts)\n\n\n\n\nMarking rubric for the final project report\n\nAbstract (2 pts) that summarizes the main idea of the project and your contributions.\nIntroduction (3 pts) that states the problem being solved and any applications / implications.\nFigure or diagram (2 pts) that shows the overall idea in a way that is easily understandable.\nRelated work (2 pts) and bibliography. Highlight how your method is different from other approaches. Present other approaches in the proper light without diminishing their contributions.\nMethodology (7 pts). Describe your method in detail as well as any assumptions it relies on. Explain prerequisite concepts clearly and succinctly. Include algorithm descriptions, figures, and equations as you wish.\nEvaluation (8 pts). Include any figures or tables that illustrate your experimental results. Do not forget to include error bars if applicable. Analyze your findings, and comment on their statistical significance. In your evaluation please take into account Joelle Pineau’s ML reproducibility checklist.\nLimitations (2 pts). Describe some settings in which your approach performs poorly, and list a few ideas for how to adddress them. Describe opportunities for future work, as well as open problems.\nConclusions (1 pts). A summary of your contributions and results."
  },
  {
    "objectID": "lecs/w06/lec06.html#todays-agenda",
    "href": "lecs/w06/lec06.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\nHow to represent maps\nProbabilistic occupancy grid mapping"
  },
  {
    "objectID": "lecs/w06/lec06.html#categories-of-maps",
    "href": "lecs/w06/lec06.html#categories-of-maps",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Categories of maps",
    "text": "Categories of maps\n\nMetric\n\nMap accurately represents lengths and angles\n\nTopological\n\nMap is reduced to a graph representation of the structure of free space\n\nTopometric\n\nAtlas: a combination of local metric maps (nodes) connected via edges\n\nSequence of raw time-series observations (e.g. video)\n\nNo metric or topological information directly represented by the map"
  },
  {
    "objectID": "lecs/w06/lec06.html#typical-operations-on-maps",
    "href": "lecs/w06/lec06.html#typical-operations-on-maps",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Typical operations on maps",
    "text": "Typical operations on maps\n\nDistance and direction to closest obstacle\nCollision detection: is a given robot configuration in free space?\nMap merging / alignment\nOccupancy updates\nRaytracing\n\n\n\nCommon operations in\ncomputer graphics"
  },
  {
    "objectID": "lecs/w06/lec06.html#metric-maps",
    "href": "lecs/w06/lec06.html#metric-maps",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Metric Maps",
    "text": "Metric Maps"
  },
  {
    "objectID": "lecs/w06/lec06.html#occupancy-grids",
    "href": "lecs/w06/lec06.html#occupancy-grids",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Occupancy Grids",
    "text": "Occupancy Grids\n\n\n\n\n\n\n\n\n\nAdvantages:\n• O(1) occupancy lookup and update\n• Supports image operations\nDisadvantages:\n• Doesn’t scale well in higher dimensions\n\n\nEach cell contains either:\n\nunknown/unexplored (grey)\nprobability of occupation"
  },
  {
    "objectID": "lecs/w06/lec06.html#quadtrees",
    "href": "lecs/w06/lec06.html#quadtrees",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quadtrees",
    "text": "Quadtrees\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach node represents a square. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has four children. Subdivision stops after some minimal square size."
  },
  {
    "objectID": "lecs/w06/lec06.html#octrees",
    "href": "lecs/w06/lec06.html#octrees",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Octrees",
    "text": "Octrees\n\n\n\n\n\n\n \n\n\n\n\n\n\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size."
  },
  {
    "objectID": "lecs/w06/lec06.html#octrees-1",
    "href": "lecs/w06/lec06.html#octrees-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Octrees",
    "text": "Octrees\n\n\n\n\n\n\nProblem 1: quadtrees and octrees are not balanced trees. So, in the worst case an occupancy query could be O(n) in the number of nodes.\n\n\n\n\n\n\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size."
  },
  {
    "objectID": "lecs/w06/lec06.html#octrees-2",
    "href": "lecs/w06/lec06.html#octrees-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Octrees",
    "text": "Octrees\n\n\n\n\nProblem 1: quadtrees and octrees are not balanced trees. So, in the worst case an occupancy query could be O(n) in the number of nodes.\nProblem 2: quadtrees and octrees are sensitive to small changes in the location of obstacles.\n\n\n\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size."
  },
  {
    "objectID": "lecs/w06/lec06.html#octree-example-octomap",
    "href": "lecs/w06/lec06.html#octree-example-octomap",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Octree Example: Octomap",
    "text": "Octree Example: Octomap\n\nOpen source as a ROS package"
  },
  {
    "objectID": "lecs/w06/lec06.html#implicit-surface-definitions-signed-distance-function",
    "href": "lecs/w06/lec06.html#implicit-surface-definitions-signed-distance-function",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Implicit Surface Definitions: Signed Distance Function",
    "text": "Implicit Surface Definitions: Signed Distance Function\n\n\n\n\n\nThis distance function\nis defined over any point\nin 3D space."
  },
  {
    "objectID": "lecs/w06/lec06.html#sdf-example",
    "href": "lecs/w06/lec06.html#sdf-example",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SDF Example",
    "text": "SDF Example"
  },
  {
    "objectID": "lecs/w06/lec06.html#pointclouds",
    "href": "lecs/w06/lec06.html#pointclouds",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Pointclouds",
    "text": "Pointclouds"
  },
  {
    "objectID": "lecs/w06/lec06.html#pointclouds-1",
    "href": "lecs/w06/lec06.html#pointclouds-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Pointclouds",
    "text": "Pointclouds\n\n\n\nAdvantages:\n\ncan make local changes to the map without affecting the pointcloud globally\ncan align pointclouds\nnearest neighbor queries are easy with kd-trees or locality-sensitive hashing\n\n\n\nDisadvantages:\n\nneed to segment objects in the map\nraytracing is approximate and nontrivial"
  },
  {
    "objectID": "lecs/w06/lec06.html#topological-maps",
    "href": "lecs/w06/lec06.html#topological-maps",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Topological Maps",
    "text": "Topological Maps\nTopology: study of spatial properties that are preserved under continuous deformations of the space."
  },
  {
    "objectID": "lecs/w06/lec06.html#generalized-voronoi-graph-gvg",
    "href": "lecs/w06/lec06.html#generalized-voronoi-graph-gvg",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Generalized Voronoi Graph (GVG)",
    "text": "Generalized Voronoi Graph (GVG)"
  },
  {
    "objectID": "lecs/w06/lec06.html#deformation-retraction-gvg-in-plane",
    "href": "lecs/w06/lec06.html#deformation-retraction-gvg-in-plane",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Deformation Retraction: GVG in Plane",
    "text": "Deformation Retraction: GVG in Plane\n\\(\\qquad\\qquad\\quad\\) GVG nodes: points that are equidistant to 3 or more obstacle points\n\nRetractions are\nalso called\nroadmaps."
  },
  {
    "objectID": "lecs/w06/lec06.html#roadmap-voronoi-diagrams",
    "href": "lecs/w06/lec06.html#roadmap-voronoi-diagrams",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Roadmap: Voronoi diagrams",
    "text": "Roadmap: Voronoi diagrams\n\n\n\nGVG is formed by paths equidistant from the two closest objects\nmaximizing the clearance between the obstacles.\n\n\n\n\n\nThis generates a very safe roadmap which avoids obstacles as much as possible"
  },
  {
    "objectID": "lecs/w06/lec06.html#generalized-voronoi-graphs-gvg",
    "href": "lecs/w06/lec06.html#generalized-voronoi-graphs-gvg",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Generalized Voronoi Graphs (GVG)",
    "text": "Generalized Voronoi Graphs (GVG)\n\nTurns comparison between pixels to comparison between graphs."
  },
  {
    "objectID": "lecs/w06/lec06.html#gvg-sensitivity",
    "href": "lecs/w06/lec06.html#gvg-sensitivity",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GVG: sensitivity",
    "text": "GVG: sensitivity\n\nThe skeleton is sensitive to small changes in the object’s boundary."
  },
  {
    "objectID": "lecs/w06/lec06.html#gvg-advantages",
    "href": "lecs/w06/lec06.html#gvg-advantages",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GVG: advantages",
    "text": "GVG: advantages\n\nCan specify whether we pass on the “left” or “right” of each obstacle\non our way to the goal."
  },
  {
    "objectID": "lecs/w06/lec06.html#gvg-advantages-1",
    "href": "lecs/w06/lec06.html#gvg-advantages-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GVG: advantages",
    "text": "GVG: advantages"
  },
  {
    "objectID": "lecs/w06/lec06.html#how-a-curve-winds-around-an-obstacle",
    "href": "lecs/w06/lec06.html#how-a-curve-winds-around-an-obstacle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How a curve winds around an obstacle",
    "text": "How a curve winds around an obstacle\n\n\nNote: winding angle of a path\ncan be more than 360 degrees"
  },
  {
    "objectID": "lecs/w06/lec06.html#homotopy-classes",
    "href": "lecs/w06/lec06.html#homotopy-classes",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Homotopy classes",
    "text": "Homotopy classes\n\n\nTwo paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:\n\n\n\nwith\n\n\n\\[\n\\begin{align}\n\\tau_1 : [0, T] &\\to \\mathbb{R}^2 \\\\\n\\tau_2 : [0, T] &\\to \\mathbb{R}^2 \\\\\n\\tau_1(0) &= \\tau_2(0) \\\\\n\\tau_1(T) &= \\tau_2(T)\n\\end{align}\n\\]\n\n\n\nare homotopic iff there exists a continuous function\n\\[H : [0, 1] \\times [0, T] \\to \\mathbb{R}^2\\]\nsuch that for any time t:\n\\[\n\\begin{align}\nH(0, t) &= \\tau_1(t) \\\\\nH(1, t) &= \\tau_2(t)\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#homotopy-functions-for-deformations",
    "href": "lecs/w06/lec06.html#homotopy-functions-for-deformations",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Homotopy functions for deformations",
    "text": "Homotopy functions for deformations\n\n\nTwo paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:\n\n\n\nwith\n\n\n\\[\n\\begin{align}\n\\tau_1 : [0, T] &\\to \\mathbb{R}^2 \\\\\n\\tau_2 : [0, T] &\\to \\mathbb{R}^2 \\\\\n\\tau_1(0) &= \\tau_2(0) \\\\\n\\tau_1(T) &= \\tau_2(T)\n\\end{align}\n\\]\n\n\n\nare homotopic iff there exists a continuous function\n\\[H : [0, 1] \\times [0, T] \\to \\mathbb{R}^2\\]\nsuch that for any time t:\n\\[\n\\begin{align}\nH(0, t) &= \\tau_1(t) \\\\\nH(1, t) &= \\tau_2(t)\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#topometric-maps",
    "href": "lecs/w06/lec06.html#topometric-maps",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Topometric maps",
    "text": "Topometric maps"
  },
  {
    "objectID": "lecs/w06/lec06.html#topometric-maps-1",
    "href": "lecs/w06/lec06.html#topometric-maps-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Topometric maps",
    "text": "Topometric maps\n\n\n\n\nOccupancy grid\n\n\nTopological map\n\n\nTopometric map"
  },
  {
    "objectID": "lecs/w06/lec06.html#topometric-maps-2",
    "href": "lecs/w06/lec06.html#topometric-maps-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Topometric maps",
    "text": "Topometric maps\nEdges: rotations and\ntranslations between\nlocal maps, but also topological\nconnectivity\n\n\n\n\n\nMain advantage:\nallows us combine accurate local\nmaps into a global, typically\ninconsistent map that nevertheless\nprovides sufficient navigation information."
  },
  {
    "objectID": "lecs/w06/lec06.html#maps-of-raw-observations",
    "href": "lecs/w06/lec06.html#maps-of-raw-observations",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maps of Raw Observations",
    "text": "Maps of Raw Observations"
  },
  {
    "objectID": "lecs/w06/lec06.html#main-idea",
    "href": "lecs/w06/lec06.html#main-idea",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main Idea",
    "text": "Main Idea\n\nMap = entire (unprocessed) sequence of observations, e.g. video.\nDo not try to support distance, collision, and raytracing queries.\nInstead, provide only a similarity/nearest neighbors query\n\n“Find the image in the video that is most similar to the one I’m seeing now.”\n\nHistory of observations determines a (set of) location(s) in the map"
  },
  {
    "objectID": "lecs/w06/lec06.html#metric-map-alignment",
    "href": "lecs/w06/lec06.html#metric-map-alignment",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Metric Map Alignment",
    "text": "Metric Map Alignment\na.k.a. scan matching, a.k.a. iterative closest point (ICP), a.k.a. registration"
  },
  {
    "objectID": "lecs/w06/lec06.html#problem-definition",
    "href": "lecs/w06/lec06.html#problem-definition",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Problem definition",
    "text": "Problem definition\n\n\n\nGiven\n\ntwo pointclouds or\na (local) laser scan and a pointcloud (global map) or\ntwo maps\n\nfind the rotation and translation that aligns them\n\n\n\n\n\n\nAssumption: We are assuming in these slides for simplicity that that rigid-body transformations are sufficient to align the scans. They might not be. We might need to also model scaling, non-uniform stretching and other nonlinear transformations."
  },
  {
    "objectID": "lecs/w06/lec06.html#scan-alignment-with-known-correspondences",
    "href": "lecs/w06/lec06.html#scan-alignment-with-known-correspondences",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Scan alignment with known correspondences",
    "text": "Scan alignment with known correspondences\nIf the correct correspondences are known, the correct relative rotation/translation can be calculated in closed form.\n\n\nWhen correct correspondences\nare known we say that data\nassociation is known/unambiguous.\nIn general, data association is a real\nand hairy problem in robotics."
  },
  {
    "objectID": "lecs/w06/lec06.html#scan-alignment-with-known-correspondences-1",
    "href": "lecs/w06/lec06.html#scan-alignment-with-known-correspondences-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Scan alignment with known correspondences",
    "text": "Scan alignment with known correspondences\n\n\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\n\\[\n\\text{error}(R, t) = \\frac{1}{N} \\sum_{i=1}^{N} ||p_i - (Rq_i + t)||^2\n\\]\n\\[\nR^*, t^* = \\operatorname*{argmin}_{R,t} \\text{error}(R, t)\n\\]\n\nQ: How do we minimize this error?\nA: Turns out it has a closed-form solution."
  },
  {
    "objectID": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences",
    "href": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Closed form solution of scan alignment with known correspondences",
    "text": "Closed form solution of scan alignment with known correspondences\n\n\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\n\\[\n\\text{error}(R, t) = \\frac{1}{N} \\sum_{i=1}^{N} ||p_i - (Rq_i + t)||^2\n\\]\n\\[\nR^*, t^* = \\operatorname*{argmin}_{R,t} \\text{error}(R, t)\n\\]\nStep 1: compute the means of the two scans\n\\[\n\\mu_p = \\frac{1}{N} \\sum_{i=1}^{N} p_i \\qquad\\qquad \\mu_q = \\frac{1}{N} \\sum_{i=1}^{N} q_i\n\\]\nStep 2: subtract the means from the scans\n\\(\\qquad \\bar{p}_i = p_i - \\mu_p \\qquad\\qquad \\bar{q}_i = q_i - \\mu_q\\)\nStep 3: form the matrix\n\\[W = \\sum_{i=1}^{N} \\bar{p}_i \\bar{q}_i^T\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences-1",
    "href": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Closed form solution of scan alignment with known correspondences",
    "text": "Closed form solution of scan alignment with known correspondences\n\n\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\n\\[\n\\text{error}(R, t) = \\frac{1}{N} \\sum_{i=1}^{N} ||\\mathbf{p}_i - (R\\mathbf{q}_i + t)||^2\n\\]\n\\[\nR^*, t^* = \\operatorname*{argmin}_{R,t} \\text{error}(R, t)\n\\]\nStep 1: compute the means of the two scans\n\\[\n\\mu_p = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{p}_i \\qquad\\qquad \\mu_q = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{q}_i\n\\]\nStep 2: subtract the means from the scans\n\\(\\qquad \\bar{\\mathbf{p}}_i = \\mathbf{p}_i - \\mu_p \\qquad\\qquad \\bar{\\mathbf{q}}_i = \\mathbf{q}_i - \\mu_q\\)\nStep 3: form the matrix\n\\[W = \\sum_{i=1}^{N} \\bar{\\mathbf{p}}_i \\bar{\\mathbf{q}}_i^T\\]\n\n\nStep 4: compute the SVD of the matrix W\n\\(\\qquad W = U\\Sigma V^T\\)\nStep 5: if rank(W)=3, optimal solution is unique:\n\\(\\qquad R^* = UV^T \\qquad\\qquad t^* = \\mu_p - R^* \\mu_q\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences-2",
    "href": "lecs/w06/lec06.html#closed-form-solution-of-scan-alignment-with-known-correspondences-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Closed form solution of scan alignment with known correspondences",
    "text": "Closed form solution of scan alignment with known correspondences\n\n\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\n\\[\n\\text{error}(R, t) = \\frac{1}{N} \\sum_{i=1}^{N} ||p_i - (Rp_i + t)||^2\n\\]\n\\[\nR^*, t^* = \\operatorname*{argmin}_{R,t} \\text{error}(R, t)\n\\]\n\nIf you’re interested, the proof of the closed-form solution can be found in:\nK. S. Arun, T. S. Huang, and S. D. Blostein. Least square fitting of two 3-d point sets.\nIEEE Transactions on Pattern Analysis and Machine Intelligence, 9(5):698 – 700, 1987"
  },
  {
    "objectID": "lecs/w06/lec06.html#scan-alignment-with-unknown-correspondences",
    "href": "lecs/w06/lec06.html#scan-alignment-with-unknown-correspondences",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Scan alignment with unknown correspondences",
    "text": "Scan alignment with unknown correspondences\nIf correct correspondences are not known, it is generally impossible to determine the optimal relative rotation/ translation in one step"
  },
  {
    "objectID": "lecs/w06/lec06.html#scan-alignment-with-unknown-correspondences-1",
    "href": "lecs/w06/lec06.html#scan-alignment-with-unknown-correspondences-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Scan alignment with unknown correspondences",
    "text": "Scan alignment with unknown correspondences\n\n\n\n\nMain idea for data association:\n\nassociate each point in the source scan to its nearest neighbor in the target scan\nFind optimal rotation and translation for this correspondence.\n\nRepeat until no significant drop in error."
  },
  {
    "objectID": "lecs/w06/lec06.html#libpointmatcher",
    "href": "lecs/w06/lec06.html#libpointmatcher",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "libpointmatcher",
    "text": "libpointmatcher"
  },
  {
    "objectID": "lecs/w06/lec06.html#todays-agenda-1",
    "href": "lecs/w06/lec06.html#todays-agenda-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\nHow to represent maps\nProbabilistic occupancy grid mapping"
  },
  {
    "objectID": "lecs/w06/lec06.html#what-we-want-to-do",
    "href": "lecs/w06/lec06.html#what-we-want-to-do",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What we want to do",
    "text": "What we want to do"
  },
  {
    "objectID": "lecs/w06/lec06.html#terminology",
    "href": "lecs/w06/lec06.html#terminology",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Terminology",
    "text": "Terminology\n\nPose: the rotation and translation of a robot\nOdometry: the transformation of the body frame with respect to its initial pose (fixed frame of reference).\n\n\\[_{B_{t}}^{B_0}T\\]\n\nDynamics model: what is the next state given current state and control?\n\n\\[\nx_{t+1} = f(x_t, u_t)\n\\]\n\nSensor measurement model: what is the expected measurement given the robot’s current state?\n\n\\[z_t = h(x_t)\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#perfect-models-vs.-reality",
    "href": "lecs/w06/lec06.html#perfect-models-vs.-reality",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Perfect models vs. Reality",
    "text": "Perfect models vs. Reality\n\n\n\n\n \n\n\n\\(x_{t+1} = f(x_t, u_t)\\)\n\n\n\\(x_{t+1} = f(x_t, u_t) + w_t\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#perfect-models-vs.-reality-1",
    "href": "lecs/w06/lec06.html#perfect-models-vs.-reality-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Perfect models vs. Reality",
    "text": "Perfect models vs. Reality\n\n\n\nSensor\nMeasurements\n\n\n\\(z_t = h(x_t)\\)\n\n\n \n\n\n\n\n\ne.g. GPS (simplified)\n\n\\(z_t = x_t\\) \n\n\\(z_t = x_t + v_t, \\quad v_t \\sim \\mathcal{N}(0, \\sigma^2I)\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#perfect-models-vs.-reality-2",
    "href": "lecs/w06/lec06.html#perfect-models-vs.-reality-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Perfect models vs. Reality",
    "text": "Perfect models vs. Reality\n\n\nDynamics\n\nSensor Measurements\n\ne.g. GPS (simplified)\n\n\\(x_{t+1} = f(x_t, u_t)\\)\n\n\n\\(z_t = h(x_t)\\)\n\n\\(z_t = x_t\\) \n\n\n\n\n\\(p(x_{t+1} | x_t, u_t)\\)\nprobabilistic dynamics model\n\n\\(p(z_t| x_t)\\)\nprobabilistic measurement model"
  },
  {
    "objectID": "lecs/w06/lec06.html#why-is-mapping-a-problem",
    "href": "lecs/w06/lec06.html#why-is-mapping-a-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is mapping a problem?",
    "text": "Why is mapping a problem?\nDon’t we have all the information we need to build a map?\n\nTwo main sources of uncertainty:\n\naccumulating uncertainty in the dynamics\n\n\n\n\n\n\\(p(x_{t+1} | x_t, u_t)\\)\n\n\n\n\n\n\n\n\nUncertainty in the dynamics compounds into increasing uncertainty in odometry, as time passes."
  },
  {
    "objectID": "lecs/w06/lec06.html#why-is-mapping-a-problem-1",
    "href": "lecs/w06/lec06.html#why-is-mapping-a-problem-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is mapping a problem?",
    "text": "Why is mapping a problem?\nDon’t we have all the information we need to build a map?\n\nTwo main sources of uncertainty:\n\nuncertainty in the dynamics \\(p(x_{t+1} | x_t, u_t)\\)\nuncertainty in sensor measurements"
  },
  {
    "objectID": "lecs/w06/lec06.html#why-is-mapping-a-problem-2",
    "href": "lecs/w06/lec06.html#why-is-mapping-a-problem-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is mapping a problem?",
    "text": "Why is mapping a problem?\nDon’t we have all the information we need to build a map?\n\nIf we had no uncertainty, i.e. \\(x_{t+1} = f(x_t, u_t)\\) and \\(z_t = h(x_t)\\) then mapping would be trivial.\nToday we will assume perfect dynamics and odometry, but noisy sensor measurements. \\(p(z_t | x_t)\\)\nWe are also going to assume a static map, no moving objects"
  },
  {
    "objectID": "lecs/w06/lec06.html#defining-the-problem",
    "href": "lecs/w06/lec06.html#defining-the-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Defining the problem",
    "text": "Defining the problem\n\nThe occupancy grid map is a binary random variable\n\n\\[\\mathbf{m} = \\{m_{ij}\\} \\in \\{0,1\\}^{W \\times H}\\]\n\nwidth = #columns\nheight = #rows\nof the occupancy grid\n\n\nThe path of the robot up to time t is a sequence of random variables \\(\\mathbf{x}_{1:t} = \\mathbf{x}_1, . . ., \\mathbf{x}_t\\) with \\(\\mathbf{x}_i = (x_i, y_i, \\theta_i)\\)\n\nOdometry coordinates\n\n\n\nAt each time step the robot makes a measurement (sonar/laser). Measurements up to time t are a sequence of random variables\n\\(\\mathbf{z}_{1:t} = \\mathbf{z}_1, . . ., \\mathbf{z}_t\\) with \\(\\mathbf{z}_i = {(r_i, \\psi_i)}^K\\)\n\n K = #beams, or   #points in the scan\n(range, angle) in\nthe laser’s local\ncoordinates"
  },
  {
    "objectID": "lecs/w06/lec06.html#the-goal-of-mapping",
    "href": "lecs/w06/lec06.html#the-goal-of-mapping",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The goal of mapping",
    "text": "The goal of mapping\n\nTo estimate the probability of any map, given path and measurements\n\n\\[\nbelief_{t}(\\mathbf{m}) = p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\n\\]\n\n\nSensor\nMeasurements\n\n\n\nOdometry / Robot Poses"
  },
  {
    "objectID": "lecs/w06/lec06.html#the-goal-of-mapping-1",
    "href": "lecs/w06/lec06.html#the-goal-of-mapping-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The goal of mapping",
    "text": "The goal of mapping\n\nTo estimate the probability of any map, given path and measurements\n\n\\[\np(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\n\\]\n\nThis is intractable. E.g. for a 100 x 100 grid there are \\(2^{1000}\\) possible binary maps.\nWe can approximate \\[p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) \\simeq \\prod_{i,j} p(m_{ij} | \\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\]\n\nApproximation ignores all dependencies\nbetween map cells, given known info.\nAssumes (for tractability) that cells are\nindependent given path and measurements"
  },
  {
    "objectID": "lecs/w06/lec06.html#why-is-it-an-approximation",
    "href": "lecs/w06/lec06.html#why-is-it-an-approximation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is it an approximation?",
    "text": "Why is it an approximation?\n\n\n\n\n \n\n\nScenario\n\n\nNearby\nmeasurements\n\n\nResulting map when\nconsidering cells\nindependently\n\n\nResulting map when\nconsidering cells\njointly"
  },
  {
    "objectID": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell",
    "href": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Evaluating the occupancy of a map cell",
    "text": "Evaluating the occupancy of a map cell\n\nHow do we evaluate \\(p(m_{ij} = 1 | \\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\) ?\n\n\n\n\n\n\nUsing conditional Bayes’ rule we get\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t}, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\n\nBayes’ Rule\n\\(p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\\)\nConditional Bayes’ Rule\n\\(p(A|B, C) = \\frac{p(B|A, C)p(A|C)}{p(B|C)}\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-1",
    "href": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Evaluating the occupancy of a map cell",
    "text": "Evaluating the occupancy of a map cell\n\nHow do we evaluate \\(p(m_{ij} = 1 | z_{1:t}, x_{1:t})\\) ?\nUsing conditional Bayes’ rule we get\n\n\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t}, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\n\nAnd we simplify\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t-1})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\n\nIf C is independent of A\ngiven B, then C provides\nno extra information\nabout A after we know B\n\\(p(A|B, C) = p(A | B)\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-2",
    "href": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Evaluating the occupancy of a map cell",
    "text": "Evaluating the occupancy of a map cell\n\nHow do we evaluate \\(p(m_{ij} = 1 | z_{1:t}, x_{1:t})\\) ?\nUsing conditional Bayes’ rule we get\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t}, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\n\nAnd we simplify\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t-1})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\nCurrent measurement\nonly depends on current\nstate and map cell\nCurrent state without\ncurrent measurement provides\nno additional information\nabout the occupancy of the map cell"
  },
  {
    "objectID": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-3",
    "href": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Evaluating the occupancy of a map cell",
    "text": "Evaluating the occupancy of a map cell\n\nAnd we simplify:\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t-1})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\nAnother way to write this:\n\n\\(belief_t(m_{ij} = 1) = \\eta \\, p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1) \\, belief_{t-1}(m_{ij} = 1)\\)\n\nBelief at time t-1 was updated to belief at time t based on likelihood of measurement received at time t."
  },
  {
    "objectID": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-4",
    "href": "lecs/w06/lec06.html#evaluating-the-occupancy-of-a-map-cell-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Evaluating the occupancy of a map cell",
    "text": "Evaluating the occupancy of a map cell\n\nAnd we simplify:\n\n\\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\frac{p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1)p(m_{ij} = 1|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t-1})}{p(\\mathbf{z}_t|\\mathbf{z}_{1:t-1}, \\mathbf{x}_{1:t})}\\)\n\n\n\nAnother way to write this:\n\n\\(belief_t(m_{ij} = 1) = \\eta \\, p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1) \\, belief_{t-1}(m_{ij} = 1)\\)\n\nSo, as long as we can evaluate the measurement likelihood \\(\\color{black}p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)\\)\nand the normalization factor \\(\\color{black}\\eta = 1/p(\\mathbf{z}_t | \\mathbf{z}_{1: t-1}, \\mathbf{x}_{1:t})\\)\nwe can do the belief update.\n\n\n\nProblem: this is hard to\ncompute. How can we avoid it?"
  },
  {
    "objectID": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables",
    "href": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The log-odds trick for binary random variables",
    "text": "The log-odds trick for binary random variables\n\nWe showed \\(belief_t(m_{ij} = 1) = \\eta p(\\mathbf{z_t}|\\mathbf{x_t}, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)\\)\nDefine the log odds ratio \\(l_t^{(ij)} = \\log \\frac{p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})}{p(m_{ij} = 0|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})} = \\log \\frac{belief_t(m_{ij} = 1)}{belief_t(m_{ij} = 0)}\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables-1",
    "href": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The log-odds trick for binary random variables",
    "text": "The log-odds trick for binary random variables\n\nWe showed \\(belief_t(m_{ij} = 1) = \\eta p(\\mathbf{z_t}|\\mathbf{x_t}, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)\\) (1)\nDefine the log odds ratio \\(l_t^{(ij)} = \\log \\frac{p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})}{p(m_{ij} = 0|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})} = \\log \\frac{belief_t(m_{ij} = 1)}{belief_t(m_{ij} = 0)}\\)\n\n\n\nThen (1) becomes \\(l_t^{(ij)} = \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}\\)\n\n\n\n\nWe can recover the original belief as\n\n\\(belief_t(m_{ij} = 1) = 1 - \\frac{1}{1 + \\exp(l_t^{(ij)})}\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables-2",
    "href": "lecs/w06/lec06.html#the-log-odds-trick-for-binary-random-variables-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The log-odds trick for binary random variables",
    "text": "The log-odds trick for binary random variables\n\nWe showed \\(belief_t(m_{ij} = 1) = \\eta p(\\mathbf{z_t}|\\mathbf{x_t}, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)\\) (1)\nDefine the log odds ratio \\(l_t^{(ij)} = \\log \\frac{p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})}{p(m_{ij} = 0|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})} = \\log \\frac{belief_t(m_{ij} = 1)}{belief_t(m_{ij} = 0)}\\)\nThen (1) becomes \\(l_t^{(ij)} = \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}\\)\n\n\nSo, as long as we can evaluate\nthe log odds ratio for the\nmeasurement likelihood:\n\\(\\color{black}\\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)}\\)\nwe can do the belief update."
  },
  {
    "objectID": "lecs/w06/lec06.html#log-odds-ratio-for-the-measurement-likelihood",
    "href": "lecs/w06/lec06.html#log-odds-ratio-for-the-measurement-likelihood",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Log-odds ratio for the measurement likelihood",
    "text": "Log-odds ratio for the measurement likelihood\n\nWe want to compute \\(\\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)}\\) to do the belief update\nWe apply conditional Bayes’ rule again: \\(\\quad p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1) = \\frac{p(m_{ij} = 1 | \\mathbf{z}_t, \\mathbf{x}_t) p(\\mathbf{z}_t | \\mathbf{x}_t)}{p(m_{ij} = 1 | \\mathbf{x}_t)}\\)\n\n\n\nIf we take the log-odds ratio: \\(\\quad \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} = \\log\\frac{p(m_{ij}=1|\\mathbf{z}_{t},\\mathbf{x}_{t})}{p(m_{ij}=0|\\mathbf{z}_{t},\\mathbf{x}_{t})}+\\log\\frac{p(m_{ij}=0|\\mathbf{x}_{t})}{p(m_{ij}=1|\\mathbf{x}_{t})}\\)\n\n\n\n\n\nWe can simplify further: \\(\\quad\\quad \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} = \\log\\frac{p(m_{ij}=1|\\mathbf{z}_{t},\\mathbf{x}_{t})}{p(m_{ij}=0|\\mathbf{z}_{t},\\mathbf{x}_{t})}+\\log\\frac{p(m_{ij}=0)}{p(m_{ij}=1)}\\)\n\n\nKnowing the current state provides no\ninformation about whether cell is\noccupied, if there are no observations\n\n\n\nPrior probability of cell being occupied.\nCan choose uniform distribution, for example.\n\n\n\nInverse measurement model:\nwhat is the likelihood of the map\ncell being occupied given the current\nstate and current measurement?"
  },
  {
    "objectID": "lecs/w06/lec06.html#summary-log-odds-ratio-for-the-measurement-likelihood",
    "href": "lecs/w06/lec06.html#summary-log-odds-ratio-for-the-measurement-likelihood",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Summary: Log-odds ratio for the measurement likelihood",
    "text": "Summary: Log-odds ratio for the measurement likelihood\n\nWe want to compute \\(\\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)}\\) but it’s hard\nInstead, we can compute the log-odds ratio of the measurement likelihood in terms of the inverse measurement model:\n\n\\[\\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} = \\log\\frac{p(m_{ij}=1|\\mathbf{z}_{t},\\mathbf{x}_{t})}{p(m_{ij}=0|\\mathbf{z}_{t},\\mathbf{x}_{t})}+\\log\\frac{p(m_{ij}=0)}{p(m_{ij}=1)}\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#inverse-sensor-measurement-model",
    "href": "lecs/w06/lec06.html#inverse-sensor-measurement-model",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inverse sensor measurement model",
    "text": "Inverse sensor measurement model\n\n\n\n\n\n\\(p(m_{ij} = 1 | z_t, x_t)\\)\n\n\n\nGiven map cell \\((i, j)\\) , the robot’s state \\(\\mathbf{x} = (x, y, \\theta)\\), and beams \\(\\mathbf{z} = {(r_k, \\psi_k)}\\)\nFind index k of sensor beam that is closest in heading to the cell \\((i,j)\\)\n\n\nIf the cell \\((i, j)\\) is sufficiently farther than \\(r_k\\) or out of the field of view\n// We don’t have enough information to decide whether cell is occupied\nReturn prior occupation probability \\(p(m_{ij} = 1)\\)\n\n\n\nIf the cell \\((i, j)\\) is nearly as far as the measurement \\(r_k\\)\n// Cell is most likely occupied\nReturn \\(p_{\\text{occupied}}\\) that is well above 0.5\n\n\n\nIf the cell \\((i, j)\\) is sufficiently closer than \\(r_k\\)\n// Cell is most likely free\nReturn \\(p_{\\text{occupied}}\\) that is well below 0.5"
  },
  {
    "objectID": "lecs/w06/lec06.html#inverse_sensor_measurement_modelij-mathbfx-x-y-theta-mathbfz-r_k-psi_k",
    "href": "lecs/w06/lec06.html#inverse_sensor_measurement_modelij-mathbfx-x-y-theta-mathbfz-r_k-psi_k",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "inverse_sensor_measurement_model(\\((i,j), \\mathbf{x} = (x, y, \\theta), \\mathbf{z} = \\{(r_k, \\psi_k)\\}\\))",
    "text": "inverse_sensor_measurement_model(\\((i,j), \\mathbf{x} = (x, y, \\theta), \\mathbf{z} = \\{(r_k, \\psi_k)\\}\\))\nFrom Probabilistic Robotics, chapter 9.2\n\n\nLet \\((x_i, y_i)\\) be the center of the cell \\((i, j)\\)\nLet \\(r = \\|(x_i, y_i) - (x, y)\\|\\)\nLet \\(\\phi = \\operatorname{atan2}(y_i - y, x_i - x) - \\theta\\) // Might need to ensure this angle difference is in \\([-\\pi, \\pi]\\)\nThe index of the closest-in-heading beam to \\((x_i, y_i)\\) is \\(k^* = \\mathbf{\\operatorname*{argmin}_{k}\\left|\\phi - \\psi_{k}\\right|}\\)\nIf \\(r &gt; \\min\\{r_{\\max}, r_k + \\alpha/2\\}\\) or \\(|\\phi - \\psi_k| &gt; \\beta/2\\)\n\nReturn the log odds ratio of the prior occupancy \\(\\log \\frac{p(m_{ij}=1)}{p(m_{ij}=0)}\\)\n\nIf \\(r_k &lt; r_{\\max}\\) and \\(|r - r_k| &lt; \\alpha/2\\)\n\nReturn the log odds ratio of being occupied (corresponding to occupation probability &gt; 0.5)\n\nIf \\(r \\le r_k\\)\n\nReturn the log odds ratio of being free (corresponding to occupation probability &lt; 0.5)"
  },
  {
    "objectID": "lecs/w06/lec06.html#recap",
    "href": "lecs/w06/lec06.html#recap",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recap",
    "text": "Recap\n\n\nWe wanted to compute the likelihood of any map based on known states and observations\n\n\\[p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) \\simeq \\prod_{i,j} p(m_{ij}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#recap-1",
    "href": "lecs/w06/lec06.html#recap-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recap",
    "text": "Recap\n\n\nWe wanted to compute the likelihood of any map based on known path and observations\n\n\\[p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) \\simeq \\prod_{i,j} p(m_{ij}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\]\n\nTo evaluate \\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\text{belief}_t(m_{ij} = 1)\\) we had to apply Bayes’ theorem, which revealed a way to recursively update the belief\n\n\\[belief_t(m_{ij} = 1) = \\eta p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)\\]\nVery frequent\nreasoning in\nprobabilistic\nrobotics\n\n\nTo avoid evaluating \\(\\eta\\) we used the log odds ratio\n\n\\[l_t^{(ij)} = \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}\\]\nCan do this for binary\nrandom variables"
  },
  {
    "objectID": "lecs/w06/lec06.html#recap-2",
    "href": "lecs/w06/lec06.html#recap-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recap",
    "text": "Recap\n\n\nWe wanted to compute the likelihood of any map based on known path and observations\n\n\\[p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) \\simeq \\prod_{i,j} p(m_{ij}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\]\n\nTo evaluate \\(p(m_{ij} = 1|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t}) = \\text{belief}_t(m_{ij} = 1)\\) we had to apply Bayes’ theorem, which revealed a way to recursively update the belief\n\n\\[belief_t(m_{ij} = 1) = \\eta p(\\mathbf{z}_t|\\mathbf{x}_t, m_{ij} = 1) belief_{t-1}(m_{ij} = 1)\\]\n\nTo avoid evaluating \\(\\eta\\) we used the log odds ratio\n\n\\[l_t^{(ij)} = \\log \\frac{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 1)}{p(\\mathbf{z}_t | \\mathbf{x}_t, m_{ij} = 0)} + l_{t-1}^{(ij)}\\]\n\nComputing the forward measurement model \\(p(\\mathbf{z}_{t}|\\mathbf{x}_{t}, m_{ij}=1)\\) was hard, so we applied Bayes’ rule again, to get an inverse measurement model \\(p(m_{ij}=1|\\mathbf{z}_t, \\mathbf{x}_t)\\) and an easier-to-compute log-odds ratio:\n\n\\[l_{t}^{(ij)}=l_{t-1}^{(ij)}+\\log\\frac{p(m_{ij}=1|\\mathbf{z}_{t},\\mathbf{x}_{t})}{p(m_{ij}=0|\\mathbf{z}_{t},\\mathbf{x}_{t})}-\\log\\frac{p(m_{ij}=1)}{p(m_{ij}=0)}\\]"
  },
  {
    "objectID": "lecs/w06/lec06.html#occupancy-grid-algorithm",
    "href": "lecs/w06/lec06.html#occupancy-grid-algorithm",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Occupancy Grid Algorithm",
    "text": "Occupancy Grid Algorithm\n\n\nUpon reception of a new laser/sonar/scan measurement \\(\\mathbf{z}_t = \\{(r_k, \\psi_k)\\}\\)\nLet the robot’s current state be \\(\\mathbf{x}_t = (x_t, y_t, \\theta_t)\\)\nLet the previous log-odds ratio of the occupancy belief be the 2D array \\(l_{t}^{(ij)}\\) where i is a row, j is a column\nIn the beginning we set the prior \\(l_{0}^{(ij)}=\\log\\frac{p(m_{ij}=1)}{p(m_{ij}=0)}\\) where the occupancy probability is a design decision.\n\n\n\n\n\nFor all cells (i,j) in the grid\n\nIf the cell (i,j) is in the field of view of the robot’s sensor at state \\(\\qquad \\mathbf{x}_t\\) \\[l_t^{(ij)} = _{t-1}^{(ij)} + \\text{inverse-sensor-measurement-model}((i,j), \\mathbf{x}_t, \\mathbf{z}_t) - l_0^{(ij)}\\]\nElse \\(\\qquad l_{t}^{(ij)} = l_{t-1}^{(ij)}\\)\n\nIf asked, return the following 2D matrix of occupancy probabilities: \\(\\qquad \\text{belief}_t(m_{ij} = 1) = 1 - \\frac{1}{1 + \\exp(l_t^{(ij)})}\\)"
  },
  {
    "objectID": "lecs/w06/lec06.html#results",
    "href": "lecs/w06/lec06.html#results",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Results",
    "text": "Results\n\nThe maximum likelihood map is obtained by clipping the occupancy grid map at a threshold of 0.5"
  },
  {
    "objectID": "lecs/w08/lec08.html#recommended-reading",
    "href": "lecs/w08/lec08.html#recommended-reading",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nChapters 2 and 3.2 from Probabilistic Robotics\nChapters 4.9 and 8.3 from Computational Principles of Mobile Robotics\nLesson 2 in https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\nThis illustrative blog post: http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\nCareful: the figure between equations (9) and (10) is wrong. The blue Gaussian should be taller and peakier than the other two Gaussians, the prior and the measurement models. This is not fixed as of March 15, 2017."
  },
  {
    "objectID": "lecs/w08/lec08.html#filtering-vs.-smoothing",
    "href": "lecs/w08/lec08.html#filtering-vs.-smoothing",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Filtering vs. Smoothing",
    "text": "Filtering vs. Smoothing\n\nSmoothing/Batch Estimation\n\n\\[p(\\mathbf{x}_{0:T} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1})\\]\n\n\n\nFiltering Estimation\n\n\\[p(\\mathbf{x}_t \\mid \\mathbf{z}_{0:t}, \\mathbf{u}_{0:t-1})\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#whats-the-difference",
    "href": "lecs/w08/lec08.html#whats-the-difference",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What’s the difference?",
    "text": "What’s the difference?\n\nSmoothing/Batch Estimation\n\n\\[p(\\mathbf{x}_{0:T} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1})\\]\nAll measurements and\ncontrols are known\nin advance\n\n\nFiltering Estimation\n\n\\[p(\\mathbf{x}_t \\mid \\mathbf{z}_{0:t}, \\mathbf{u}_{0:t-1})\\]\nMeasurements and controls\nare processed online as they come.\nFuture measurements are unknown."
  },
  {
    "objectID": "lecs/w08/lec08.html#why-do-we-use-filtering",
    "href": "lecs/w08/lec08.html#why-do-we-use-filtering",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why do we use filtering?",
    "text": "Why do we use filtering?\n\nOnline belief updates: filters provide a principled way to incorporate noisy information from sensor measurements, which can change our prior belief, in an online fashion.\n\n\n\nSensor fusion: filters enable us to combine measurements from multiple different noisy sensors into one coherent state estimate. E.g. camera + laser, camera + IMU, multiple cameras, sonar and IMU, GPS and IMU etc.\n\nTechnically speaking, this is also\ntrue for smoothing estimators."
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter",
    "href": "lecs/w08/lec08.html#bayes-filter",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter",
    "text": "Bayes’ Filter\n\nA generic class of filters that make use of Bayes’ rule and assume the following:\n\nMarkov Assumption For Dynamics : the state \\(x_t\\) is conditionally independent of past states and controls, given the previous state \\(x_{t-1}\\) In other words, the dynamics model is assumed to satisfy \\[p(x_{t}|x_{0:t-1}, u_{0:t-1}) = p(x_{t}|x_{t-1}, u_{t-1})\\]\nStatic World Assumption: the current observation is conditionally independent of past observations and controls, given the current state\n\\[p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) = p(z_t|x_t)\\]\n\n\n\nNote: the Markov assumption is\nmore general than what we have\npresented here."
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\ &= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1})\n\\end{align*}\\]\n\n\nNormalizing factor that makes the integral/sum of the numerator in Bayes’ Rule be 1.\n\nConditional Bayes’ Rule\n\n\\(p(A|B,C) = \\frac{p(C|A,B)p(A|B)}{p(C|B)}\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-1",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1})\n\\end{align*}\\]\n\n\nStatic World Assumption"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-2",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1}\n\\end{align*}\\]\n\n\n\n\nMarginalization, or law of total probability\n\\(\\color{black}p(A) = \\sum_{B_{i}}p(A,B_{i})\\)\nwhere the sum enumerates all possibilities over the variable Bi. If we see Bi as a set, then the collection of Bi’s must be pairwise disjoint. I.e. the collection of subsets Bi must be a partition of the sample space."
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-3",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1}\n\\end{align*}\\]\n\n\n\n\nMarginalization, or law of total probability\n\\(\\color{black}p(A) = \\sum_{B_{i}}p(A,B_{i})\\)\nHere we are actually using the law of total probability for conditional distributions, so\n\\(\\color{black}p(A|C) = \\sum_{B_{i}}p(A,B_{i}|C)\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-4",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t, x_t|u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1}\n\\end{align}\\]\n\n\n\nDefinition of conditional distribution\n\\(\\color{black}p(A, B|C) = p(A|B, C)p(B|C)\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-5",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\ &= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\ &= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\ &= \\eta p(z_t|x_t) \\int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\\\ &= \\eta p(z_t|x_t) \\int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\\\ &= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\end{align*}\\]\n\nMarkov assumption for dynamics"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-6",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\n\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t, u_{0:t-1}, z_{0:t-1}) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t, x_{t-1}|u_{0:t-1}, z_{0:t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{0:t-1}, z_{0:t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) p(x_{t-1}|z_{0:t-1}, u_{0:t-2}) dx_{t-1}\n\\end{align*}\\]\n\n\n\nControl at time t-1 only affects state at time t"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-7",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-7",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}\n\\end{align*}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-8",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-8",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\\[\\begin{align}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta \\, p(z_t|x_t) \\underbrace{\\int p(x_t|u_{t-1}, x_{t-1}) \\, bel(x_{t-1}) \\, dx_{t-1}}_{\\begin{subarray}{c} \\text{Computes the probability density of reaching state} \\\\ \\text{$x_t$ from any possible previous state $x_{t-1}$} \\\\ \\text{via the command $u_{t-1}$} \\end{subarray}}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-9",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-9",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\\[\\begin{align}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\underbrace{\\eta \\, p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) \\, bel(x_{t-1}) \\, dx_{t-1}}_{\\begin{subarray}{c} \\text{Computes the probability density of reaching state} \\\\ \\text{$x_t$ from any possible previous state $x_{t-1}$} \\\\ \\text{via the command $u_{t-1}$ and observing $z_t$} \\end{subarray}}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#bayes-filter-derivation-10",
    "href": "lecs/w08/lec08.html#bayes-filter-derivation-10",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayes’ Filter: Derivation",
    "text": "Bayes’ Filter: Derivation\n\\[\\begin{align}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\underbrace{\\eta \\, p(z_t|x_t) \\underbrace{\\int p(x_t|u_{t-1}, x_{t-1}) \\, bel(x_{t-1}) \\, dx_{t-1}}_{\\text{Belief after prediction step}}}_{\\text{Belief after update step}}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter",
    "href": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\\[\\begin{align}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta \\, p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) \\, bel(x_{t-1}) \\, dx_{t-1}\n\\end{align}\\]\n\n\\(z_t = Hx_t + n_t\\)\n\\(\\qquad\\) with noise \\(n_t \\sim \\mathcal{N}(0, R)\\)\n\n\\(x_{t} = Ax_{t-1}+Bu_{t-1}+Gw_{t-1}\\)\n\\(\\qquad\\) with noise \\(w_{t-1} \\sim \\mathcal{N}(0, Q)\\)\n\n\\(bel(x_0) \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-assumptions",
    "href": "lecs/w08/lec08.html#kalman-filter-assumptions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: assumptions",
    "text": "Kalman Filter: assumptions\n\nTwo assumptions inherited from Bayes’ Filter\nLinear dynamics and observation models\nInitial belief is Gaussian\nNoise variables and initial state \\[x_0, w_0, w_1, \\ldots, \\eta_0, \\eta_1, \\ldots\\] are jointly Gaussian and independent\nNoise variables \\(w_t\\) are independent and identically distributed \\(\\mathcal{N}(0, Q)\\)\nNoise variables \\(n_t\\) are independent and identically distributed \\(\\mathcal{N}(0, R)\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions",
    "href": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: why so many assumptions?",
    "text": "Kalman Filter: why so many assumptions?\n\nTwo assumptions inherited from Bayes’ Filter\nLinear dynamics and observation models\nInitial belief is Gaussian\nNoise variables and initial state \\[x_0, w_0, w_1, \\ldots, \\eta_0, \\eta_1, \\ldots\\] are jointly Gaussian and independent\nNoise variables \\(w_t\\) are independent and identically distributed \\(\\mathcal{N}(0, Q)\\)\nNoise variables \\(n_t\\) are independent and identically distributed \\(\\mathcal{N}(0, R)\\)\n\n\n\nWithout linearity there is no closed\nform solution for the posterior\nbelief in the Bayes’ Filter. Recall that\nif X is Gaussian then Y=AX+b is also\nGaussian. This is not true in general\nif Y=h(X).\nAlso, we will see later that applying\nBayes’ rule to a Gaussian prior and a\nGaussian measurement likelihood\nresults in a Gaussian posterior."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions-1",
    "href": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: why so many assumptions?",
    "text": "Kalman Filter: why so many assumptions?\n\nTwo assumptions inherited from Bayes’ Filter\nLinear dynamics and observation models\nInitial belief is Gaussian\nNoise variables and initial state \\[x_0, w_0, w_1, \\ldots, \\eta_0, \\eta_1, \\ldots\\] are jointly Gaussian and independent\nNoise variables \\(w_t\\) are independent and identically distributed \\(\\mathcal{N}(0, Q)\\)\nNoise variables \\(n_t\\) are independent and identically distributed \\(\\mathcal{N}(0, R)\\)\n\n\n\nThis results in the belief remaining Gaussian\nafter each propagation and update step.\nThis means that we only have to worry\nabout how the mean and the covariance\nof the belief evolve recursively with\neach prediction step and update step\n-&gt; COOL!"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions-2",
    "href": "lecs/w08/lec08.html#kalman-filter-why-so-many-assumptions-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: why so many assumptions?",
    "text": "Kalman Filter: why so many assumptions?\n\nTwo assumptions inherited from Bayes’ Filter\nLinear dynamics and observation models\nInitial belief is Gaussian\nNoise variables and initial state \\[x_0, w_0, w_1, \\ldots, \\eta_0, \\eta_1, \\ldots\\] are jointly Gaussian and independent\nNoise variables \\(w_t\\) are independent and identically distributed \\(\\mathcal{N}(0, Q)\\)\nNoise variables \\(n_t\\) are independent and identically distributed \\(\\mathcal{N}(0, R)\\)\n\n\n\nThis makes the recursive updates of the mean and covariance much simpler."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-1",
    "href": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\\[\\begin{align*}\n\\text{bel}(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) \\text{bel}(x_{t-1}) dx_{t-1}\n\\end{align*}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-2",
    "href": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\\[\\begin{align*}\nbel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\overline{bel}(x_t)\n\\end{align*}\\]\n\n Belief after prediction step (to simplify notation)\n\nSo, under the Kalman Filter assumptions we get\n\\(bel(x_{t-1}) \\sim \\mathcal{N}(\\mu_{t-1|t-1}, \\Sigma_{t-1|t-1})\\)\n\\(\\overline{bel}(x_t) \\sim \\mathcal{N}(\\mu_{t|t-1}, \\Sigma_{t|t-1})\\)\n\\(bel(x_t) \\sim \\mathcal{N}(\\mu_{t|t}, \\Sigma_{t|t})\\)\n\n Notation: estimate at time t given history of observations and\ncontrols up to time t-1"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-3",
    "href": "lecs/w08/lec08.html#kalman-filter-an-instance-of-bayes-filter-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\\[\\begin{align*}\nbel(x_t) &= \\eta p(z_t|x_t) p(x_t|u_{0:t-1}, z_{0:t-1}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1} \\\\\n&= \\eta p(z_t|x_t) \\overline{bel}(x_t)\n\\end{align*}\\]\n\n\nSo, under the Kalman Filter assumptions we get\n\\(bel(x_{t-1}) \\sim \\mathcal{N}(\\mu_{t-1|t-1}, \\Sigma_{t-1|t-1})\\)\n\\(\\qquad\\qquad \\color{red}\\downarrow\\)\n\\(\\overline{bel}(x_t) \\sim \\mathcal{N}(\\mu_{t|t-1}, \\Sigma_{t|t-1})\\)\n\\(\\qquad\\qquad \\color{red}\\downarrow\\)\n\\(bel(x_{t}) \\sim \\mathcal{N}(\\mu_{t|t}, \\Sigma_{t|t})\\)\n\nTwo main questions:\n\n\nHow to get prediction mean and covariance from prior mean and covariance?\n\n\n\nHow to get posterior mean and covariance from prediction mean and covariance?\n\nThese questions were answered in the 1960s. The resulting algorithm was used in the Apollo missions to the moon, and in almost every system in which there is a noisy sensor involved  COOL!"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state",
    "text": "Kalman Filter with 1D state\n\nLet’s start with the update step recursion. Here’s an example:\n\n\n\n\n\nSuppose your measurement model is \\(z_t = x_t + n_t\\) with \\(n_t \\sim \\mathcal{N}(0, 1^2)\\)\nSuppose your belief after the prediction step is \\(\\overline{bel}(x_{t})=\\mathcal{N}(0,2^{2})\\)\nSuppose your first noisy measurement is \\(z_0 = 5\\)\nQ: What is the mean and covariance of \\(bel(x_t)\\) ?"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})\\)\n\\(\\sigma^{2}=\\sigma_{B}^{2}-\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}\\sigma_{B}^{2}\\)\n\n\n\nPrediction residual/error between\nactual observation and expected\nobservation.\nYou expected the measured mean\nto be 0, according to your prediction\nprior, but you actually observed 5.\nThe smaller this prediction error is the better\nyour estimate will be, or the better it will agree\nwith the measurements."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-1",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\n\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})\\)\n\\(\\sigma^{2}=\\sigma_{B}^{2}-\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}\\sigma_{B}^{2}\\)\n\nKalman Gain: specifies\nhow much effect will the\nmeasurement have in the\nposterior, compared to the\nprediction prior. Which one do you\ntrust more, your prior \\(\\color{black}\\overline{bel}(x_t)\\)\nor your measurement \\(\\color{black}p(z_t | x_t)\\) ?"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-2",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\n\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})\\)\n\\(\\sigma^{2}=\\sigma_{B}^{2}-\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}\\sigma_{B}^{2}\\)\n\nThe measurement is more confident\n(lower variance) than the prior, so\nthe posterior mean is going to be\ncloser to 5 than to 0."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-3",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\n\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})\\)\n\n\n\n\n\n\nNo matter what happens, the variance of the\nposterior is going to be reduced. I.e. new\nmeasurement increases confidence no matter\nhow noisy it is."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-4",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\n\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})\\)\n\n\n\n\n\n\nIn fact you can write this as\n\\(\\color{black}\\frac{1}{\\sigma^{2}}=\\frac{1}{\\sigma_{A}^{2}}+\\frac{1}{\\sigma_{B}^{2}}\\)\nso \\(\\color{black}\\sigma &lt; \\sigma_A\\) and \\(\\color{black}\\sigma &lt; \\sigma_B\\)\nI.e. the posterior is more confident than both\nthe prior and the measurement."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-5",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nFrom Bayes’ Filter we get \\(bel(x_t) = \\eta p(z_t|x_t) \\overline{bel}(x_t)\\) so\n\\[\\begin{align*}\np(z_t|x_t) \\overline{bel}(x_t) &= \\mathcal{N}(\\mu_A, \\sigma_A^2)\\mathcal{N}(\\mu_B, \\sigma_B^2) \\\\\n&= \\dots \\\\\n&= \\text{see Appendix 1 for proof} \\\\\n&= \\dots \\\\\n&= \\mathcal{N}(\\mu, \\sigma^2)/\\eta\n\\end{align*}\\]\n\n\nIn this example:\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})= 4\\)\n\\(\\sigma^{2}=\\sigma_{B}^{2}-\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}\\sigma_{B}^{2} = 4/5\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-6",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\n\n\n\n\nAnother example:\n\\(\\mu=\\mu_{B}+\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}(\\mu_{A}-\\mu_{B})= 5\\)\n\\(\\sigma^{2}=\\sigma_{B}^{2}-\\frac{\\sigma_{B}^{2}}{\\sigma_{A}^{2}+\\sigma_{B}^{2}}\\sigma_{B}^{2} = \\sigma^2_B / 2 = 2\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-7",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-update-step-7",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the update step",
    "text": "Kalman Filter with 1D state: the update step\nTake-home message: new observations, no matter how noisy, always reduce  uncertainty in the posterior. The mean of the posterior, on the other hand, only changes when there is a nonzero prediction residual."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\n\n\n\n\n\nRecall: this notation means\nexpected value with respect to\nconditional expectation, i.e\n\n\\(\\color{black}\\int x_{t}p(x_{t}|z_{0:t-1},u_{0:t-1})dx_{t}\\)\n\\(\\color{black}= \\int x_{t} \\overline{bel}(x_{t}) dx_{t}\\)\nControl is a constant with\nrespect to the distribution\n\\(\\color{black}\\overline{bel}(x_{t})\\)\nDynamics noise is zero mean,\nand independent of observations\nand controls"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-1",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}]\n\\end{align}\\]\n\n\n\n\n\\(\\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] = \\mathbb{E}[x_t^2|z_{0:t-1}, u_{0:t-1}] - (\\mathbb{E}[x_t|z_{0:t-1}, u_{0:t-1}])^2\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-2",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}]\n\\end{align}\\]\n\n\n\n\n\n\\(\\xleftarrow{\\hspace{1cm}}\\) Recall: covariance neglects addition\nof constant terms, i.e. \nCov(X+b) = Cov(X)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-3",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \\text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-4",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \\text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-5",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \\text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \\text{Cov}[w_{t-1}]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-6",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \\text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \\text{Cov}[w_{t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-2}] + \\text{Cov}[w_{t-1}]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-7",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-7",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\n\n\n\n\nSuppose that the dynamics model is\n\\(x_t = x_{t-1} + u_{t-1} + w_{t-1} \\text{ with } w_{t-1} \\sim \\mathcal{N}(0, q^2)\\)\nand you applied the command \\(u_{t-1} = 10\\) Then\n\n\n\\[\\begin{align*}\n\\mu &= \\mathbb{E}[x_t | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + u_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\mathbb{E}[x_{t-1} + w_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-1}] + u_{t-1} \\\\\n&= \\mathbb{E}[x_{t-1} | z_{0:t-1}, u_{0:t-2}] + u_{t-1} \\\\\n&= \\mu_C + u_{t-1}\n\\end{align*}\\]\n\\[\\begin{align}\n\\sigma^2 &= \\text{Cov}[x_t|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + u_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1} + w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1}, u_{0:t-1}] + \\text{Cov}[w_{t-1}|z_{0:t-1}, u_{0:t-1}] - 2\\text{Cov}[x_{t-1}, w_{t-1}|z_{0:t-1}, u_{0:t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-1}] + \\text{Cov}[w_{t-1}] \\\\\n&= \\text{Cov}[x_{t-1}|z_{0:t-1},u_{0:t-2}] + \\text{Cov}[w_{t-1}] \\\\\n&= \\sigma_{C}^{2} + q^{2}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-8",
    "href": "lecs/w08/lec08.html#kalman-filter-with-1d-state-the-propagationprediction-step-8",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 1D state: the propagation/prediction step",
    "text": "Kalman Filter with 1D state: the propagation/prediction step\nTake home message: uncertainty increases after the prediction step,\nbecause we are speculating about the future."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state",
    "text": "Kalman Filter with 2D state\n\n\n\n\nSuppose we have a robot that moves on a 1D line, but we also want to estimate its velocity. Then the 2D state vector is \\(x_t = [p, v]^T\\)\nSuppose we do not have any control over this robot, i.e. we are just trying to estimate its state through observations of the position only . I.e.:\n\\(z_t = Hx_t + n_t = [1, 0]x_t + n_t \\quad \\text{with} \\quad n_t \\sim \\mathcal{N}(0, r^2)\\)\nAlso suppose that we predict zero acceleration in the near future, so\n\\(p_{t+1} = p_{t} + v_{t}\\delta t + w_{p}(t)\\)\n\\(v_{t+1} = v_{t} + w_{v}(t)\\)\nwhich in vector form is expressed as\n\\[x_{t+1} = Ax_t + w_t \\qquad\n\\begin{align}\nA &= \\begin{bmatrix} 1 & \\delta t \\\\ 0 & 1 \\end{bmatrix} \\\\\nw_t &= \\begin{bmatrix} w_p(t) \\\\ w_v(t) \\end{bmatrix} \\sim \\mathcal{N}(0_{2 \\times 1}, Q)\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-1",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state",
    "text": "Kalman Filter with 2D state\n\n\n\n\nSuppose we have a robot that moves on a 1D line, but we also want to estimate its velocity. Then the 2D state vector is \\(x_t = [p, v]^T\\)\nSuppose we do not have any control over this robot, i.e. we are just trying to estimate its state through observations of the position only . I.e.:\n\\(\\qquad z_t = Hx_t + n_t = [1, 0]x_t + n_t \\quad \\text{with} \\quad n_t \\sim \\mathcal{N}(0, r^2)\\)\nAlso suppose that we predict zero acceleration in the near future, so\n\\(p_{t+1} = p_{t} + v_{t}\\delta t + w_{p}(t)\\)\n\\(v_{t+1} = v_{t} + w_{v}(t)\\)\nwhich in vector form is expressed as\n\\[x_{t+1} = Ax_t + w_t \\qquad\n\\begin{align}\nA &= \\begin{bmatrix} 1 & \\delta t \\\\ 0 & 1 \\end{bmatrix} \\\\\nw_t &= \\begin{bmatrix} w_p(t) \\\\ w_v(t) \\end{bmatrix} \\sim \\mathcal{N}(0_{2 \\times 1}, Q)\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-2",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state",
    "text": "Kalman Filter with 2D state\n\n\n\n\nSuppose that at time t the state is distributed as \\(p(x_{t}|z_{0:t})=\\mathcal{N}(\\mu_{t|t},\\Sigma_{t|t})\\) with\n\\[\\mu_{t|t} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\quad \\Sigma_{t|t} = \\begin{bmatrix} \\sigma_p^2 & \\sigma_{pv} \\\\ \\sigma_{pv} & \\sigma_v^2 \\end{bmatrix} = \\begin{bmatrix} 1^2 & 0 \\\\ 0 & 10^2 \\end{bmatrix}\\]\nIn other words, we are confident that in the beginning the position is with high probability (~0.997) within range \\(3\\sigma_{v}=3\\) of the mean position, 0.\nWe are not very confident in the velocity, however. We just know a priori that with high probability (~0.997) it is within range \\(3\\sigma_{v}=30\\) of the mean velocity 1.\nNotice that when the cross-correlation terms \\(\\sigma_{pv} = 0\\) then the ellipse is axis-aligned. This means that the position and velocity are initially uncorrelated."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-propagationprediction-step",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-propagationprediction-step",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state: the propagation/prediction step",
    "text": "Kalman Filter with 2D state: the propagation/prediction step\n\n\n\n\nAfter the prediction step the state is distributed as \\(p(x_{t+1}|z_{0:t})=\\mathcal{N}(\\mu_{t+1|t},\\Sigma_{t+1|t})\\) with\n\n\n\\[\\begin{align}\n\\mu_{t+1|t} &= \\mathbb{E}[x_{t+1}|z_{0:t}] \\\\\n&= \\mathbb{E}[Ax_t + w_t|z_{0:t}] \\\\\n&= A\\mathbb{E}[x_t + w_t|z_{0:t}] \\\\\n&= A\\mathbb{E}[x_t|z_{0:t}] \\\\\n&= A\\mu_{t|t} \\\\\n&= \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n\\end{align}\\]\n\\[\\begin{align*}\n\\Sigma_{t+1|t} &= \\text{Cov}[x_{t+1}|z_{0:t}] \\\\\n&= \\text{Cov}[Ax_t + w_t|z_{0:t}] \\\\\n&= \\text{Cov}[Ax_t|z_{0:t}] + \\text{Cov}[w_t|z_{0:t}] - 2\\text{Cov}[Ax_t, w_t|z_{0:t}] \\\\\n&= A\\text{Cov}[x_t|z_{0:t}]A^T + \\text{Cov}[w_t] \\\\\n&= A\\Sigma_{t|t}A^T + Q \\\\\n&= \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1^2 & 0 \\\\ 0 & 10^2 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 1^2 & 0 \\\\ 0 & 1^2 \\end{bmatrix} = \\begin{bmatrix} 102 & 100 \\\\ 100 & 101 \\end{bmatrix}\n\\end{align*}\\]\n\n\n\n\n\nMany things to notice here:\n\nThe covariance has nonzero\noff- diagonal terms, so the\nposition and velocity are\nnow correlated. This is why\nthe orange ellipse\nis rotated.\n\nAlso, the orange ellipse is\n“larger” than the initial\nblue ellipse,which means\nthat our uncertainty has\nincreased by speculating\nfor future outcomes.\n\nThere is now large uncertainty\nin the predicted position,\nsince there was large\nuncertainty in the velocity."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state: the update step",
    "text": "Kalman Filter with 2D state: the update step\n\n\n\n\nBefore the update step the state is distributed as \\(p(x_{t+1}|z_{0:t})=\\mathcal{N}(\\mu_{t+1|t},\\Sigma_{t+1|t})\\) with $\\(\\mu_{t+1|t}=[1,1]^{T}\\) and \\(\\Sigma_{t+1|t} = \\begin{bmatrix} 102 & 100 \\\\ 100 & 101 \\end{bmatrix}\\)\nAt this point we predict that the next measurement of the position is going to be \\(\\mu_{z_{t+1}}=H\\mu_{t+1|t}=[1,0]\\mu_{t+1|t}=1\\) with uncertainty \\(s_{t+1}^2\\) which depends on previous uncertainty and measurement uncertainty.\nSuppose that we actually measure \\(\\overline{z}_{t+1}=5\\) which means that our mean estimate of the velocity was way off (it was 1). Therefore, there is a prediction residual/error \\(\\delta z=\\overline{z}_{t+1}-z_{t+1}\\sim\\mathcal{N}(4,s_{t+1}^{2})\\)\nHow confident are we about this residual?\n\n\n\\[\\begin{align}\ns_{t+1}^2 &= \\text{Cov}[\\bar{z}_{t+1} - z_{t+1}|z_{0:t}] \\\\\n&= \\text{Cov}[z_{t+1}|z_{0:t}] \\\\\n&= \\text{Cov}[Hx_{t+1} + n_{t+1}|z_{0:t}] \\\\\n&= HCov[x_{t+1}|z_{0:t}]H^T + \\text{Cov}[n_{t+1}|z_{0:t}] \\\\\n&= HCov[x_{t+1}|z_{0:t}]H^T + \\text{Cov}[n_{t+1}] \\\\\n&= H\\Sigma_{t+1|t}H^T + r^2 = 102 + 1^2 = 103\n\\end{align}\\]\n\n\n\n\n\n\nThis means that our\nmeasurement was within\na range of \\(3\\sqrt{103}\\) from the\ntrue position with high\nprobability (~0.997)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-1",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state: the update step",
    "text": "Kalman Filter with 2D state: the update step\n\n\n\n\n\n\nHow do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is \\(p(x_{t+1}|z_{0:t+1})=\\mathcal{N}(\\mu_{t+1|t+1},\\Sigma_{t+1|t+1})\\) with\n\\(K_{t+1} = \\Sigma_{t+1|t} H^T s_{t+1}^{-2} = \\begin{bmatrix} 102 & 100 \\\\ 100 & 101 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} 103^{-1} = \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix}\\)\n\\(\\mu_{t+1|t+1} = \\mu_{t+1|t} + K_{t+1} \\mu_{\\delta x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix} 4 = \\begin{bmatrix} 4.96 \\\\ 4.88 \\end{bmatrix}\\)\n\n\n\n\\[\\begin{align}\n\\Sigma_{t+1|t+1} &= \\Sigma_{t+1|t} - K H \\Sigma_{t+1|t} \\\\\n&= \\Sigma_{t+1|t} - \\frac{102}{103} \\Sigma_{t+1|t} \\\\\n&= \\frac{1}{103} \\Sigma_{t+1|t} \\\\\n&= \\begin{bmatrix} 0.99 & 0.97 \\\\ 0.97 & 0.98 \\end{bmatrix}\\end{align}\\]"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-2",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state: the update step",
    "text": "Kalman Filter with 2D state: the update step\n\n\n\n\n\n\nHow do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is \\(p(x_{t+1}|z_{0:t+1})=\\mathcal{N}(\\mu_{t+1|t+1},\\Sigma_{t+1|t+1})\\) with\n\\(K_{t+1} = \\Sigma_{t+1|t} H^T s_{t+1}^{-2} = \\begin{bmatrix} 102 & 100 \\\\ 100 & 101 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} 103^{-1} = \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix}\\)\n\\(\\mu_{t+1|t+1} = \\mu_{t+1|t} + K_{t+1} \\mu_{\\delta x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix} 4 = \\begin{bmatrix} 4.96 \\\\ 4.88 \\end{bmatrix}\\)\n\n\n\n\\[\\begin{align}\n\\Sigma_{t+1|t+1} &= \\Sigma_{t+1|t} - K H \\Sigma_{t+1|t} \\\\\n&= \\Sigma_{t+1|t} - \\frac{102}{103} \\Sigma_{t+1|t} \\\\\n&= \\frac{1}{103} \\Sigma_{t+1|t} \\\\\n&= \\begin{bmatrix} 0.99 & 0.97 \\\\ 0.97 & 0.98 \\end{bmatrix}\\end{align}\\]\n\n\n After the measurement the covariance was reduced. We are now more confident than both the measurement and the prediction estimate."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-3",
    "href": "lecs/w08/lec08.html#kalman-filter-with-2d-state-the-update-step-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 2D state: the update step",
    "text": "Kalman Filter with 2D state: the update step\n\n\n\n\n\n\nHow do we update our belief based on the noisy measurement? We’re not going to provide a proof here (see Probabilistic Robotics, section 3.2), but the updated belief is \\(p(x_{t+1}|z_{0:t+1})=\\mathcal{N}(\\mu_{t+1|t+1},\\Sigma_{t+1|t+1})\\) with\n\\(K_{t+1} = \\Sigma_{t+1|t} H^T s_{t+1}^{-2} = \\begin{bmatrix} 102 & 100 \\\\ 100 & 101 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} 103^{-1} = \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix}\\)\n\\(\\mu_{t+1|t+1} = \\mu_{t+1|t} + K_{t+1} \\mu_{\\delta x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 102/103 \\\\ 100/103 \\end{bmatrix} 4 = \\begin{bmatrix} 4.96 \\\\ 4.88 \\end{bmatrix}\\)\n\n\n\n\\[\\begin{align}\n\\Sigma_{t+1|t+1} &= \\Sigma_{t+1|t} - K H \\Sigma_{t+1|t} \\\\\n&= \\Sigma_{t+1|t} - \\frac{102}{103} \\Sigma_{t+1|t} \\\\\n&= \\frac{1}{103} \\Sigma_{t+1|t} \\\\\n&= \\begin{bmatrix} 0.99 & 0.97 \\\\ 0.97 & 0.98 \\end{bmatrix}\\end{align}\\]\n\n\n\n\n\nAlso, notice how we MEASURED\nposition, and through correlation,\nwe were able to INFER velocity.\nThis is not always possible."
  },
  {
    "objectID": "lecs/w08/lec08.html#qquadquad-kalman-filter-in-n-dimensions",
    "href": "lecs/w08/lec08.html#qquadquad-kalman-filter-in-n-dimensions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "\\(\\qquad\\quad\\) Kalman Filter in N dimensions",
    "text": "\\(\\qquad\\quad\\) Kalman Filter in N dimensions\n\nDynamics\n\\(x_{t+1} = Ax_t + Bu_t + Gw_t\\)\n\\(w_t \\sim \\mathcal{N}(0, Q)\\)\n\n\nMeasurements\n\\(z_t = Hx_t + n_t\\)\n\\(n_t \\sim \\mathcal{N}(0, R)\\)\n\n\nInit \\[bel(x_0) \\sim \\mathcal{N}(\\mu_{0|0}, \\Sigma_{0|0})\\]\nPrediction Step \\[\\mu_{t+1|t} = A\\mu_{t|t} + Bu_t\\] \\[\\Sigma_{t+1|t} = A\\Sigma_{t|t}A^T + GQG^T\\]\nUpdate Step\nReceived measurement \\(\\tilde{z}_{t+1}\\) but expected to receive \\(\\mu_{z_{t+1}} = H\\mu_{t+1|t}\\)\nPrediction residual is a Gaussian random variable \\(\\delta z \\sim \\mathcal{N}(\\tilde{z}_{t+1} - \\mu_{z_{t+1}}, S_{t+1})\\)\nwhere the covariance of the residual is \\(S_{t+1} = H\\Sigma_{t+1|t}H^T + R\\)\nKalman Gain (optimal correction factor): \\(K_{t+1} = \\Sigma_{t+1|t}H^T S_{t+1}^{-1}\\)\n\\[\\mu_{t+1|t+1} = \\mu_{t+1|t} + K_{t+1}(\\tilde{z}_{t+1} - \\mu_{z_{t+1}})\\]\n\\[\\Sigma_{t+1|t+1} = \\Sigma_{t+1|t} - K_{t+1}H\\Sigma_{t+1|t}\\]\n\n\n\nPotentially\n\\(\\xleftarrow{\\hspace{1.5cm}}\\) expensive and\nerror-prone\noperation: matrix\ninversion O(|z|^2.4)"
  },
  {
    "objectID": "lecs/w08/lec08.html#quadqquad-kalman-filter-in-n-dimensions",
    "href": "lecs/w08/lec08.html#quadqquad-kalman-filter-in-n-dimensions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "\\(\\quad\\qquad\\) Kalman Filter in N dimensions",
    "text": "\\(\\quad\\qquad\\) Kalman Filter in N dimensions\n\nDynamics\n\\(x_{t+1} = Ax_t + Bu_t + Gw_t\\)\n\\(w_t \\sim \\mathcal{N}(0, Q)\\)\n\n\nMeasurements\n\\(z_t = Hx_t + n_t\\)\n\\(n_t \\sim \\mathcal{N}(0, R)\\)\n\n\nInit \\[bel(x_0) \\sim \\mathcal{N}(\\mu_{0|0}, \\Sigma_{0|0})\\]\nPrediction Step \\[\\mu_{t+1|t} = A\\mu_{t|t} + Bu_t\\] \\[\\Sigma_{t+1|t} = A\\Sigma_{t|t}A^T + GQG^T\\]\nUpdate Step\nReceived measurement \\(\\tilde{z}_{t+1}\\) but expected to receive \\(\\mu_{z_{t+1}} = H\\mu_{t+1|t}\\)\nPrediction residual is a Gaussian random variable \\(\\delta z \\sim \\mathcal{N}(\\tilde{z}_{t+1} - \\mu_{z_{t+1}}, S_{t+1})\\)\nwhere the covariance of the residual is \\(S_{t+1} = H\\Sigma_{t+1|t}H^T + R\\)\nKalman Gain (optimal correction factor): \\(K_{t+1} = \\Sigma_{t+1|t}H^T S_{t+1}^{-1}\\)\n\\[\\mu_{t+1|t+1} = \\mu_{t+1|t} + K_{t+1}(\\tilde{z}_{t+1} - \\mu_{z_{t+1}})\\]\n\\[\\Sigma_{t+1|t+1} = \\Sigma_{t+1|t} - K_{t+1}H\\Sigma_{t+1|t}\\]\n\n\nNumerical errors may make the\ncovariance non-symmetric at\nsome point. In practice, we\neither force symmetry, or we\ndecompose the covariance\nduring the update.\n\n See “Factorization methods\nfor discrete sequential\nestimation” by Gerald Bierman\nfor more info."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-4d-state",
    "href": "lecs/w08/lec08.html#kalman-filter-with-4d-state",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 4D state",
    "text": "Kalman Filter with 4D state\n\nSuppose a cannonball is shot from a cannon, and assume we can somehow measure its position in flight.\nAssuming zero drag and resistance from the air, the only force acting on the ball after it is ejected is its weight (suppose mass=1kg).\nThen the continuous dynamics of the system are given by \\(\\ddot{p}_x = w_x\\) \\(\\ddot{p}_y = -g + w_y\\) where \\(w\\) is noise in the acceleration.\nThe discrete-time version of this dynamics model is\n\\[\\begin{align}\np_x(t + 1) &= p_x(t) + v_x(t)\\delta t + w_x(t)\\delta t^2/2 \\\\\np_y(t + 1) &= p_y(t) + v_y(t)\\delta t + (-g + w_y(t))\\delta t^2/2 \\\\\nv_x(t + 1) &= v_x(t) + w_x(t)\\delta t \\\\\nv_y(t + 1) &= v_y(t) + (-g + w_y(t))\\delta t\n\\end{align}\\]\nwhich can be expressed in matrix form as \\(x_{t+1} = Ax_t + Bu_t + Gw_t \\quad\\) where \\(\\quad x_t = [p_x(t), p_y(t), v_x(t), v_y(t)]^T\\)\n\\[A = \\begin{bmatrix} 1 & 0 & \\delta t & 0 \\\\ 0 & 1 & 0 & \\delta t \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\quad B = I_{4 \\times 4} \\quad u_t = \\begin{bmatrix} 0 \\\\ -g\\delta t^2/2 \\\\ 0 \\\\ -g\\delta t \\end{bmatrix} \\quad G = \\begin{bmatrix} \\delta t^2/2 & 0 \\\\ 0 & \\delta t^2/2 \\\\ \\delta t & 0 \\\\ 0 & \\delta t \\end{bmatrix} \\quad w_t \\sim \\mathcal{N}(0_{2 \\times 1}, Q) \\quad g = 9.81 m/s^2\\]\nSince we can measure its position the measurement model is \\(z_t = Hx_t + n_t\\) where \\(H = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{bmatrix}\\) and \\(n_t \\sim \\mathcal{N}(0_{2 \\times 1}, R)\\)\n\n\n\n\n\n \n\n\nNotice here that we don’t actually control the system,\nbut we include \\(u_t\\) to account for additive constants in the dynamics."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-4d-state-1",
    "href": "lecs/w08/lec08.html#kalman-filter-with-4d-state-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 4D state",
    "text": "Kalman Filter with 4D state\n\n\n\n\n\n\n\n\nThis is the \\(3\\sigma_{py}\\) uncertainty around the mean estimate. With probability ~0.997 the true \\(p_y\\) should be within these bounds, as long as the system has been initialized close enough to the true initial state, and as long as the KF assumptions hold.\n\n\n \n\n\n\n\\(\\color{blue}\\xrightarrow{\\hspace{2cm}}\\)"
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-4d-state-2",
    "href": "lecs/w08/lec08.html#kalman-filter-with-4d-state-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 4D state",
    "text": "Kalman Filter with 4D state\n\n\n\n\n\n\n\n\nWe initialized the KF estimated mean position to be [0, 2] when the true value was [0, 0] and we assigned high uncertainty in the initial position estimate, which was reduced after the first few measurements."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-4d-state-3",
    "href": "lecs/w08/lec08.html#kalman-filter-with-4d-state-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 4D state",
    "text": "Kalman Filter with 4D state\n\n\n\n\n\n\n\n\nWe initialized the KF estimated mean y-velocity to be 5 when the true value was 10 and we assigned high uncertainty in the initial y-velocity estimate.\n Even though we do not measure the velocity directly, through correlation with position, the KF is able to INFER it and the initially large uncertainty shrinks as more measurements are received."
  },
  {
    "objectID": "lecs/w08/lec08.html#kalman-filter-with-4d-state-4",
    "href": "lecs/w08/lec08.html#kalman-filter-with-4d-state-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter with 4D state",
    "text": "Kalman Filter with 4D state\n\n\n\n\n\n\nParameters and code to reproduce this can be found at https://github.com/florianshkurti/comp417/tree/master/filtering_examples\n\n\n\n\nWe initialized the KF estimated mean y-velocity to be 5 when the true value was 10 and we assigned high uncertainty in the initial y-velocity estimate.\n Even though we do not measure the velocity directly, through correlation with position, the KF is able to INFER it and the initially large uncertainty shrinks as more measurements become are received."
  },
  {
    "objectID": "lecs/w08/lec08.html#appendix-1",
    "href": "lecs/w08/lec08.html#appendix-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\n\n\n\nClaim \\(\\mathcal{N}(\\mu_A, \\sigma_A^2) \\mathcal{N}(\\mu_B, \\sigma_B^2) \\propto \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\nwhere \\(\\mu = \\mu_B + \\frac{\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2}(\\mu_A - \\mu_B) \\qquad \\sigma^2 = \\sigma_B^2 - \\frac{\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2} \\sigma_B^2\\)\n\n\n\nProof:\n\\[\\mathcal{N}(\\mu_A, \\sigma_A^2) \\mathcal{N}(\\mu_B, \\sigma_B^2) = \\frac{1}{2\\pi\\sigma_A\\sigma_B} \\exp\\{-0.5(x - \\mu_A)^2/\\sigma_A^2 - 0.5(x - \\mu_B)^2/\\sigma_B^2\\}\\]\n\n\n\nDefine \\(\\quad \\beta = \\frac{(x - \\mu_A)^2}{2\\sigma_A^2} + \\frac{(x - \\mu_B)^2}{2\\sigma_B^2}\\)\n\\[\\begin{align}\n\\beta &= \\frac{(\\sigma_A^2 + \\sigma_B^2)x^2 - 2(\\mu_A\\sigma_B^2 + \\mu_B\\sigma_A^2)x + \\mu_A^2\\sigma_B^2 + \\mu_B^2\\sigma_A^2}{2\\sigma_A^2\\sigma_B^2} \\\\\n\\beta &= \\frac{x^2 - 2\\frac{\\mu_A\\sigma_B^2 + \\mu_B\\sigma_A^2}{\\sigma_A^2 + \\sigma_B^2}x + \\frac{\\mu_A^2\\sigma_B^2 + \\mu_B^2\\sigma_A^2}{\\sigma_A^2 + \\sigma_B^2}}{2\\frac{\\sigma_A^2\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2}} \\\\\n\\beta &= \\frac{x^2 - 2\\mu x + \\mu^2}{2\\sigma^2} = \\frac{(x - \\mu)^2}{2\\sigma^2}\n\\end{align}\\]\n\n\nwhere\n\\[\\begin{align}\n\\mu &= \\mu_A \\frac{\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2} + \\mu_B \\frac{\\sigma_A^2}{\\sigma_A^2 + \\sigma_B^2} = \\mu_B + \\frac{\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2}(\\mu_A - \\mu_B) \\\\\n\\sigma^2 &= \\frac{\\sigma_A^2\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2} = \\sigma_B^2 - \\frac{\\sigma_B^2}{\\sigma_A^2 + \\sigma_B^2}\\sigma_B^2\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#todays-agenda",
    "href": "lecs/w07/lec07.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\nLeast Squares Estimation\nMaximum Likelihood Estimation (MLE)\nMaximum a Posteriori Estimation (MAP)\nBayesian Estimation\nGraphSLAM"
  },
  {
    "objectID": "lecs/w07/lec07.html#estimating-parameters-of-probability-models",
    "href": "lecs/w07/lec07.html#estimating-parameters-of-probability-models",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimating parameters of probability models",
    "text": "Estimating parameters of probability models\n\nIn the occupancy grid mapping problem we wanted to compute \\(p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\) over all possible maps.\nWe can see this problem as a specific instance within a category of problems where we are given data (observations) and we want to “explain” or fit the data using a parametric function.\n\n\n\nThere are typically three ways to work with this type of problems:\n\nMaximum Likelihood parameter estimation (MLE)\n\nLeast Squares\n\nMaximum A Posteriori (MAP) parameter estimation\nBayesian parameter distribution estimation"
  },
  {
    "objectID": "lecs/w07/lec07.html#least-squares-parameter-estimation",
    "href": "lecs/w07/lec07.html#least-squares-parameter-estimation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Least Squares Parameter Estimation",
    "text": "Least Squares Parameter Estimation\n\n\n\n\nExample: we think that the 2D data was generated by a line \\(z = \\theta_{0} + \\theta_{1}x\\) whose parameters we do not know, and was corrupted by noise.\n\n\nWe are given data points \\(\\mathbf{(x_1, z_1), \\dots, (x_N, z_N)}\\)\nWe think that the data was generated by a parametric function \\(\\mathbf{z = h(\\theta, x)}\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#least-squares-parameter-estimation-1",
    "href": "lecs/w07/lec07.html#least-squares-parameter-estimation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Least Squares Parameter Estimation",
    "text": "Least Squares Parameter Estimation\n\n\n\nExample: we think that the 2D data was generated by a line \\(z = \\theta_{0} + \\theta_{1}x\\) whose parameters we do not know\n\nWe are given data points \\(\\mathbf{(x_1, z_1), \\dots, (x_N, z_N)}\\)\nWe think that the data was generated by a parametric function \\(\\mathbf{z = h(\\theta, x)}\\)\nThis parametric model will have a fitting error: \\[e(\\theta)=\\sum_{i=1}^{N}||\\mathbf{z}_{i}-\\mathbf{h}(\\theta,\\mathbf{x}_{i})||^{2}\\]\nThe least-squares estimator is: \\[\\theta_{LS} = \\underset{\\theta}{\\operatorname*{argmin}} e(\\theta)\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#linear-least-squares-parameter-estimation",
    "href": "lecs/w07/lec07.html#linear-least-squares-parameter-estimation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linear Least Squares Parameter Estimation",
    "text": "Linear Least Squares Parameter Estimation\n\n\n\nExample: we think that the 2D data was generated by a line \\(z = \\theta_{0} + \\theta_{1}x\\) whose parameters we do not know\n\nWe are given data points \\(\\mathbf{(x_1, z_1), \\dots, (x_N, z_N)}\\)\nWe think that the data was generated by a linear parametric function \\(\\mathbf{z = h(\\theta, x) = H_x\\theta}\\) where \\(\\mathbf{H_x}\\) is a matrix whose elements depend on \\(\\mathbf{x}\\)\nThis parametric model will have a fitting error: \\[e(\\theta) = \\sum_{i=1}^{N} ||\\mathbf{z}_i - \\mathbf{H}_{x_i}\\theta||^2\\]\nThe least-squares estimator is: \\[\\theta_{LS} = \\underset{\\theta}{\\operatorname*{argmin}} e(\\theta)\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#linear-least-squares-parameter-estimation-1",
    "href": "lecs/w07/lec07.html#linear-least-squares-parameter-estimation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linear Least Squares Parameter Estimation",
    "text": "Linear Least Squares Parameter Estimation\n\n\n\nExample: we think that the 2D data was generated by a line \\(z = \\theta_{0} + \\theta_{1}x\\) whose parameters we do not know\n\nWe are given data points \\(\\mathbf{(x_1, z_1), \\dots, (x_N, z_N)}\\)\nWe think that the data was generated by a linear parametric function \\(\\mathbf{z = h(\\theta, x) = \\mathbf{H}_x\\theta}\\)\nThis parametric model will have a fitting error:\n\\[\\begin{align}\ne(\\theta) &= \\sum_{i=1}^{N} ||\\mathbf{z}_i - \\mathbf{H}_{x_i} \\theta||^2 \\\\\n&= \\sum_{i=1}^{N} \\mathbf{z}_i^T \\mathbf{z}_i - 2\\theta^T \\mathbf{H}_{x_i}^T \\mathbf{z}_i + \\theta^T \\mathbf{H}_{x_i}^T \\mathbf{H}_{x_i} \\theta\n\\end{align}\\]\n\nThe least-squares estimator minimizes the error:\n\\[\\frac{\\partial e(\\theta)}{\\partial \\theta} = 0 \\Leftrightarrow -2\\sum_{i=1}^{N} \\mathbf{H}_{x_i}^T \\mathbf{z}_i + 2\\mathbf{H}_{x_i}^T \\mathbf{H}_{x_i} \\theta = 0 \\Leftrightarrow \\left[\\sum_{i=1}^{N} \\mathbf{H}_{x_i}^T \\mathbf{H}_{x_i}\\right] \\theta = \\sum_{i=1}^{N} \\mathbf{H}_{x_i}^T \\mathbf{z}_i\\]\n\n\n\\[\\theta_{LS} = \\operatorname*{argmin}_{\\theta} e(\\theta) \\Leftrightarrow \\left[\\sum_{i=1}^{N} \\mathbf{H}_{x_i}^T \\mathbf{H}_{x_i}\\right] \\theta_{LS} = \\sum_{i=1}^{N} \\mathbf{H}_{x_i}^T \\mathbf{z}_i\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#example-1-linear-least-squares",
    "href": "lecs/w07/lec07.html#example-1-linear-least-squares",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example #1: Linear Least Squares",
    "text": "Example #1: Linear Least Squares\n\n\n\nExample: we think that the 2D data was generated by a line \\(z = \\theta_{0} + \\theta_{1}x\\) whose parameters we do not know\n\nWe are given data points \\((x_1, z_1), \\dots, (x_N, z_N)\\)\nWe think that the data was generated by a linear parametric function \\(z = h(\\mathbf{\\theta}, x) = \\begin{bmatrix} 1 & x \\end{bmatrix}\\mathbf{\\theta} = \\theta_{0} + \\theta_{1}x\\)\nThis parametric model will have a fitting error: \\[e(\\theta_{0},\\theta_{1})=\\sum_{i=1}^{N}(z_{i}-\\theta_{0}-\\theta_{1}x_{i})^{2}\\]\nThe least-squares estimator minimizes the error:\n\\[\\theta_{LS} = \\operatorname*{argmin}_{\\theta_0, \\theta_1} e(\\theta_0, \\theta_1) \\Leftrightarrow \\left[\\sum_{i=1}^{N} \\begin{bmatrix} 1 \\\\ x_i \\end{bmatrix} \\begin{bmatrix} 1 & x_i \\end{bmatrix}\\right] \\theta_{LS} = \\sum_{i=1}^{N} \\begin{bmatrix} 1 \\\\ x_i \\end{bmatrix} z_i\\]\nWhich is a linear system of 2 equations. If we have at least two data points we can solve for \\(\\theta_{LS}\\) to define the line."
  },
  {
    "objectID": "lecs/w07/lec07.html#example-2-linear-least-squares",
    "href": "lecs/w07/lec07.html#example-2-linear-least-squares",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example #2: Linear Least Squares",
    "text": "Example #2: Linear Least Squares\n\n\n\nExample: we think that the 2D data was generated by a quadratic \\(z = \\theta_{0} + \\theta_{1}x + \\theta_2x^2\\) whose parameters we do not know.\n\nWe are given data points \\((x_1, z_1), \\dots, (x_N, z_N)\\)\nWe think that the data was generated by a linear parametric function \\(z = h(\\mathbf{\\theta},x) = \\begin{bmatrix} 1 & x & x^{2} \\end{bmatrix}\\mathbf{\\theta}=\\theta_{0}+\\theta_{1}x+\\theta_{2}x^{2}\\)\nThis parametric model will have a fitting error:\n\\[e(\\theta_0, \\theta_1, \\theta_2) = \\sum_{i=1}^{N} (z_i - \\theta_0 - \\theta_1 x_i - \\theta_2 x_i^2)^2\\]\nThe least-squares estimator minimizes the error: \\[\\theta_{LS} = \\operatorname*{argmin}_{\\theta_0, \\theta_1, \\theta_2} e(\\theta_0, \\theta_1, \\theta_2) \\Leftrightarrow \\left[\\sum_{i=1}^{N} \\begin{bmatrix} 1 \\\\ x_i \\\\ x_i^2 \\end{bmatrix} \\begin{bmatrix} 1 & x_i & x_i^2 \\end{bmatrix}\\right] \\theta_{LS} = \\sum_{i=1}^{N} \\begin{bmatrix} 1 \\\\ x_i \\\\ x_i^2 \\end{bmatrix} z_i\\]\nWhich is a linear system of 3 equations. If we have at least three data points we can solve for \\(\\theta_{LS}\\) to define the quadratic."
  },
  {
    "objectID": "lecs/w07/lec07.html#todays-agenda-1",
    "href": "lecs/w07/lec07.html#todays-agenda-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\n\nLeast Squares Estimation\n\n\n\nMaximum Likelihood Estimation (MLE)\nMaximum a Posteriori Estimation (MAP)\nBayesian Estimation\nGraphSLAM"
  },
  {
    "objectID": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-1",
    "href": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimating parameters of probability models",
    "text": "Estimating parameters of probability models\n\nIn the occupancy grid mapping problem we wanted to compute \\(p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\) over all possible maps.\nWe can see this problem as a specific instance within a category of problems where we are given data (observations) and we want to “explain” or fit the data using a parametric function.\nThere are typically three ways to work with this type of problems:\n\nMaximum Likelihood parameter estimation (MLE)\n\nLeast Squares\n\nMaximum A Posteriori (MAP) parameter estimation\nBayesian parameter distribution estimation"
  },
  {
    "objectID": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation",
    "href": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maximum Likelihood Parameter Estimation",
    "text": "Maximum Likelihood Parameter Estimation\n\n\n\n\nWe are given data points \\(\\mathbf{d}_{1:N} = \\mathbf{d}_1, \\ldots, \\mathbf{d}_N\\)\nWe think the data has been generated from a probability distribution \\(p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\)\nWe want to find the parameter of the model that maximizes the likelihood function of the data \\[L(\\mathbf{\\theta}) = p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\]\nwhich is a function of theta, not a probability distribution. \\[\\theta_{MLE} = \\underset{\\theta}{\\operatorname*{argmax}} p(\\mathbf{d}_{1:N} | \\theta)\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-1",
    "href": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maximum Likelihood Parameter Estimation",
    "text": "Maximum Likelihood Parameter Estimation\n\n\n\n\n\n\\[\\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}} p(\\mathbf{d}_{1:N}|\\theta)\\]\nFind the parameters of the model that maximize the likelihood function of the data \\[L(\\mathbf{\\theta}) = p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\]\nwhich is a function of theta, not a probability distribution.\n\n\n\nExample: assume we know that 1D data points were generated independently from a Gaussian distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) , but we don’t know the mean and variance. The likelihood function of the data is\n\n\\[L(\\mu, \\sigma) = p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\prod_{i=1}^{N} p(d_i|\\mu, \\sigma) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp(-0.5(d_i - \\mu)^2/\\sigma^2)\\]\n\n\nAnd the maximum-likelihood parameter estimates are\n\\[(\\mu, \\sigma)_{MLE} = \\operatorname*{argmax}_{\\mu,\\sigma} p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\operatorname*{argmax}_{\\mu,\\sigma} \\log p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\operatorname*{argmax}_{\\mu,\\sigma} \\sum_{i=1}^{N} \\log p(d_i|\\mu, \\sigma)\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-2",
    "href": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maximum Likelihood Parameter Estimation",
    "text": "Maximum Likelihood Parameter Estimation\n\n\n\n\n\n\\[\\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}} p(\\mathbf{d}_{1:N}|\\theta)\\]\nFind the parameters of the model that maximize the likelihood function of the data \\[L(\\mathbf{\\theta}) = p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\]\nwhich is a function of theta, not a probability distribution.\n\n\n\nExample: assume we know that 1D data points were generated independently from a Gaussian distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) , but we don’t know the mean and variance. The likelihood function of the data is\n\\[L(\\mu, \\sigma) = p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\prod_{i=1}^{N} p(d_i|\\mu, \\sigma) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp(-0.5(d_i - \\mu)^2/\\sigma^2)\\]\nAnd the maximum-likelihood parameter estimates are\n\\[(\\mu, \\sigma)_{MLE} = \\operatorname*{argmax}_{\\mu,\\sigma} \\sum_{i=1}^{N} \\log p(d_i|\\mu, \\sigma) = \\operatorname*{argmax}_{\\mu,\\sigma} \\left[ -N\\log(\\sqrt{2\\pi}\\sigma) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(d_i - \\mu)^2 \\right]\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-3",
    "href": "lecs/w07/lec07.html#maximum-likelihood-parameter-estimation-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maximum Likelihood Parameter Estimation",
    "text": "Maximum Likelihood Parameter Estimation\n\n\n\n\n\n\\[\\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}} p(\\mathbf{d}_{1:N}|\\theta)\\]\nFind the parameters of the model that maximize the likelihood function of the data \\[L(\\mathbf{\\theta}) = p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\]\nwhich is a function of theta, not a probability distribution.\n\n\n\nExample: assume we know that 1D data points were generated independently from a Gaussian distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) , but we don’t know the mean and variance. The likelihood function of the data is\n\\[L(\\mu, \\sigma) = p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\prod_{i=1}^{N} p(d_i|\\mu, \\sigma) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp(-0.5(d_i - \\mu)^2/\\sigma^2)\\]\nAnd the maximum-likelihood parameter estimates are\n\n\n\\[(\\mu, \\sigma)_{MLE} = \\operatorname*{argmax}_{\\mu,\\sigma} \\sum_{i=1}^{N} \\log p(d_i|\\mu, \\sigma) = \\operatorname*{argmax}_{\\mu,\\sigma} \\left[ -N\\log(\\sqrt{2\\pi}\\sigma) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(d_i - \\mu)^2 \\right]\\]\n\nSet partial derivatives w.r.t. \\(\\mu\\) and \\(\\sigma\\) to zero \n\n\\[\\mu_{MLE}=\\sum_{i=1}^{N}d_{i}/N\\]\n\\[\\sigma_{MLE}^{2}=\\frac{1}{N}\\sum_{i=1}^{N}(d_{i}-\\mu_{MLE})^{2}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#least-squares-as-maximum-likelihood",
    "href": "lecs/w07/lec07.html#least-squares-as-maximum-likelihood",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Least Squares as Maximum Likelihood",
    "text": "Least Squares as Maximum Likelihood\n\n\n\n\n\\[\\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}} p(\\mathbf{d}_{1:N}|\\theta)\\]\nFind the parameters of the model that maximize the likelihood function of the data \\[L(\\mathbf{\\theta}) = p(\\mathbf{d}_{1:N}|\\mathbf{\\theta})\\]\nwhich is a function of theta, not a probability distribution.\n\n\n\nExample: assume we know that 1D data points were generated independently from a Gaussian distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) , but we don’t know the mean and variance. The likelihood function of the data is\n\\[L(\\mu, \\sigma) = p(\\mathbf{d}_{1:N}|\\mu, \\sigma) = \\prod_{i=1}^{N} p(d_i|\\mu, \\sigma) = \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp(-0.5(d_i - \\mu)^2/\\sigma^2)\\]\nAnd the maximum-likelihood parameter estimates are\n\n\n\n\\[(\\mu, \\sigma)_{MLE} = \\operatorname*{argmax}_{\\mu,\\sigma} \\sum_{i=1}^{N} \\log p(d_i|\\mu, \\sigma) = \\operatorname*{argmax}_{\\mu,\\sigma} \\left[ -N\\log(\\sqrt{2\\pi}\\sigma) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(d_i - \\mu)^2 \\right]\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-2",
    "href": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimating parameters of probability models",
    "text": "Estimating parameters of probability models\n\nIn the occupancy grid mapping problem we wanted to compute \\(p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\) over all possible maps.\nWe can see this problem as a specific instance within a category of problems where we are given data (observations) and we want to “explain” or fit the data using a parametric function.\nThere are typically three ways to work with this type of problems:\n\nMaximum Likelihood parameter estimation (MLE)\n\nLeast Squares\n\nMaximum A Posteriori (MAP) parameter estimation\nBayesian parameter distribution estimation"
  },
  {
    "objectID": "lecs/w07/lec07.html#maximum-a-posteriori-parameter-estimation",
    "href": "lecs/w07/lec07.html#maximum-a-posteriori-parameter-estimation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Maximum A Posteriori Parameter Estimation",
    "text": "Maximum A Posteriori Parameter Estimation\n\n\nLikelihood\n\\(p(d|\\theta)\\)\n\nPrior\n\\(p(\\theta)\\)\n\nPosterior\n\\(p(\\theta|d) \\propto p(d|\\theta)p(\\theta)\\)\n\n\n\n\\[\\begin{align}\n\\theta_{MAP} &= \\operatorname*{argmax}_{\\theta} p(\\theta|\\mathbf{d}_{1:N}) \\\\\n&= \\operatorname*{argmax}_{\\theta} \\left[ \\frac{p(\\mathbf{d}_{1:N}|\\theta)p(\\theta)}{p(\\mathbf{d}_{1:N})} \\right] \\\\\n&= \\operatorname*{argmax}_{\\theta} \\left[ p(\\mathbf{d}_{1:N}|\\theta)p(\\theta) \\right]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-3",
    "href": "lecs/w07/lec07.html#estimating-parameters-of-probability-models-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimating parameters of probability models",
    "text": "Estimating parameters of probability models\n\nIn the occupancy grid mapping problem we wanted to compute \\(p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\) over all possible maps.\nWe can see this problem as a specific instance within a category of problems where we are given data (observations) and we want to “explain” or fit the data using a parametric function.\nThere are typically three ways to work with this type of problems:\n\nMaximum Likelihood parameter estimation (MLE)\n\nLeast Squares\n\nMaximum A Posteriori (MAP) parameter estimation\nBayesian parameter distribution estimation"
  },
  {
    "objectID": "lecs/w07/lec07.html#bayesian-parameter-estimation",
    "href": "lecs/w07/lec07.html#bayesian-parameter-estimation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayesian parameter estimation",
    "text": "Bayesian parameter estimation\n\nBoth MLE and MAP estimators give you a single point estimate .\nBut there might be many parameters that are compatible with the data.\nInstead of point estimates, compute a distribution of estimates that explain the data\n\n\n\nBayesian parameter estimation:\n\n\\[p(\\theta|\\mathbf{d}_{1:N}) = \\frac{p(\\mathbf{d}_{1:N}|\\theta)p(\\theta)}{p(\\mathbf{d}_{1:N})}\\]\n\nThe probability of the\ndata is usually hard to\ncompute. But it does not\ndepend on the parameter\ntheta, so it is treated as a\nnormalizing factor, and we\ncan still compute how the\nposterior varies with theta."
  },
  {
    "objectID": "lecs/w07/lec07.html#bayesian-parameter-estimation-1",
    "href": "lecs/w07/lec07.html#bayesian-parameter-estimation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Bayesian parameter estimation",
    "text": "Bayesian parameter estimation\n\nBoth MLE and MAP estimators give you a single point estimate .\nBut there might be many parameters that are compatible with the data.\nInstead of point estimates, compute a distribution of estimates that explain the data\nBayesian parameter estimation:\n\n\\[p(\\theta|\\mathbf{d}_{1:N}) = \\frac{p(\\mathbf{d}_{1:N}|\\theta)p(\\theta)}{p(\\mathbf{d}_{1:N})}\\]\n\nThis is what we used in occupancy grid mapping, when we approximated\n\n\\[p(\\mathbf{m}|\\mathbf{z}_{1:t}, \\mathbf{x}_{1:t})\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#todays-agenda-2",
    "href": "lecs/w07/lec07.html#todays-agenda-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\n\nLeast Squares Estimation\nMaximum Likelihood Estimation (MLE)\nMaximum a Posteriori Estimation (MAP)\nBayesian Estimation\n\n\n\nGraphSLAM"
  },
  {
    "objectID": "lecs/w07/lec07.html#goal",
    "href": "lecs/w07/lec07.html#goal",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Goal",
    "text": "Goal\n\nEnable a robot to simultaneously build a map of its environment and estimate where it is in that map.\nThis is called SLAM (Simultaneous Localization And Mapping)\nToday we are going to look at the batch version, i.e. collect all measurements and controls, and later form an estimate of the states and the map.\nWe are going to solve SLAM using least squares"
  },
  {
    "objectID": "lecs/w07/lec07.html#examples-of-slam-systems",
    "href": "lecs/w07/lec07.html#examples-of-slam-systems",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of SLAM systems",
    "text": "Examples of SLAM systems\n\n\n \n\n\nMORESLAM system, McGill, 2016"
  },
  {
    "objectID": "lecs/w07/lec07.html#section",
    "href": "lecs/w07/lec07.html#section",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "MORESLAM system, McGill, 2016"
  },
  {
    "objectID": "lecs/w07/lec07.html#examples-of-slam-systems-1",
    "href": "lecs/w07/lec07.html#examples-of-slam-systems-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of SLAM systems",
    "text": "Examples of SLAM systems"
  },
  {
    "objectID": "lecs/w07/lec07.html#examples-of-slam-systems-2",
    "href": "lecs/w07/lec07.html#examples-of-slam-systems-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of SLAM systems",
    "text": "Examples of SLAM systems\n\nSource Code: https://github.com/erik-nelson/blam"
  },
  {
    "objectID": "lecs/w07/lec07.html#examples-of-slam-systems-3",
    "href": "lecs/w07/lec07.html#examples-of-slam-systems-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of SLAM systems",
    "text": "Examples of SLAM systems\nGoogle Cartographer: 2D and 3D laser SLAM\n\nCode: https://github.com/googlecartographer/cartographer"
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-possible-problem-definitions",
    "href": "lecs/w07/lec07.html#slam-possible-problem-definitions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: possible problem definitions",
    "text": "SLAM: possible problem definitions\n\nSmoothing/Batch/Full SLAM\n\n\\[p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\]\n\n\n\n\nFiltering SLAM\n\n\\[p(\\mathbf{x}_t, \\mathbf{m}_t \\mid \\mathbf{z}_{0:t}, \\mathbf{u}_{0:t-1}, \\mathbf{x}_0)\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution",
    "href": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: Multivariate Gaussian Distribution",
    "text": "Background: Multivariate Gaussian Distribution\n\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}}\\exp\\left(-0.5(\\mathbf{x}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right)\\)\n\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}} \\exp\\left(-0.5\\|\\mathbf{x} - \\mathbf{\\mu}\\|_{\\mathbf{\\Sigma}}^2\\right)\\)\n\nShortcut notation: \\(\\|x\\|_{\\Sigma}^{2}=x^{T}\\Sigma^{-1}x\\)\n\n\n\n\nFrom “Computer Vision: Models, Learning, and Inference” Simon Prince\nNote: The shapes of these covariances are important, you should\nknow them well. In particular, when are x1 and x2 correlated?"
  },
  {
    "objectID": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-1",
    "href": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: Multivariate Gaussian Distribution",
    "text": "Background: Multivariate Gaussian Distribution\n\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}}\\exp\\left(-0.5(\\mathbf{x}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right)\\)\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}} \\exp\\left(-0.5\\|\\mathbf{x} - \\mathbf{\\mu}\\|_{\\mathbf{\\Sigma}}^2\\right)\\)\n\nShortcut notation: \\(\\|x\\|_{\\Sigma}^{2}=x^{T}\\Sigma^{-1}x\\)\n\n\n\nFrom “Computer Vision: Models, Learning, and Inference” Simon Prince\nx1 and x2 are correlated when the shape of the ellipse is rotated,\ni.e. when there are nonzero off-diagonal terms in the covariance matrix.\nIn this example, (e) and (f)"
  },
  {
    "objectID": "lecs/w07/lec07.html#confidence-regions",
    "href": "lecs/w07/lec07.html#confidence-regions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Confidence regions",
    "text": "Confidence regions\n\nTo quantify confidence and uncertainty define a confidence region R about a point x (e.g. the mode) such that at a confidence level c ≤ 1\n\n\\[p(x \\in R) = c\\]\n\nwe can then say (for example) there is a 99% probability that the true value is in R\ne.g. for a univariate normal distribution \\(N(\\mu, \\sigma^2)\\)\n\n\n\n\\(p(|x - \\mu| &lt; \\sigma) \\approx 0.67\\)\n\\(p(|x - \\mu| &lt; 2\\sigma) \\approx 0.95\\)\n\\(p(|x - \\mu| &lt; 3\\sigma) \\approx 0.997\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#expectation",
    "href": "lecs/w07/lec07.html#expectation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Expectation",
    "text": "Expectation\n\nExpected value of a random variable X:\n\n\\[\\mathbb{E}_{x\\sim p(X)}[X]=\\int_{x}xp(X=x)dx\\]\n\nE is linear: \\(\\quad \\mathbb{E}_{x \\sim p(X)}[X + c] = \\mathbb{E}_{x \\sim p(X)}[X] + c\\)\n\n\\(\\qquad\\qquad\\quad \\mathbb{E}_{x \\sim p(X)}[AX + b] = A\\mathbb{E}_{x \\sim p(X)}[X] + b\\)\n\nIf X,Y are independent then [Note: inverse does not hold]\n\n\\[\\mathbb{E}_{x,y \\sim p(X,Y)}[XY] = \\mathbb{E}_{x \\sim p(X)}[X] \\mathbb{E}_{x \\sim p(Y)}[Y]\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#covariance-matrix",
    "href": "lecs/w07/lec07.html#covariance-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\n\nMeasures linear dependence between random variables X, Y. Does not measure independence.\n\n\\[\\text{Cov}[X, Y] = E[XY] - E[X]E[Y]\\]\n\nVariance of X\n\n\\[\\begin{align}\n& \\text{Var}[X] = \\text{Cov}[X] = \\text{Cov}[X, X] = E[X^2] - E[X]^2 \\\\\n& \\text{Cov}[AX + b] = A\\text{Cov}[X]A^T \\\\\n& \\text{Cov}[X + Y] = \\text{Cov}[X] + \\text{Cov}[Y] - 2\\text{Cov}[X, Y]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#covariance-matrix-1",
    "href": "lecs/w07/lec07.html#covariance-matrix-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\n\nMeasures linear dependence between random variables X, Y. Does not measure independence.\n\n\\[\\text{Cov}[X, Y] = E[XY] - E[X]E[Y]\\]\n\nEntry (i,j) of the covariance matrix measures whether changes in variable \\(X_i\\) co-occur with changes in variable \\(Y_j\\)\nIt does not measure whether one causes the other."
  },
  {
    "objectID": "lecs/w07/lec07.html#correlation-does-not-imply-causation",
    "href": "lecs/w07/lec07.html#correlation-does-not-imply-causation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Correlation does not imply causation",
    "text": "Correlation does not imply causation"
  },
  {
    "objectID": "lecs/w07/lec07.html#correlation-does-not-imply-causation-1",
    "href": "lecs/w07/lec07.html#correlation-does-not-imply-causation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Correlation does not imply causation",
    "text": "Correlation does not imply causation"
  },
  {
    "objectID": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-2",
    "href": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: Multivariate Gaussian Distribution",
    "text": "Background: Multivariate Gaussian Distribution\n\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}}\\exp\\left(-0.5(\\mathbf{x}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right)\\)\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}} \\exp\\left(-0.5\\|\\mathbf{x} - \\mathbf{\\mu}\\|_{\\mathbf{\\Sigma}}^2\\right)\\)\n\nFor multivariate Gaussians:\n\\[\\begin{align}\nE[\\mathbf{x}] = \\mu \\\\\n\\text{Cov}[\\mathbf{x}] = \\Sigma\n\\end{align}\\]\n\n\n\nFrom “Computer Vision: Models, Learning, and Inference” Simon Prince"
  },
  {
    "objectID": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-3",
    "href": "lecs/w07/lec07.html#background-multivariate-gaussian-distribution-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: Multivariate Gaussian Distribution",
    "text": "Background: Multivariate Gaussian Distribution\n\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}}\\exp\\left(-0.5(\\mathbf{x}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right)\\)\n\n\\(p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2}\\det(\\mathbf{\\Sigma})^{1/2}} \\exp\\left(-0.5\\|\\mathbf{x} - \\mathbf{\\mu}\\|_{\\mathbf{\\Sigma}}^2\\right)\\)\n\nSince we have 2D examples here:\n\\[\\begin{align}\n\\text{Cov}[\\mathbf{x}] = \\boldsymbol{\\Sigma} &= \\begin{bmatrix}\n\\text{Cov}[x_1, x_1] & \\text{Cov}[x_1, x_2] \\\\\n\\text{Cov}[x_2, x_1] & \\text{Cov}[x_2, x_2]\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n\\text{Var}[x_1] & \\text{Cov}[x_1, x_2] \\\\\n\\text{Cov}[x_2, x_1] & \\text{Var}[x_2]\n\\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-graph-representation",
    "href": "lecs/w07/lec07.html#slam-graph-representation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: graph representation",
    "text": "SLAM: graph representation\n\n\n\n\nMap \\(\\mathbf{m} = \\{\\mathbf{m}_0, \\mathbf{m}_1\\}\\) consists of landmarks that are easily identifiable and cannot be mistaken for one another.\ni.e. we are avoiding\nthe data association\nproblem here."
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-graph-representation-1",
    "href": "lecs/w07/lec07.html#slam-graph-representation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: graph representation",
    "text": "SLAM: graph representation\n\n\n\n\nMap \\(\\mathbf{m} = \\{\\mathbf{m}_0, \\mathbf{m}_1\\}\\) consists of landmarks that are easily identifiable and cannot be mistaken for one another."
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-graph-representation-2",
    "href": "lecs/w07/lec07.html#slam-graph-representation-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: graph representation",
    "text": "SLAM: graph representation\n\n\n\n\nNotice that the graph is mostly sparse as long as not many states observe the same landmark.\n\nThat implies that there are many symbolic dependencies between random variables in \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) that are not necessary and can be dropped."
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\mathbf{x}^*_{1:T}, \\mathbf{m}^* = \\underset{\\mathbf{x}_{1:T},\\mathbf{m}}{\\operatorname{argmax}} p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0)\\]\nSee least\nsquares lecture"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-1",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^*, \\mathbf{m}^* &= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m} | \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\frac{p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)}{p(\\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)} \\right]\n\\end{align}\\]\nby definition\nof conditional\ndistribution"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-2",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^*, \\mathbf{m}^* &= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m} | \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\frac{p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)}{p(\\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)} \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)\n\\end{align}\\]\ndenominator does\nnot depend on\noptimization\nvariables"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-3",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^*, \\mathbf{m}^* &= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m} | \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\frac{p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)}{p(\\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)} \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\prod_{t=1}^{T} p(\\mathbf{x}_t|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) \\prod_{t=0}^{T} \\prod_{\\mathbf{z}_t^{(k)} \\in \\mathbf{z}_t} p(\\mathbf{z}_t^{(k)}|\\mathbf{x}_t, \\mathbf{m}_k) \\right]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-4",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^*, \\mathbf{m}^* &= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m} | \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\frac{p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)}{p(\\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)} \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\prod_{t=1}^{T} p(\\mathbf{x}_t|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) \\prod_{t=0}^{T} \\prod_{z_t^{(k)} \\in \\mathbf{z}_t} p(z_t^{(k)}|\\mathbf{x}_t, \\mathbf{m}_k) \\right]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-5",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\n\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^*, \\mathbf{m}^* &= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m} | \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\frac{p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)}{p(\\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0)} \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}|\\mathbf{x}_0) \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\prod_{t=1}^{T} p(\\mathbf{x}_t|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) \\prod_{t=0}^{T} \\prod_{\\mathbf{z}_t^{(k)} \\in \\mathbf{z}_t} p(\\mathbf{z}_t^{(k)}|\\mathbf{x}_t, \\mathbf{m}_k) \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T}, \\mathbf{m}} \\left[ \\sum_{t=1}^{T} \\log p(\\mathbf{x}_t|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) + \\sum_{t=0}^{T} \\sum_{\\mathbf{z}_t^{(k)} \\in \\mathbf{z}_t} \\log p(\\mathbf{z}_t^{(k)}|\\mathbf{x}_t, \\mathbf{m}_k) \\right]\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-6",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-maximum-a-posteriori-estimate-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate",
    "text": "GraphSLAM: SLAM as a Maximum A Posteriori Estimate\n\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\mathbf{x}_{1:T}^{*},\\mathbf{m}^{*} = \\underset{\\mathbf{x}_{1:T},\\mathbf{m}}{\\operatorname{argmax}}\\left[\\sum_{t=1}^{T}\\log p(\\mathbf{x}_{t}|\\mathbf{x}_{t-1},\\mathbf{u}_{t-1})+\\sum_{t=0}^{T}\\sum_{\\mathbf{z}_{t}^{(k)}\\in \\mathbf{z}_{t}}\\log p(\\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t},\\mathbf{m}_{k})\\right]\\]\n\n\nMain GraphSLAM assumptions:\n\n1. Uncertainty in the dynamics model is Gaussian\n\\(\\mathbf{x}_{t}=f(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1})+\\mathbf{w}_{t}\\)\n\\(\\mathbf{w}_{t} \\sim \\mathcal{N}(0, \\mathbf{R}_{t})\\)\nso\n\\(\\mathbf{x}_t|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1} \\sim \\mathcal{N}(\\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}), \\mathbf{R}_t)\\)\n\n2. Uncertainty in the sensor model is Gaussian\n\\(\\mathbf{z}_t^{(k)} = \\mathbf{h}(\\mathbf{x}_t, \\mathbf{m}_k) + \\mathbf{v}_t\\)\n\\(\\mathbf{v}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_t)\\)\nso\n\\(\\mathbf{z}_t^{(k)} | \\mathbf{x}_t, \\mathbf{m}_k \\sim \\mathcal{N}(\\mathbf{h}(\\mathbf{x}_t, \\mathbf{m}_k), \\mathbf{Q}_t)\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-noiseerrors",
    "href": "lecs/w07/lec07.html#slam-noiseerrors",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: noise/errors",
    "text": "SLAM: noise/errors\n\n\n\n\n\\(\\mathbf{x}_1|\\mathbf{x}_0, \\mathbf{u}_0 \\sim \\mathcal{N}(\\mathbf{f}(\\mathbf{x}_0, \\mathbf{u}_0), \\mathbf{R}_0)\\)\nExpected to end up at \\(\\mathbf{x}_1 = \\mathbf{f}(\\mathbf{x}_0, \\mathbf{u}_0)\\) from \\(\\mathbf{x}_0\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-noiseerrors-1",
    "href": "lecs/w07/lec07.html#slam-noiseerrors-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: noise/errors",
    "text": "SLAM: noise/errors\n\n\n\n\n\\(\\mathbf{x}_1|\\mathbf{x}_0, \\mathbf{u}_0 \\sim \\mathcal{N}(\\mathbf{f}(\\mathbf{x}_0, \\mathbf{u}_0), \\mathbf{R}_0)\\)\nExpected to end up at \\(\\mathbf{x}_1 = \\mathbf{f}(\\mathbf{x}_0, \\mathbf{u}_0)\\) from \\(\\mathbf{x}_0\\) but we might end up around it, within the ellipse defined by the covariance matrix \\(\\mathbf{R}_0\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#slam-noiseerrors-2",
    "href": "lecs/w07/lec07.html#slam-noiseerrors-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "SLAM: noise/errors",
    "text": "SLAM: noise/errors\n\n\n\n\n\n\\(\\mathbf{z}_1^{(0)}|\\mathbf{x}_1, \\mathbf{m}_0 \\sim \\mathcal{N}(\\mathbf{h}(\\mathbf{x}_1, \\mathbf{m}_0), \\mathbf{Q}_1)\\)\nExpected to get measurement \\(\\mathbf{h}(\\mathbf{x}_1, \\mathbf{m}_0)\\) at state \\(\\mathbf{x}_1\\) but it might be somewhere within the ellipse defined by the covariance matrix \\(\\mathbf{Q}_1\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-least-squares-problem",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-least-squares-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a least squares problem",
    "text": "GraphSLAM: SLAM as a least squares problem\n\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^{*}, \\mathbf{m}^{*} &= \\underset{\\mathbf{x}_{1:T}, \\mathbf{m}}{\\operatorname{argmax}} \\left[ \\sum_{t=1}^{T} \\log p(\\mathbf{x}_{t}|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) + \\sum_{t=0}^{T} \\sum_{\\mathbf{z}_{t}^{(k)} \\in \\mathbf{z}_{t}} \\log p(\\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t}, \\mathbf{m}_{k}) \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T},\\mathbf{m}} \\left[ - \\sum_{t=1}^{T} \\|\\mathbf{x}_t - \\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1})\\|_{\\mathbf{{R}}_t}^2 - \\sum_{t=0}^{T} \\sum_{z_t^{(k)} \\in \\mathbf{z}_t} \\|\\mathbf{z}_t^{(k)} - \\mathbf{h}(\\mathbf{x}_t, \\mathbf{m}_k)\\|_{\\mathbf{{Q}}_t}^2 \\right]\n\\end{align}\\]\n\nNotation:\n\\(\\mathbf{x}^T \\mathbf{Q}^{-1} \\mathbf{x} = ||\\mathbf{x}||_{\\mathbf{Q}}^2\\)\n\n\n\\(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t-1} \\sim \\mathcal{N}(\\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}), \\mathbf{R}_t) \\qquad\\qquad\\qquad \\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t}, \\mathbf{m}_{k} \\sim \\mathcal{N}(\\mathbf{h}(\\mathbf{x}_{t}, \\mathbf{m}_{k}), \\mathbf{Q}_{t})\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-slam-as-a-least-squares-problem-1",
    "href": "lecs/w07/lec07.html#graphslam-slam-as-a-least-squares-problem-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: SLAM as a least squares problem",
    "text": "GraphSLAM: SLAM as a least squares problem\n\nInstead of computing the posterior \\(p(\\mathbf{x}_{1:T}, \\mathbf{m} \\mid \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0})\\) we are going to compute its max\n\\[\\begin{align}\n\\mathbf{x}_{1:T}^{*}, \\mathbf{m}^{*} &= \\underset{\\mathbf{x}_{1:T}, \\mathbf{m}}{\\operatorname{argmax}} \\left[ \\sum_{t=1}^{T} \\log p(\\mathbf{x}_{t}|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) + \\sum_{t=0}^{T} \\sum_{\\mathbf{z}_{t}^{(k)} \\in \\mathbf{z}_{t}} \\log p(\\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t}, \\mathbf{m}_{k}) \\right] \\\\\n&= \\operatorname*{argmax}_{\\mathbf{x}_{1:T},\\mathbf{m}} \\left[ - \\sum_{t=1}^{T} \\|\\mathbf{x}_t - \\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1})\\|_{\\mathbf{{R}}_t}^2 - \\sum_{t=0}^{T} \\sum_{z_t^{(k)} \\in \\mathbf{z}_t} \\|\\mathbf{z}_t^{(k)} - \\mathbf{h}(\\mathbf{x}_t, \\mathbf{m}_k)\\|_{\\mathbf{{Q}}_t}^2 \\right] \\\\\n&= \\underset{\\mathbf{x}_{1:T}, \\mathbf{m}}{\\operatorname{argmin}} \\left[ \\sum_{t=1}^{T} \\|\\mathbf{x}_t - \\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1})\\|_{\\mathbf{R}_t}^2 + \\sum_{t=0}^{T} \\sum_{\\mathbf{z}_t^{(k)} \\in \\mathbf{z}_t} \\|\\mathbf{z}_t^{(k)} - \\mathbf{h}(\\mathbf{x}_t, \\mathbf{m}_k)\\|_{\\mathbf{Q}_t}^2 \\right]\n\\end{align}\\]\n\nNotation:\n\\(\\mathbf{x}^T \\mathbf{Q}^{-1} \\mathbf{x} = ||\\mathbf{x}||_{\\mathbf{Q}}^2\\)\n\n\n\\(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t-1} \\sim \\mathcal{N}(\\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}), \\mathbf{R}_t) \\qquad\\qquad\\qquad \\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t}, \\mathbf{m}_{k} \\sim \\mathcal{N}(\\mathbf{h}(\\mathbf{x}_{t}, \\mathbf{m}_{k}), \\mathbf{Q}_{t})\\)"
  },
  {
    "objectID": "lecs/w07/lec07.html#graphslam-example",
    "href": "lecs/w07/lec07.html#graphslam-example",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "GraphSLAM: example",
    "text": "GraphSLAM: example\n\n\n\n\nNeed to minimize the sum of the following quadratic terms:\n\\[\\begin{align}\n& ||\\mathbf{x}_1 - \\mathbf{f}(\\mathbf{x}_0, \\mathbf{u}_0)||_{\\mathbf{R}_1}^2 \\\\\n& ||\\mathbf{x}_2 - \\mathbf{f}(\\mathbf{x}_1, \\mathbf{u}_1)||_{\\mathbf{R}_2}^2 \\\\\n& ||\\mathbf{x}_3 - \\mathbf{f}(\\mathbf{x}_2, \\mathbf{u}_2)||_{\\mathbf{R}_3}^2 \\\\\n& ||\\mathbf{z}_0^{(0)} - \\mathbf{h}(\\mathbf{x}_0, \\mathbf{m}_0)||_{\\mathbf{Q}_0}^2 \\\\\n& ||\\mathbf{z}_1^{(0)} - \\mathbf{h}(\\mathbf{x}_1, \\mathbf{m}_0)||_{\\mathbf{Q}_1}^2 \\\\\n& ||\\mathbf{z}_1^{(1)} - \\mathbf{h}(\\mathbf{x}_1, \\mathbf{m}_1)||_{\\mathbf{Q}_1}^2 \\\\\n& ||\\mathbf{z}_2^{(1)} - \\mathbf{h}(\\mathbf{x}_2, \\mathbf{m}_1)||_{\\mathbf{Q}_2}^2\n\\end{align}\\]\nwith respect to variables: \\(\\mathbf{x_1 \\quad x_2 \\quad x_3 \\quad m_0 \\quad m_1}\\)\ninitial state \\(\\mathbf{x}_0\\) is given\n\n\nCovariance matrices \\(\\mathbf{R_t, Q_t}\\)\nare problem-dependent, but\nthey usually do not change\nwith time."
  },
  {
    "objectID": "lecs/w07/lec07.html#examples-of-dynamics-and-sensor-models",
    "href": "lecs/w07/lec07.html#examples-of-dynamics-and-sensor-models",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of dynamics and sensor models",
    "text": "Examples of dynamics and sensor models\n\n\n\\(\\mathbf{x}_t = \\mathbf{f}(\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) + \\mathbf{w}_t\\)\n\\(\\mathbf{z}_{t}^{(k)} = \\mathbf{h}(\\mathbf{x}_{t}, \\mathbf{m}_{k}) + \\mathbf{v}_{t}\\)\n\nCan be any of the dynamical systems we saw in Lecture 2.\n\\(\\mathbf{z}_t^{(k)}\\) can be any of the sensors we saw in Lecture 4:\n\nLaser scan \\(\\{(r_{i},\\theta_{i})\\}_{i=1:K}\\) where \\(\\mathbf{m}_k\\) is an occupancy grid\nRange and bearing \\((r, \\theta)\\) to the landmark \\(\\mathbf{m}_k = (x_k, y_k, z_k)\\)\nBearing measurements from images\nAltitude/Depth\nGyroscope\nAccelerometer"
  },
  {
    "objectID": "lecs/w07/lec07.html#appendix-1",
    "href": "lecs/w07/lec07.html#appendix-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\nClaim:\n\n\\[p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_{0}) = p(\\mathbf{x}_{0}) \\prod_{t=1}^{T} p(\\mathbf{x}_{t}|\\mathbf{x}_{t-1}, \\mathbf{u}_{t-1}) \\prod_{t=0}^{T} \\prod_{\\mathbf{z}_{t}^{(k)}\\in \\mathbf{z}_{t}} p(\\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t}, \\mathbf{m}_{k})\\]\n\n\n\n\nProof:\n\\[\\begin{align}\np(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) &= p(\\mathbf{z}_T | \\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-1}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\, p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-1}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= p(\\mathbf{z}_T | \\mathbf{x}_T, \\mathbf{m}) \\, p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-1}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= p(\\mathbf{z}_T | \\mathbf{x}_T, \\mathbf{m}) \\, p(\\mathbf{z}_{T-1} | \\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-2}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\, p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-2}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= p(\\mathbf{z}_T | \\mathbf{x}_T, \\mathbf{m}) \\, p(\\mathbf{z}_{T-1} | \\mathbf{x}_{T-1}, \\mathbf{m}) \\, p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{z}_{0:T-2}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&\\quad \\dots \\\\\n&= \\prod_{t=0}^{T} p(\\mathbf{z}_t | \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{x}_{1:T}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\prod_{t=0}^{T} p(\\mathbf{z}_t | \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{x}_T | \\mathbf{x}_{1:T-1}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\, p(\\mathbf{x}_{1:T-1}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\prod_{t=0}^{T} p(\\mathbf{z}_t | \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{x}_T | \\mathbf{x}_{T-1}, \\mathbf{u}_{T-1}) \\, p(\\mathbf{x}_{1:T-1}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&= \\prod_{t=0}^{T} p(\\mathbf{z}_t | \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{x}_T | \\mathbf{x}_{T-1}, \\mathbf{u}_{T-1}) \\, p(\\mathbf{x}_{T-1} | \\mathbf{x}_{T-2}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\, p(\\mathbf{x}_{1:T-2}, \\mathbf{m}, \\mathbf{u}_{0:T-1}, \\mathbf{x}_0) \\\\\n&\\quad \\dots \\\\\n&= \\left[ \\prod_{t=0}^{T} p(\\mathbf{z}_t | \\mathbf{x}_t, \\mathbf{m}) \\right] p(\\mathbf{x}_0) \\prod_{t=1}^{T} p(\\mathbf{x}_t | \\mathbf{x}_{t-1}, \\mathbf{u}_{t-1})\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w07/lec07.html#appendix-1-1",
    "href": "lecs/w07/lec07.html#appendix-1-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\n\nClaim: \\[p(\\mathbf{z}_{t}|\\mathbf{x}_{t},\\mathbf{m}) = \\prod_{\\mathbf{z}_{t}^{(k)}\\in\\mathbf{z}_{t}}p(\\mathbf{z}_{t}^{(k)}|\\mathbf{x}_{t},\\mathbf{m}_{k})\\]\n\nwhere \\(\\mathbf{z}_t = \\left\\{ \\mathbf{z}_t^{(k)} \\text{ iff landmark } \\mathbf{m}_k \\text{ was observed} \\right\\}\\)\n\\(\\mathbf{m} = \\{\\text{landmarks } \\mathbf{m}_k\\}\\)\n\n\nProof:\nSuppose without loss of generality that \\(\\mathbf{z}_t = \\left\\{ \\mathbf{z}_t^{(k)}, k = 1...K \\right\\}\\) and \\(\\mathbf{m} = \\{\\mathbf{m}_{k}, k = 1...K\\}\\)\ni.e. that all landmarks were observed from the state at time t. Then:\n\\[\\begin{align}\np(\\mathbf{z}_t^{(1)}, \\ldots, \\mathbf{z}_t^{(K)}|\\mathbf{x}_t, \\mathbf{m}) &= p(\\mathbf{z}_t^{(1)}|\\mathbf{z}_t^{(2)}, \\ldots, \\mathbf{z}_t^{(K)}, \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{z}_t^{(2)}, \\ldots, \\mathbf{z}_t^{(K)}|\\mathbf{x}_t, \\mathbf{m}) \\\\\n&= p(\\mathbf{z}_t^{(1)}|\\mathbf{x}_t, \\mathbf{m}_1) \\, p(\\mathbf{z}_t^{(2)}, \\ldots, \\mathbf{z}_t^{(K)}|\\mathbf{x}_t, \\mathbf{m}) \\\\\n&= p(\\mathbf{z}_t^{(1)}|\\mathbf{x}_t, \\mathbf{m}_1) \\, p(\\mathbf{z}_t^{(2)}|\\mathbf{z}_t^{(3)}, \\ldots, \\mathbf{z}_t^{(K)}, \\mathbf{x}_t, \\mathbf{m}) \\, p(\\mathbf{z}_t^{(3)}, \\ldots, \\mathbf{z}_t^{(K)}|\\mathbf{x}_t, \\mathbf{m}) \\\\\n&= p(\\mathbf{z}_t^{(1)}|\\mathbf{x}_t, \\mathbf{m}_1) \\, p(\\mathbf{z}_t^{(2)}|\\mathbf{x}_t, \\mathbf{m}_2) \\, p(\\mathbf{z}_t^{(3)}, \\ldots, \\mathbf{z}_t^{(K)}|\\mathbf{x}_t, \\mathbf{m}) \\\\\n&\\quad \\vdots \\\\\n&= \\prod_{k=1}^{K} p(\\mathbf{z}_t^{(k)}|\\mathbf{x}_t, \\mathbf{m}_k)\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#section",
    "href": "lecs/w02/lec02.html#section",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "Today’s slides borrow parts of Paul Furgale’s “Representing robot pose” presentation:\nhttp://paulfurgale.info/news/2014/6/9/representing-robot-pose-the-good-the-bad-and-the-ugly\nYou should absolutely read it."
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda",
    "href": "lecs/w02/lec02.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n• Frames of reference\n• Ways to represent rotations\n• Simplified models of vehicles\n• Forward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#d-frames-of-reference-are-everywhere-in-robotics",
    "href": "lecs/w02/lec02.html#d-frames-of-reference-are-everywhere-in-robotics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "3D frames of reference are everywhere in robotics",
    "text": "3D frames of reference are everywhere in robotics"
  },
  {
    "objectID": "lecs/w02/lec02.html#right-handed-vs-left-handed-frames",
    "href": "lecs/w02/lec02.html#right-handed-vs-left-handed-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Right-handed vs left-handed frames",
    "text": "Right-handed vs left-handed frames\n\n\nUnless otherwise specified,\nwe use right-handed\nframes in robotics"
  },
  {
    "objectID": "lecs/w02/lec02.html#why-do-we-need-to-use-so-many-frames",
    "href": "lecs/w02/lec02.html#why-do-we-need-to-use-so-many-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why do we need to use so many frames?",
    "text": "Why do we need to use so many frames?\n\n\n\nBecause we want to reason and express quantities relative to their local configuration.\nFor example: “grab the bottle behind the cereal bowl”\nThis lecture is about defining and representing frames of reference and reasoning about how to express quantities in one frame to quantities in the other."
  },
  {
    "objectID": "lecs/w02/lec02.html#rigid-body-motion",
    "href": "lecs/w02/lec02.html#rigid-body-motion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rigid-body motion",
    "text": "Rigid-body motion\n\nMotion that can be described by a rotation and translation.\nAll the parts making up the body move in unison, and there are no deformations.\nRepresenting rotations, translations, and vectors in a given frame of reference is often a source of frustration and bugs in robot software because there are so many options."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-answer-is-meaningless-unless-i-provide-a-definition-of-the-coordinate-frames",
    "href": "lecs/w02/lec02.html#the-answer-is-meaningless-unless-i-provide-a-definition-of-the-coordinate-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The answer is meaningless unless I provide a definition of the coordinate frames",
    "text": "The answer is meaningless unless I provide a definition of the coordinate frames"
  },
  {
    "objectID": "lecs/w02/lec02.html#section-2",
    "href": "lecs/w02/lec02.html#section-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "Color convention\nfor frames\n\n\nMoving body (robot) frame\n\n\nFixed world frame"
  },
  {
    "objectID": "lecs/w02/lec02.html#always-provide-a-frame-diagram",
    "href": "lecs/w02/lec02.html#always-provide-a-frame-diagram",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Always provide a frame diagram",
    "text": "Always provide a frame diagram"
  },
  {
    "objectID": "lecs/w02/lec02.html#inertial-frames-of-reference",
    "href": "lecs/w02/lec02.html#inertial-frames-of-reference",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inertial frames of reference",
    "text": "Inertial frames of reference\n\nG, the global frame of reference is fixed, i.e. with zero velocity in our previous example.\nBut, in general it can move as long as it has zero acceleration. Such a frame is called an “inertial” frame of reference.\nNewton’s laws hold for inertial reference frames only. For reference frames with non-constant velocity we need the theory of General Relativity.\nSo, make sure that your global frame of reference is inertial, preferably fixed."
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda-1",
    "href": "lecs/w02/lec02.html#todays-agenda-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\n\nFrames of reference\n\n\n\nWays to represent rotations\nSimplified models of vehicles\nForward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-euler-angles",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-euler-angles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Euler Angles",
    "text": "Representing Rotations in 3D: Euler Angles"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\nNeed to specify the axes which each angle refers to.\nThere are 12 different valid combinations of fundamental rotations. Here are the possible axes:\nz-x-z, x-y-x, y-z-y, z-y-z, x-z-x, y-x-y\nx-y-z, y-z-x, z-y-x, x-z-y, z-y-x, y-x-z\n\n\n\nE.g.: x-y-z rotation with Euler angles \\((\\theta, \\phi, \\psi)\\) means the rotation can be expressed as a sequence of simple rotations \\(R_x(\\theta) R_y(\\phi) R_z(\\psi)\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-1",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\nSimple rotations can be counter-clockwise or clockwise. This gives another 2 possibilities.\n\\[\n\\mathbf{R}_z(\\alpha) :=\n\\begin{bmatrix}\n\\cos\\alpha & -\\sin\\alpha & 0 \\\\\n\\sin\\alpha & \\cos\\alpha  & 0 \\\\\n0          & 0           & 1\n\\end{bmatrix}\n\\qquad\n\\mathbf{C}_z(\\alpha) :=\n\\begin{bmatrix}\n\\cos\\alpha & \\sin\\alpha  & 0 \\\\\n-\\sin\\alpha & \\cos\\alpha & 0 \\\\\n0           & 0          & 1\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-2",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\n\nYou need to specify whether the rotation rotates from the world frame to the body frame, or the other way around.\nAnother 2 possibilities. More possibilities if you have more frames.\nDegrees or radians? Another 2 possibilities"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-3",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\nNeed to specify the ordering of the three parameters.\n1-2-3, 1-3-2, 2-1-3, 2-3-1, 3-1-2, 3-2-1\nAnother 6 different valid combinations"
  },
  {
    "objectID": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock",
    "href": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Another problem with Euler angles: Gimbal Lock",
    "text": "Another problem with Euler angles: Gimbal Lock"
  },
  {
    "objectID": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock-1",
    "href": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Another problem with Euler angles: Gimbal Lock",
    "text": "Another problem with Euler angles: Gimbal Lock\n\nWhy should roboticists care about this?\nBecause when it happens Euler angle representations lose one degree of freedom.\nThey cannot represent the entire range of rotations any more.\nThey get “locked” into a subset of the space of possible rotations."
  },
  {
    "objectID": "lecs/w02/lec02.html#so-we-need-other-representations-aside-from-euler-angles.-even-though-they-are-a-minimal-representation.",
    "href": "lecs/w02/lec02.html#so-we-need-other-representations-aside-from-euler-angles.-even-though-they-are-a-minimal-representation.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "So, we need other representations aside from Euler angles. Even though they are a minimal representation.",
    "text": "So, we need other representations aside from Euler angles. Even though they are a minimal representation."
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-axis-angle",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-axis-angle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Axis-Angle",
    "text": "Representing Rotations in 3D: Axis-Angle\n\n\n\n\n\n4-number representation (angle, 3D axis)\n2 ambiguities: (-angle, -axis) is the same as (angle, axis)"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-rotation-matrix",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Rotation Matrix",
    "text": "Representing Rotations in 3D: Rotation Matrix\n\nThe royalty of rotation representations\n3x3-number representation, very redundant\nNo ambiguities, as long as source frame and target frame are specified correctly. For example, define your notation this way:\nRotation from Body frame to World frame: \\(\\mathbf{R}_{BW}\\)\nOr you can define it this way: \\(_B^W \\mathbf{R}\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#inverse-rotation-matrix",
    "href": "lecs/w02/lec02.html#inverse-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inverse Rotation Matrix",
    "text": "Inverse Rotation Matrix\n\\[\n_B^W\\mathbf{R}^{-1} = _B^W\\mathbf{R}^t = _W^B\\mathbf{R}\n\\]\nRotation matrices are orthogonal matrices: their transpose is their inverse and they do not change the length of a vector, they just rotate it in space.\n\\[{}^W_B\\mathbf{R}^{t} {}^W_B\\mathbf{R} = \\mathbf{I}\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#converting-axis-angle-to-rotation-matrix",
    "href": "lecs/w02/lec02.html#converting-axis-angle-to-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Converting axis-angle to rotation matrix",
    "text": "Converting axis-angle to rotation matrix\n\nGiven angle theta and axis v the equivalent rotation matrix is\n\n\\[\n\\mathbf{R} = \\mathbf{I}\\cos\\theta + (1 - \\cos\\theta)\\mathbf{v}\\mathbf{v}^t + [\\mathbf{v}]_\\times\n\\]\n\nWhere I is the 3x3 identity and \\[[\\mathbf{a}]_\\times \\stackrel{\\text{def}}{=} \\begin{bmatrix} 0 & -a_3 & a_2 \\\\ a_3 & 0 & -a_1 \\\\ -a_2 & a_1 & 0 \\end{bmatrix}\\]\nThis is called the “Rodrigues formula”"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-a-rotation-matrix-that-rotates-one-vector-to-another",
    "href": "lecs/w02/lec02.html#example-finding-a-rotation-matrix-that-rotates-one-vector-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding a rotation matrix that rotates one vector to another",
    "text": "Example: finding a rotation matrix that rotates one vector to another\n\n\n\n\n\\[\n_C^D\\mathbf{R} = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix}\n\\]\n\nThis matrix transforms the x-axis of frame C to the z-axis of frame D. Same for y and z axes."
  },
  {
    "objectID": "lecs/w02/lec02.html#rotation-multiplication-vs-addition-3d-vs-2d",
    "href": "lecs/w02/lec02.html#rotation-multiplication-vs-addition-3d-vs-2d",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rotation multiplication vs addition: 3D vs 2D",
    "text": "Rotation multiplication vs addition: 3D vs 2D\n\nIn 2D adding angles with wraparound at 360 degrees is a valid operation.\nRotation matrices can be added, but the result is not necessarily a valid rotation. Rotations are not closed under the operation of addition.\nRotations are closed under the operation of multiplication. To compose a sequence of simple rotations we need to multiply them."
  },
  {
    "objectID": "lecs/w02/lec02.html#compound-rotations",
    "href": "lecs/w02/lec02.html#compound-rotations",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Compound rotations",
    "text": "Compound rotations\n\n\\[\n_C^E \\mathbf{R} = _D^E \\mathbf{R} _C^D \\mathbf{R}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-quaternions",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-quaternions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Quaternions",
    "text": "Representing Rotations in 3D: Quaternions\n\nBased on axis-angle representation, but more computationally efficient.\nThe main workhorse of rotation representations.\nUsed almost everywhere in robotics, aerospace, aviation.\nVery important to master in this course. You will need it for the first assignment and for working with ROS in general."
  },
  {
    "objectID": "lecs/w02/lec02.html#converting-axis-angle-to-quaternion",
    "href": "lecs/w02/lec02.html#converting-axis-angle-to-quaternion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Converting axis-angle to quaternion",
    "text": "Converting axis-angle to quaternion\n\nGiven angle theta and axis v the equivalent quaternion representation is\n\n\\[\n\\mathbf{q} = [\\sin(\\theta/2)v_1, \\sin(\\theta/2)v_2, \\sin(\\theta/2)v_3, \\cos(\\theta/2)]\n\\]\n\\[\\mathbf{q} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k} + w\\]\n\nJust like in the case of rotation matrices we denote the source and target frames of the rotation quaternion: \\(_B^W \\mathbf{q}\\)\n\n\n\nWe always work with unit length (normalized) quaternions."
  },
  {
    "objectID": "lecs/w02/lec02.html#examples-of-quaternions",
    "href": "lecs/w02/lec02.html#examples-of-quaternions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of quaternions",
    "text": "Examples of quaternions\n\n90 degree rotation about the z-axis\n\n\\[\n\\mathbf{q} = [0, 0, \\sin(\\pi / 4)v_3, cos(\\pi / 4)]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-multiplication",
    "href": "lecs/w02/lec02.html#quaternion-multiplication",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion multiplication",
    "text": "Quaternion multiplication\n\nDefined algebraically by\n\\[ \\begin{align}\nQ = q_0 + q_1i + q_2j q_sk \\\\\ni^2 = j^2 = k^2 = ijk = -1 \\\\\nij = k, jk = i, ki = j\n\\end{align}\n\\]\nand usually denoted by the circular cross symbol. For example:\n\\[\n_F^W\\mathbf{q} = _C^W\\mathbf{q} \\otimes {} _F^C\\mathbf{q}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-multiplication-1",
    "href": "lecs/w02/lec02.html#quaternion-multiplication-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion multiplication",
    "text": "Quaternion multiplication\n\\[{}^W_F\\mathbf{q} = {}^W_C\\mathbf{q} \\otimes {}^C_F\\mathbf{q}\\]\nDirect correspondence with matrix multiplication:\n\\[\n_F^W\\mathbf{R(q)} = _C^W\\mathbf{R(q)} _F^C\\mathbf{R(q)}\n\\]\nNOTE: the quaternion to matrix conversion will not be given here.\nIt is usually present in all numerical algebra libraries. At the moment we’ll take it for granted."
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-inversion",
    "href": "lecs/w02/lec02.html#quaternion-inversion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion inversion",
    "text": "Quaternion inversion\n\\[\n\\mathbf{q}^{-1} = -x\\mathbf{i} - y\\mathbf{j} -z\\mathbf{k} + w\n\\]\n\n\\[\n[0,0,0,1] = \\mathbf{q}^{-1} \\otimes \\mathbf{q}\n\\]\nDirect correspondence with matrix inversion:  \\[\n\\mathbf{I} = \\mathbf{R(q^{-1})R(q)}\n\\]\n\\[\n\\mathbf{I} = \\mathbf{R(q)^{-1} R(q)}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-updating-orientation-based-on-angular-velocity",
    "href": "lecs/w02/lec02.html#example-updating-orientation-based-on-angular-velocity",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: updating orientation based on angular velocity",
    "text": "Example: updating orientation based on angular velocity\n\nIf the angular velocity of the Body frame is \\(^Bw\\) and the body-to-world rotation at time t is \\(_B^W\\mathbf{q}(t)\\)\nThen, at time t+dt the new body-to-world rotation will be \\[{}^W_{B(t+dt)}\\mathbf{q} = {}^W_{B(t)}\\mathbf{q} \\otimes {}^{B(t)}_{B(t+dt)}\\mathbf{q}\\]\n\nwhere \\({}^{B(t)}_{B(t+dt)}\\mathbf{q}\\) has unit axis \\(\\frac{{}^B\\omega}{||{}^B\\omega||}\\) and angle \\(||{}^B\\omega|| dt\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#main-ambiguities-of-quaternion-representation",
    "href": "lecs/w02/lec02.html#main-ambiguities-of-quaternion-representation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main ambiguities of quaternion representation",
    "text": "Main ambiguities of quaternion representation\n\nThe ones inherited from the axis-angle representation, but also:"
  },
  {
    "objectID": "lecs/w02/lec02.html#be-clear-about-your-orientation-representation.",
    "href": "lecs/w02/lec02.html#be-clear-about-your-orientation-representation.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Be clear about your orientation representation.",
    "text": "Be clear about your orientation representation."
  },
  {
    "objectID": "lecs/w02/lec02.html#suggested-minimum-documentation",
    "href": "lecs/w02/lec02.html#suggested-minimum-documentation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Suggested minimum documentation",
    "text": "Suggested minimum documentation\n\nFrame diagram\nFull description of how to build a transformation matrix from the provided scalars and down to the scalar level.\nA clear statement of which transformation matrix it is."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code.\n\nCode has the same requirements as notation\nRotation matrices have two frame decorations:\n\nto\nfrom\n\nCoordinates of vectors have three decorations:\n\nto\nfrom\nexpressed in"
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-1",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-2",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-3",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-4",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-5",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-6",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code.\nChoose an expressive coding style.\nExplain it clearly.\nStick with it."
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another",
    "href": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding quaternion that rotates one vector into another",
    "text": "Example: finding quaternion that rotates one vector into another\n\nSuppose you have a vector in frame A, and a vector in frame B\nYou want to find a quaternion that transforms \\(^A\\mathbf{v}\\) to \\(^B\\mathbf{v}\\)\nIdea: use axis-angle and convert it to quaternion\nCan rotate from \\(^A\\mathbf{v}\\) to \\(^B\\mathbf{v}\\) along an axis that is perpendicular to both of them. How do we find that?"
  },
  {
    "objectID": "lecs/w02/lec02.html#cross-product",
    "href": "lecs/w02/lec02.html#cross-product",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Cross Product",
    "text": "Cross Product\n\n\n\n\n\\[\n\\mathbf{a} \\times \\mathbf{b} = ||\\mathbf{a}|| ||\\mathbf{b}|| \\sin(\\theta) \\mathbf{n}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another-1",
    "href": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding quaternion that rotates one vector into another",
    "text": "Example: finding quaternion that rotates one vector into another\n\\(\\mathbf{v}_\\text{rot axis} = ^A\\mathbf{v} \\times ^B\\mathbf{v}\\) is perpendicular to both of them\n\\(\\theta_{\\text{rot angle}} = \\text{acos}(^A\\mathbf{v} \\cdot ^B\\mathbf{v})\\)\nAssuming the two vectors are unit length"
  },
  {
    "objectID": "lecs/w02/lec02.html#rotating-a-vector-via-a-quaternion",
    "href": "lecs/w02/lec02.html#rotating-a-vector-via-a-quaternion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rotating a vector via a quaternion",
    "text": "Rotating a vector via a quaternion\n\nLet \\(^A\\mathbf{v}\\) be given and a quaternion \\(_A^B\\mathbf{q}\\)\nTo obtain \\(^B\\mathbf{v}\\) you have two choices:\nEither use the rotation matrix \\(^B\\mathbf{v} = _A^B\\mathbf{R(q)} ^A\\mathbf{v}\\)\nOr use quaternion multiplication directly\n\n\\[\n[^B\\mathbf{v}, 0] = _A^B\\mathbf{q} \\otimes [^A\\mathbf{v}, 0] \\otimes _B^A\\mathbf{q}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#transforming-points-from-one-frame-to-another",
    "href": "lecs/w02/lec02.html#transforming-points-from-one-frame-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Transforming points from one frame to another",
    "text": "Transforming points from one frame to another\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nSuppose you have a point in the Body frame,\\(^B\\mathbf{p}\\) which you want to transform/express in the World frame. Then you can do any of the two following options:\n\n\\[{}^W\\mathbf{p} = {}^W_B\\mathbf{R} {}^B\\mathbf{p} + {}^W\\mathbf{t}_{WB} \\qquad {}^W\\mathbf{p} = {}^W_B\\mathbf{R}({}^B\\mathbf{p} - {}^B\\mathbf{t}_{BW})\\]\n\nThink of it as first rotating the point to be in the World frame and then adding to it the translation from Body to World."
  },
  {
    "objectID": "lecs/w02/lec02.html#transforming-vectors-from-one-frame-to-another",
    "href": "lecs/w02/lec02.html#transforming-vectors-from-one-frame-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Transforming vectors from one frame to another",
    "text": "Transforming vectors from one frame to another\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nSuppose you have a vector in the Body frame, \\(^B\\mathbf{v}\\) which you want to transform/express in the World frame. Then\n\n\\[\n^W\\mathbf{v} = _B^W\\mathbf{R} ^B_\\mathbf{v}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#combining-rotations-and-translation-into-one-transformation",
    "href": "lecs/w02/lec02.html#combining-rotations-and-translation-into-one-transformation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining rotations and translation into one transformation",
    "text": "Combining rotations and translation into one transformation\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nMany times we combine the rotation and translation of a rigid motion into a 4x4 homogeneous matrix\n\n\\[\n_B^W\\mathbf{T} = \\begin{bmatrix}\n_B^W\\mathbf{R} & ^W\\mathbf{t}_{WB}  \\\\\n0 & 1   \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#main-advantage-of-homogeneous-transformations-easy-composition",
    "href": "lecs/w02/lec02.html#main-advantage-of-homogeneous-transformations-easy-composition",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main advantage of homogeneous transformations: easy composition",
    "text": "Main advantage of homogeneous transformations: easy composition\n\\[\n_B^W\\mathbf{T} = _A^W\\mathbf{T} _B^A\\mathbf{T}\n\\]\nComposing rigid motions now becomes a series of matrix multiplications"
  },
  {
    "objectID": "lecs/w02/lec02.html#inverting-a-homogeneous-transformation",
    "href": "lecs/w02/lec02.html#inverting-a-homogeneous-transformation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inverting a homogeneous transformation",
    "text": "Inverting a homogeneous transformation\n\nBe careful:\n\n\\[\n_B^W\\mathbf{T}^{-1} \\neq _A^W\\mathbf{T}^t\n\\]\nas was the case with rotation matrices."
  },
  {
    "objectID": "lecs/w02/lec02.html#physical-models-of-how-systems-move",
    "href": "lecs/w02/lec02.html#physical-models-of-how-systems-move",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Physical models of how systems move",
    "text": "Physical models of how systems move"
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda-2",
    "href": "lecs/w02/lec02.html#todays-agenda-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\n\nFrames of reference\nWays to represent rotations\n\n\n\nSimplified models of vehicles\nForward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#why-simplified",
    "href": "lecs/w02/lec02.html#why-simplified",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why simplified?",
    "text": "Why simplified?\n\n“All models are wrong, but some are useful” – George Box (statistician)\nModel: a function that describes a physical phenomenon or a system, i.e. how a set of input variables cause a set of output variables.\nModels are useful if they can predict reality up to some degree .\nMismatch between model prediction and reality = error / noise"
  },
  {
    "objectID": "lecs/w02/lec02.html#noise",
    "href": "lecs/w02/lec02.html#noise",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Noise",
    "text": "Noise\n\nAnything that we do not bother modelling with our model\nExample 1: “assume frictionless surface”\nExample 2: Taylor series expansion (only first few terms are dominant)\nWith models, can be thought of as approximation error."
  },
  {
    "objectID": "lecs/w02/lec02.html#simplified-physical-models-of-robotic-vehicles",
    "href": "lecs/w02/lec02.html#simplified-physical-models-of-robotic-vehicles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Simplified physical models of robotic vehicles",
    "text": "Simplified physical models of robotic vehicles\n\nOmnidirectional motion\nDubins car\nDifferential drive steering\nAckerman steering\nUnicycle\nCartpole\nQuadcopter"
  },
  {
    "objectID": "lecs/w02/lec02.html#omnidirectional-robots",
    "href": "lecs/w02/lec02.html#omnidirectional-robots",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Omnidirectional Robots",
    "text": "Omnidirectional Robots"
  },
  {
    "objectID": "lecs/w02/lec02.html#omnidirectional-robots-1",
    "href": "lecs/w02/lec02.html#omnidirectional-robots-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Omnidirectional Robots",
    "text": "Omnidirectional Robots"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#the-state-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of an omnidirectional robot",
    "text": "The state of an omnidirectional robot\nState := Configuration := \\(\\mathbf{X}\\) := vector of physical quantities of interest about the system\n\n\n\n\n\\[\n\\mathbf{X} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the robot’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame C with respect to frame G."
  },
  {
    "objectID": "lecs/w02/lec02.html#control-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#control-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Control of an omnidirectional robot",
    "text": "Control of an omnidirectional robot\nControl := \\(\\mathbf{u}\\) := a vector of input commands that can modify the state of the system\n\n\n\n\n\\[\n\\mathbf{u} = [^Cv_x, ^Cv_y, ^Cw_z]\n\\]\nControl = [Linear velocity, Angular velocity]\nLinear and angular velocity of the robot’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of frame C."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#dynamics-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of an omnidirectional robot",
    "text": "Dynamics of an omnidirectional robot\nDynamical System : = Dynamics := a function that describes the time evolution of the state in response to a control signal\n\n\n\n\nContinuous case:\n\\[\n\\begin{align}\n\\frac{dx}{dt} &= \\dot{x} = f(x, u) \\\\\n\\dot{p}_x &= v_x \\\\\n\\dot{p}_y &= v_y \\\\\n\\dot{\\theta} &= \\omega_z\n\\end{align}\n\\]\nNote: reference frames have been removed for readability."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-state-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a simple car",
    "text": "The state of a simple car\n\nState = [Position and orientation]\nPosition of the car’s frame of reference C with respect to a fixed frame of reference G, expressed in frame G.\nThe angle is the orientation of frame C with respect to G.\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-controls-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-controls-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The controls of a simple car",
    "text": "The controls of a simple car\n\nControls = [Forward speed and angular velocity]\nLinear velocity and angular velocity of the car’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of C.\n\\[\n\\mathbf{u} = [^Cv_x, ^Cw_z]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-dynamical-system-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-dynamical-system-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The dynamical system of a simple car",
    "text": "The dynamical system of a simple car\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= v_x \\cos(\\theta) \\\\\n\\dot{p}_y &= v_x \\sin(\\theta) \\\\\n\\dot{\\theta} &= \\omega_z\n\\end{align}\n\\]\nNote: reference frames have been removed for readability."
  },
  {
    "objectID": "lecs/w02/lec02.html#kinematics-vs-dynamics",
    "href": "lecs/w02/lec02.html#kinematics-vs-dynamics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kinematics vs Dynamics",
    "text": "Kinematics vs Dynamics\n\nKinematics considers models of locomotion independently of external forces and control.\nFor example, it describes how the speed of a car affects the state without considering what the required control commands required to generate those speeds are.\nDynamics considers models of locomotion as functions of their control inputs and state."
  },
  {
    "objectID": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car",
    "href": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Special case of simple car: Dubins car",
    "text": "Special case of simple car: Dubins car\n\n\n\nCan only go forward\nConstant speed\n\n\\[\n^Cv_x = \\text{const} &gt; 0\n\\]\n\nYou only control the angular velocity"
  },
  {
    "objectID": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car-1",
    "href": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Special case of simple car: Dubins car",
    "text": "Special case of simple car: Dubins car\n\n\n\nCan only go forward\nConstant speed\n\n\\[\n^Cv_x = \\text{const} &gt; 0\n\\]\n\nYou only control the angular velocity"
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-motion-primitives",
    "href": "lecs/w02/lec02.html#dubins-car-motion-primitives",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car: motion primitives",
    "text": "Dubins car: motion primitives\nThe path of the car can be decomposed to L(eft), R(ight), S(traight) segments.\n\n\n\n\nRSR path"
  },
  {
    "objectID": "lecs/w02/lec02.html#instantaneous-center-of-rotation",
    "href": "lecs/w02/lec02.html#instantaneous-center-of-rotation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Instantaneous Center of Rotation",
    "text": "Instantaneous Center of Rotation\n\n\n\n\n\n\nIC = Instantaneous Center of Rotation\nThe center of the circle circumscribed by the turning path.\nUndefined for straight path segments."
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-boat",
    "href": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-boat",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins boat",
    "text": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins boat\n\nWhy do we care about a car that can only go forward?\nBecause we can also model idealized airplanes and boats\nDubins boat = Dubins car"
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-airplane-in-3d",
    "href": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-airplane-in-3d",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins airplane in 3D",
    "text": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins airplane in 3D\n\nPitch angle \\(\\phi\\) and forward velocity determine descent rate\nYaw angle \\(\\theta\\) and forward velocity determine turning rate\n\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= v_x \\cos(\\theta) \\sin(\\phi) \\\\\n\\dot{p}_y &= v_x \\sin(\\theta) \\sin(\\phi) \\\\\n\\dot{p}_z &= v_x \\cos(\\phi) \\\\\n\\dot{\\theta} &= \\omega_z \\\\\n\\dot{\\phi} &= \\omega_y\n\\end{align}\n\\]\n\n\\(\\theta\\) is yaw\n\\(\\phi\\) is pitch"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-unicycle",
    "href": "lecs/w02/lec02.html#the-state-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a unicycle",
    "text": "The state of a unicycle\n\n\n\nTop view of a unicycle\n\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the unicycle’s frame of reference U with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame U with respect to frame G.\nQ: Would you put the radius of the unicycle to be part of the state?\n\nA: Most likely not, because it is a constant quantity that we can measure beforehand. But, if we couldn’t measure it, we need to make it part of the state in order to estimate it."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-unicycle",
    "href": "lecs/w02/lec02.html#controls-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a unicycle",
    "text": "Controls of a unicycle\n\n\n\n\n\\[\n\\mathbf{u} = [^Uw_z, ^Uw_y]\n\\]\nControls = [Yaw rate, and pedaling rate]\nYaw and pedaling rates describe the angular velocities of the respective axes of the unicycle’s frame of reference U with respect to a fixed frame of reference G, expressed in coordinates of U."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-unicycle",
    "href": "lecs/w02/lec02.html#dynamics-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a unicycle",
    "text": "Dynamics of a unicycle\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= rw_y\\cos(\\theta) \\\\\n\\dot{p}_y &= rw_y\\sin(\\theta) \\\\\n\\dot{\\theta} &= w_z \\\\\n\\end{align}\n\\]\nr = the radius of the wheel\n\\(rw_y\\) is the forward velocity of the unicycle"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#the-state-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a differential drive vehicle",
    "text": "The state of a differential drive vehicle\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the vehicle’s frame of reference D with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame D with respect to frame G."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#controls-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a differential drive vehicle",
    "text": "Controls of a differential drive vehicle\n\n\n\nICR = Instantaneous Center of Rotation\n\n\\[\n\\mathbf{u} = [u_l, u_r]\n\\]\nControls = [Left wheel and right wheel turning rates]\nWheel turning rates determine the linear velocities of the respective wheels of the vehicle’s frame of reference D with respect to a fixed frame of reference G, expressed in coordinates of D.\n\\[\n\\begin{align}\nv_1 &= (W - H/2)w \\\\\nv_r &= (W + H/2)w \\\\\nv_x &= (v_1 + v_r)/2\n\\end{align}\n\\]\n\\(v_1 = Ru_l\\) R is the wheel radius\n\\(v_r = Ru_r\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a differential drive vehicle",
    "text": "Dynamics of a differential drive vehicle\n\n\n\nICR = Instantaneous Center of Rotation\n\n\n\\[\n\\begin{bmatrix}\np_x(t+1) \\\\\np_y(t+1) \\\\\n\\theta(t+1)\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\cos(\\omega \\delta t) & -\\sin(\\omega \\delta t) & 0 \\\\\n\\sin(\\omega \\delta t) & \\cos(\\omega \\delta t) & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\np_x(t) - \\text{ICR}_x \\\\\np_y(t) - \\text{ICR}_y \\\\\n\\theta(t)\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\text{ICR}_x \\\\\n\\text{ICR}_y \\\\\n\\omega \\delta t\n\\end{bmatrix}\n\\]\n\n\\[\n\\text{ICR} = [p_x - W\\sin\\theta, p_y + W\\cos\\theta]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle-1",
    "href": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a differential drive vehicle",
    "text": "Dynamics of a differential drive vehicle\n\n\n\n\n\n\\[\n\\begin{bmatrix}\np_x(t+1) \\\\\np_y(t+1) \\\\\n\\theta(t+1)\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\cos(\\omega \\delta t) & -\\sin(\\omega \\delta t) & 0 \\\\\n\\sin(\\omega \\delta t) & \\cos(\\omega \\delta t) & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\np_x(t) - \\text{ICR}_x \\\\\np_y(t) - \\text{ICR}_y \\\\\n\\theta(t)\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\text{ICR}_x \\\\\n\\text{ICR}_y \\\\\n\\omega \\delta t\n\\end{bmatrix}\n\\]\n\n\\[\n\\text{ICR} = [p_x - W\\sin\\theta, p_y + W\\cos\\theta]\n\\]\nSpecial cases:\n\nmoving straight \\(v_l = v_r\\)\nin-place rotation \\(v_l = -v_r\\)\nrotation about the left wheel \\(v_l = 0\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#ackerman-steering",
    "href": "lecs/w02/lec02.html#ackerman-steering",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Ackerman steering",
    "text": "Ackerman steering\n\n\nhttps://www.youtube.com/watch?v=i6uBwudwA5o"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "href": "lecs/w02/lec02.html#the-state-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a double-link inverted pendulum (a.k.a. Acrobot)",
    "text": "The state of a double-link inverted pendulum (a.k.a. Acrobot)\n\n\n\n\n\\[\n\\mathbf{x} = [\\theta_1, \\theta_2, \\dot\\theta_1, \\dot\\theta_2]\n\\]\nState = [angle of joint 1, joint 2, joint velocities]\nAngle of joint 2 is expressed with respect to joint 1. Angle of joint 1 is expressed compared to down vector."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "href": "lecs/w02/lec02.html#controls-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a double-link inverted pendulum (a.k.a. Acrobot)",
    "text": "Controls of a double-link inverted pendulum (a.k.a. Acrobot)\n\n\n\n\n\\[\n\\mathbf{u} = [\\tau_1]\n\\]\nControls = [torque applied to joint 1]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)",
    "text": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)\n\\[\n\\begin{align}\n\\ddot{\\theta}_1 &= -d_1^{-1}(d_2\\ddot{\\theta}_2 + \\phi_1) \\\\\n\\ddot{\\theta}_2 &= \\left(m_2l_{c2}^2 + I_2 - \\frac{d_2^2}{d_1}\\right)^{-1}\\left(\\tau + \\frac{d_2}{d_1}\\phi_1 - m_2gl_1l_{c2}\\dot{\\theta}_1^2\\sin\\theta_2 - \\phi_2\\right) \\\\\nd_1 &= m_1l_{c1}^2 + m_2(l_1^2 + l_{c2}^2 + 2l_1l_{c2}\\cos\\theta_2) + I_1 + I_2) \\\\\nd_2 &= m_2(l_{c2}^2 + l_1l_{c2}\\cos\\theta_2) + I_2 \\\\\n\\phi_1 &= -m_2l_1l_{c2}\\dot{\\theta}_2^2\\sin\\theta_2 - 2m_2l_1l_{c2}\\dot{\\theta}_2\\dot{\\theta}_1\\sin\\theta_2\n+ (m_1l_{c1} + m_2l_1)g\\cos(\\theta_1 - \\pi/2) + \\phi_2 \\\\\n\\phi_2 &= m_2l_{c2}g\\cos(\\theta_1 + \\theta_2 - \\pi/2)\n\\end{align}\n\\]\n\nProvided here just for reference and completeness. You are not expected to know this."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot-1",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)",
    "text": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-single-link-cartpole",
    "href": "lecs/w02/lec02.html#the-state-of-a-single-link-cartpole",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a single-link cartpole",
    "text": "The state of a single-link cartpole\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x, ^G{\\dot p_x}, ^G\\theta, ^G\\dot\\theta]\n\\]\nState = [Position and velocity of cart, orientation and angular velocity of pole]"
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-single-link-cartpole",
    "href": "lecs/w02/lec02.html#controls-of-a-single-link-cartpole",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a single-link cartpole",
    "text": "Controls of a single-link cartpole\n\n\n\n\n\\[\n\\mathbf{u} = [f]\n\\]\nControls = [Horizontal force applied to cart]"
  },
  {
    "objectID": "lecs/w02/lec02.html#balancing-a-triple-link-pendulum-on-a-cart",
    "href": "lecs/w02/lec02.html#balancing-a-triple-link-pendulum-on-a-cart",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Balancing a triple-link pendulum on a cart",
    "text": "Balancing a triple-link pendulum on a cart"
  },
  {
    "objectID": "lecs/w02/lec02.html#extreme-balancing",
    "href": "lecs/w02/lec02.html#extreme-balancing",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Extreme Balancing",
    "text": "Extreme Balancing"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#the-state-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a double integrator",
    "text": "The state of a double integrator\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x]\n\\]\nState = [Position along x-axis]"
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#controls-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a double integrator",
    "text": "Controls of a double integrator\n\n\n\n\n\\[\n\\mathbf{x} = [^Gu_x]\n\\]\nControls = [Force along x-axis]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double integrator",
    "text": "Dynamics of a double integrator\n\n\n\n\n\\[\n\\ddot x = F\n\\] This corresponds to applying force to a brick of mass 1 to move on frictionless ice. Where is the brick going to end up? Similar to curling."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#the-state-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a quadrotor",
    "text": "The state of a quadrotor\n\n\n\n\n\n\\[\n\\mathbf{x} = [^G\\phi, ^G\\theta, ^G\\psi, ^G\\dot\\phi, ^G\\dot\\theta, ^G\\dot\\psi]\n\\]\nState = [Roll, pitch, yaw, and roll rate, pitch rate, roll rate]\nAngles are with respect to the global frame."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#controls-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a quadrotor",
    "text": "Controls of a quadrotor\n\n\n\n\n\\[\n\\mathbf{u} = [T_1, T_2, T_3, T_4]\n\\]\nControls = [Thrusts of four motors]\nOR \\[\n\\mathbf{u} = [M_1, M_2, M_3, M_4]\n\\]\nControls = [Torques of four motors]\nNotice how adjacent motors spin in opposite ways. Why?"
  },
  {
    "objectID": "lecs/w02/lec02.html#what-if-all-four-motors-spin-the-same-direction",
    "href": "lecs/w02/lec02.html#what-if-all-four-motors-spin-the-same-direction",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What if all four motors spin the same direction?",
    "text": "What if all four motors spin the same direction?"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#dynamics-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a quadrotor",
    "text": "Dynamics of a quadrotor"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators",
    "href": "lecs/w02/lec02.html#manipulators",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\n\n\nRobot arms, industrial robot\n\nRigid bodies(links) connected by joints\nJoints: revolute or prismatic\nDrive: electric or hydraulic\nEnd-effector (tool) mounted on a flange or plate secured to the wrist joint of robot"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-1",
    "href": "lecs/w02/lec02.html#manipulators-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-2",
    "href": "lecs/w02/lec02.html#manipulators-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\nMotion Control Methods\n\nPoint to point control\n\na sequence of discrete points\nspot welding, pick-and-place, loading & unloading\n\nContinuous path control\n\nfollow a prescribed path, controlled-path motion\nSpray painting, Arc welding, Gluing"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-3",
    "href": "lecs/w02/lec02.html#manipulators-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\n\n\nRobot Specifications\n\nNumber of Axes\n\nMajor axes, (1-3) =&gt; Position the wrist\nMinor axes, (4-6) =&gt; Orient the tool\nRedundant, (7-n) =&gt; reaching around obstacles, avoiding undesirable configuration\n\nDegree of Freedom (DOF)\nWorkspace\nPayload (load capacity)\nPrecision v.s. Repeatability\n\n\n\n\nWhich one is more important?"
  },
  {
    "objectID": "lecs/w02/lec02.html#forward-and-inverse-kinematics",
    "href": "lecs/w02/lec02.html#forward-and-inverse-kinematics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Forward and Inverse Kinematics",
    "text": "Forward and Inverse Kinematics\n\n\nhttps://slideplayer.com/slide/4239432/"
  },
  {
    "objectID": "lecs/w02/lec02.html#controllability",
    "href": "lecs/w02/lec02.html#controllability",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controllability",
    "text": "Controllability\n\nA system is controllable if there exist control sequences that can bring the system from any state to any other state, in finite time.\nFor example, even though cars are subject to non-holonomic constraints (can’t move sideways directly), they are controllable, They can reach sideways states by parallel parking."
  },
  {
    "objectID": "lecs/w02/lec02.html#passive-dynamics",
    "href": "lecs/w02/lec02.html#passive-dynamics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Passive Dynamics",
    "text": "Passive Dynamics\n\nDynamics of systems that operate without drawing (a lot of) energy from a power supply.\n\n\n\n\nInteresting because biological locomotion systems are more efficient than current robotic systems."
  },
  {
    "objectID": "lecs/w02/lec02.html#passive-dynamics-1",
    "href": "lecs/w02/lec02.html#passive-dynamics-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Passive Dynamics",
    "text": "Passive Dynamics\n\nDynamics of systems that operate without drawing (a lot of) energy from a power supply.\n\n\n\n\nUsually propelled by their own weight.\nInteresting because biological locomotion systems are more efficient than current robotic systems.\n\n\n\nSteve Collins & Andy Ruina, Cornell, 2001"
  },
  {
    "objectID": "lecs/w04/lec04.html#todays-agenda",
    "href": "lecs/w04/lec04.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\nDijkstra’s Planning Algorithm\nA* Planning Algorithm\nSampling Based Planners\n\nRapidly-exploring Random Trees (RRT)\nProbabilistic Roadmaps (PRM)"
  },
  {
    "objectID": "lecs/w04/lec04.html#planning",
    "href": "lecs/w04/lec04.html#planning",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Planning",
    "text": "Planning\n\nSo far we have been trying to compute state-dependent feedback controllers u(x)= Kx\n\n\n\nA plan is usually “open-loop,” in the sense that it is assumed that once computed you can execute it perfectly\nThis is not realistic because: wind, drag, external forces, friction, unknown factors make the system diverge from the planned trajectory.\n\n\n\n\nPlanning does not usually take external disturbances into account.\n(External, independent feedback controllers have to make sure the robot is following the path closely)"
  },
  {
    "objectID": "lecs/w04/lec04.html#why-bother-planning",
    "href": "lecs/w04/lec04.html#why-bother-planning",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why Bother Planning?",
    "text": "Why Bother Planning?"
  },
  {
    "objectID": "lecs/w04/lec04.html#sense-plan-act-paradigm-planning-is-necessary",
    "href": "lecs/w04/lec04.html#sense-plan-act-paradigm-planning-is-necessary",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Sense-Plan-Act Paradigm: Planning Is Necessary",
    "text": "Sense-Plan-Act Paradigm: Planning Is Necessary"
  },
  {
    "objectID": "lecs/w04/lec04.html#sense-plan-act-paradigm-planning-is-necessary-1",
    "href": "lecs/w04/lec04.html#sense-plan-act-paradigm-planning-is-necessary-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Sense-Plan-Act Paradigm: Planning Is Necessary",
    "text": "Sense-Plan-Act Paradigm: Planning Is Necessary"
  },
  {
    "objectID": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary",
    "href": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Subsumption Architecture: Planning Is Not Necessary",
    "text": "Subsumption Architecture: Planning Is Not Necessary"
  },
  {
    "objectID": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary-1",
    "href": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Subsumption Architecture: Planning Is Not Necessary",
    "text": "Subsumption Architecture: Planning Is Not Necessary\n\n\nHe means: why bother\nestimating state and planning?\nIt’s too much work and could be\nerror-prone. Why not only have\na hierarchy of reactive\nbehaviors/controllers?\nOne possibility:\ninstead of u(state)=…\nuse u(sensory observation)=…"
  },
  {
    "objectID": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary-2",
    "href": "lecs/w04/lec04.html#subsumption-architecture-planning-is-not-necessary-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Subsumption Architecture: Planning Is Not Necessary",
    "text": "Subsumption Architecture: Planning Is Not Necessary"
  },
  {
    "objectID": "lecs/w04/lec04.html#planning-as-graph-search",
    "href": "lecs/w04/lec04.html#planning-as-graph-search",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Planning as graph search",
    "text": "Planning as graph search\n\nGraph nodes represent discrete states\nEdges represent transitions/actions\nEdges have weights\nPotential queries:\n\nShortest path from node a to node b, that does not hit obstacles\nIs b reachable from a?\n\n\n\n\nTypical assumptions:\n\nCurrent state is known\nMap is known\nMap is mostly static"
  },
  {
    "objectID": "lecs/w04/lec04.html#dynamic-programming",
    "href": "lecs/w04/lec04.html#dynamic-programming",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamic Programming",
    "text": "Dynamic Programming\n\\[\nD(v) = \\min_{u \\in N(v)} [d(v, u) + D(u)]\n\\]\n\\[\nD(v_{\\text{dest}}) = 0\n\\]"
  },
  {
    "objectID": "lecs/w04/lec04.html#dynamic-programming-1",
    "href": "lecs/w04/lec04.html#dynamic-programming-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamic Programming",
    "text": "Dynamic Programming\n\\[\nD(v) = \\min_{u \\in N(v)} [d(v, u) + D(u)]\n\\]\n\\[\nD(v_{\\text{dest}}) = 0\n\\]\n\n\n\n\n\n\nNote: this should remind you\nof the LQR cost-to-go update\n\n\n\\[\n\\begin{align}\nJ_{t+1}(\\mathbf{x}) &= \\min_{\\mathbf{u}} [g(\\mathbf{x}_t, \\mathbf{u}_t) + J_t(A\\mathbf{x} + B\\mathbf{u})] \\\\\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T Q\\mathbf{x}\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w04/lec04.html#dynamic-programming-2",
    "href": "lecs/w04/lec04.html#dynamic-programming-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamic Programming",
    "text": "Dynamic Programming\n\\[\nD(v) = \\min_{u \\in N(v)} [d(v, u) + D(u)]\n\\]\n\\[\nD(v_{\\text{dest}}) = 0\n\\]\n\nWorst-Case\nComplexity:\n\\(O(|V|^2)\\)\nIn 2D grid world\n\\(O(|V|)\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#dijkstras-algorithm-example-runs",
    "href": "lecs/w04/lec04.html#dijkstras-algorithm-example-runs",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dijkstra’s algorithm: example runs",
    "text": "Dijkstra’s algorithm: example runs"
  },
  {
    "objectID": "lecs/w04/lec04.html#dijkstras-algorithm",
    "href": "lecs/w04/lec04.html#dijkstras-algorithm",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dijkstra’s algorithm",
    "text": "Dijkstra’s algorithm\n\n\n\n\n\n\nLet \\(D(v)\\) denote the length of the optimal path from the source node to node \\(v\\) (i.e. cost-to-come, not cost-to-go like before)\nSet \\(D(v) = \\infty\\) for all nodes except the source: \\(D(v_{\\text{src}}) = 0\\)\nAdd all nodes to priority queue Q with cost-to-come as priority\nWhile Q is not empty:\n\n\nExtract the node with minimum cost-to-come from the queue Q\nIf found goal then done\nRemove from the queue\nThe cost-to-come of \\(v\\) is final at this point. Need to check if we can reduce the cost-to-come of its neighbors.\n\n\n\n\nFor \\(u\\) in neighborhood of \\(v\\):\n\nIf \\(d(u, v) + D(v) &lt; D(u)\\) then\n\nUpdate priority \\(u\\) of in Q to be \\(d(u,v) + D(v)\\)\n\n\n\n\n\n\n\n\n\nFor Fibonacci heaps\n\\(O(|E|T_{\\text{update priority}} + |V|T_{\\text{remove min}}) = O(|E| + |V|\\log|V|)\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#dijkstras-algorithm-example-runs-1",
    "href": "lecs/w04/lec04.html#dijkstras-algorithm-example-runs-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dijkstra’s algorithm: example runs",
    "text": "Dijkstra’s algorithm: example runs\n\n\n\nMany nodes are explored\nunnecessarily. We are sure that\nthey are not going to be part of\nthe solution."
  },
  {
    "objectID": "lecs/w04/lec04.html#a-search-main-idea",
    "href": "lecs/w04/lec04.html#a-search-main-idea",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "A* Search: Main Idea",
    "text": "A* Search: Main Idea\n\nModifies Dijkstra’s algorithm to be more efficient\nExpands fewer nodes than Dijkstra’s by using a heuristic\nWhile Dijkstra prioritizes nodes based on cost-to-come\nA* prioritizes them based on:\ncost-to-come to \\(v\\) + lower bound on cost-to-go from \\(v\\) to \\(v_{\\text{dest}}\\)\n\n\n\n\n\nOptimistic search: explore node with smallest f(v) next\n\n\nLower bound on\ncost of path from\nsource to destination\nthat passes through \\(v\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#a-search-main-idea-1",
    "href": "lecs/w04/lec04.html#a-search-main-idea-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "A* Search: Main Idea",
    "text": "A* Search: Main Idea\n\nModifies Dijkstra’s algorithm to be more efficient\nExpands fewer nodes than Dijkstra’s by using a heuristic\nWhile Dijkstra prioritizes nodes based on cost-to-come\nA* prioritizes them based on:\ncost-to-come to \\(v\\) + lower bound on cost-to-go from \\(v\\) to \\(v_{\\text{dest}}\\)\n\n\n\n\n\nh() is called a heuristic. h() must be admissible, i.e. underestimate the cost-to-go from v to destination. h() must also be monotonic, i.e. satisfy the triangle inequality.\n\n\nLower bound on\ncost of path from\nsource to destination\nthat passes through \\(v\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#a-search",
    "href": "lecs/w04/lec04.html#a-search",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "A* Search",
    "text": "A* Search\n\n\nSet \\(g(v) = \\infty\\) for all nodes except the source: \\(g(v_{\\text{src}}) = 0\\)\nSet \\(f(v) = \\infty\\) for all nodes except the source: \\(f(v_{\\text{src}}) = h(v_{\\text{src}})\\)\nAdd \\(v_{\\text{src}}\\) to priority queue Q with priority \\(f(v_{\\text{src}})\\)\nWhile Q is not empty:\n\nExtract the node \\(v\\) with minimum \\(f(v)\\) from the queue Q\nIf found goal then done. Follow the parent pointers from \\(v\\) to get the path.\nRemove \\(v\\) from the queue Q\nexplored(\\(v\\)) = true\nFor \\(u\\) in neighborhood \\(v\\) of if not explored(\\(u\\)):\n\nIf \\(u\\) not in Q then\n\nAdd u in Q with cost-to-come \\(g(u) = g(v) + d(v, u)\\) and priority \\(f(u) = g(u) + h(u)\\)\nSet the parent \\(u\\) of to be \\(v\\)\n\nElse if \\(g(v) + d(v, u) &lt; g(u)\\)\n\nUpdate the cost-to-come and the priority of \\(u\\) in Q\nSet the parent of \\(u\\) to be \\(v\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#dijkstra-vs-a",
    "href": "lecs/w04/lec04.html#dijkstra-vs-a",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dijkstra vs A*",
    "text": "Dijkstra vs A*"
  },
  {
    "objectID": "lecs/w04/lec04.html#a-for-cars",
    "href": "lecs/w04/lec04.html#a-for-cars",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "A* for cars",
    "text": "A* for cars"
  },
  {
    "objectID": "lecs/w04/lec04.html#configuration-space",
    "href": "lecs/w04/lec04.html#configuration-space",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Configuration Space",
    "text": "Configuration Space\n\n\nIdea: dilate obstacles to account for the ways the robot can collide with them.\nWhy? Instead of planning in the work space and checking whether the robot’s body collides with obstacles, plan in configuration space where you can treat the robot as a point because the obstacles are dilated.\nThis idea is typically not used for robots with high-dimensional states."
  },
  {
    "objectID": "lecs/w04/lec04.html#configuration-space-1",
    "href": "lecs/w04/lec04.html#configuration-space-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Configuration Space",
    "text": "Configuration Space\n\n\nHow do we dilate obstacles?\nMinkowski Sum\n\\(P \\oplus Q = \\{p + q \\mid p \\in P, q \\in Q\\}\\)"
  },
  {
    "objectID": "lecs/w04/lec04.html#drawbacks-of-grid-based-planners",
    "href": "lecs/w04/lec04.html#drawbacks-of-grid-based-planners",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Drawbacks of grid-based planners",
    "text": "Drawbacks of grid-based planners\n\nGrid-based planning works well for grids of up to 3-4 dimensions\nState-space discretization suffers from combinatorial explosion:\nIf the state is \\(x = [x_1, ... , x_D]\\) and we split each dimension into N bins then we will have \\(N^D\\) nodes in the graph.\nThis is not practical for planning paths for robot arms with multiple joints, or other high-dimensional systems."
  },
  {
    "objectID": "lecs/w04/lec04.html#sampling-the-state-space",
    "href": "lecs/w04/lec04.html#sampling-the-state-space",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Sampling the state-space",
    "text": "Sampling the state-space\n\nNeed to find ways to reduce the continuous domain into a sparse representation: graphs, trees etc.\nToday:\nRapidly-exploring Random Tree (RRT),\nProbabilistic RoadMap (PRM)\nVisibility Planning\nSmoothing Planned Paths"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt",
    "href": "lecs/w04/lec04.html#rrt",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\nMain idea: maintain a tree of reachable configurations from the root\nMain steps:\n\nSample random state\nFind the closest state (node) already in the tree\nSteer the closest node towards the random state"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-1",
    "href": "lecs/w04/lec04.html#rrt-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-2",
    "href": "lecs/w04/lec04.html#rrt-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\n\nThings to pay attention to:\nSampleFree() needs to sample\na random state from the\nuniform distribution. How do\nyou sample rotations uniformly?"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-3",
    "href": "lecs/w04/lec04.html#rrt-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\nThings to pay attention to:\n\nNearest() searches for the nearest\nneighbor of a given vector. Brute\nforce search examines |V| nodes\n(increasing). Is there a more\nefficient method?"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-4",
    "href": "lecs/w04/lec04.html#rrt-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\nThings to pay attention to:\n\nSteer() finds the controls that take the nearest state\nto the new state. Easy for omnidirectional robots. What\nabout non-holonomic systems?"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-5",
    "href": "lecs/w04/lec04.html#rrt-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\nThings to pay attention to:\n\nObstacleFree() checks the path from the\nnearest state to the new state for collisions.\nHow do you do collision checks?"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-6",
    "href": "lecs/w04/lec04.html#rrt-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT",
    "text": "RRT\n\nThings to pay attention to:\n\nUpside of using ObstacleFree(): you don’t need to model\nobstacles in Steer(). For example, if Steer() computes LQR\ncontrollers you don’t need to model obstacles in the control\ncomputation."
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-uniform-sampling",
    "href": "lecs/w04/lec04.html#rrt-uniform-sampling",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: uniform sampling",
    "text": "RRT: uniform sampling\n\nOnly tricky case is when the state contains rotation components\nFor example: \\(x = [_B^Wq ^Wp_{W B}]\\)\nState involving both rotation and translation components is often called the pose of the system.\nIdea #1: Uniformly sample 3 Euler angles (roll, pitch, yaw)\n\n\n\n\n\n3D rotation visualization:\nrotation axis is a point on a sphere,\nrotation angle is the direction\nof the red arrow\n\n\n\nIdea #1\nNot uniform after all\nCorrect, uniform"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-uniform-sampling-1",
    "href": "lecs/w04/lec04.html#rrt-uniform-sampling-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: uniform sampling",
    "text": "RRT: uniform sampling\n\nOnly tricky case is when the state contains rotation components\nFor example: \\(x = [_B^Wq ^Wp_{W B}]\\)\nState involving both rotation and translation components is often called the pose of the system.\nIdea #1: Uniformly sample 3 Euler angles (roll, pitch, yaw)\n\n\n\n\n\nNonuniformity at the north pole\ncaused by Gimbal Lock: same rotation\nparameterized by different Euler angles\n\n\n\nIdea #1\nNot uniform after all\nCorrect, uniform"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-uniform-sampling-2",
    "href": "lecs/w04/lec04.html#rrt-uniform-sampling-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: uniform sampling",
    "text": "RRT: uniform sampling\n\nIdea #2: Uniformly sample a quaternion\nFirst, uniformly sample \\(u_1, u_2, u_3 \\in [0,1]\\)\nThen output the unit quaternion\n\n\\[\n\\mathbf{q} = [\\sqrt{1 - u_1}\\sin(2\\pi u_2), \\sqrt{1 - u_1}\\cos(2\\pi u_2), \\sqrt{u_1}\\sin(2\\pi u_3), \\sqrt{u_1}\\cos(2\\pi u_3)]\n\\]\n\nIdea #3: Uniformly sample rotation matrices.\nIt’s possible but we won’t discuss it here."
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-finding-the-nearest-neighbor",
    "href": "lecs/w04/lec04.html#rrt-finding-the-nearest-neighbor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: finding the nearest neighbor",
    "text": "RRT: finding the nearest neighbor\n\nAny alternatives to linear (brute force) search?\n\n\n\nIdea #1: space partitioning, e.g. kd-trees\n\n\nEach split is done along the median of the\npoints on that region\nBalanced kd-tree:\nCan query in O(logn)"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-finding-the-nearest-neighbor-1",
    "href": "lecs/w04/lec04.html#rrt-finding-the-nearest-neighbor-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: finding the nearest neighbor",
    "text": "RRT: finding the nearest neighbor\n\nAny alternatives to linear (brute force) search?\nIdea #1: space partitioning, e.g. kd-trees\nIdea #2: locality-sensitive hashing\n\nMaintains buckets\nSimilar points are placed on the same bucket\nWhen searching consider only points that map to the same bucket"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-steering-to-a-given-state",
    "href": "lecs/w04/lec04.html#rrt-steering-to-a-given-state",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: steering to a given state",
    "text": "RRT: steering to a given state\n\nThis is an optimal control problem, but without a specified time constraint\nFor omnidirectional systems we can connect states by a straight line.\nFor more complicated systems you could use LQR.\nYou could also use a large set of predefined controls, one of which could be able to take the system close to the given state"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-steering-to-a-given-state-1",
    "href": "lecs/w04/lec04.html#rrt-steering-to-a-given-state-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: steering to a given state",
    "text": "RRT: steering to a given state"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-collision-detection",
    "href": "lecs/w04/lec04.html#rrt-collision-detection",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: collision detection",
    "text": "RRT: collision detection\n\nMain idea: bounding volume collision detection\n\n\nSource: https://www.toptal.com/game/video-game-physics-part-ii-collision-detection-for-solid-objects"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-example-moving-a-piano",
    "href": "lecs/w04/lec04.html#rrt-example-moving-a-piano",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT example: moving a piano",
    "text": "RRT example: moving a piano"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm",
    "href": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: properties of the planning algorithm",
    "text": "RRT: properties of the planning algorithm\n#1: The RRT will eventually cover the space, i.e. it is a space-filling tree\n\nSource: Planning Algorithms, Lavalle"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-1",
    "href": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: properties of the planning algorithm",
    "text": "RRT: properties of the planning algorithm\n#1: The RRT will eventually cover the space, i.e. it is a space-filling tree\n#2: The RRT will NOT compute the optimal path asymptotically\n\nSource: Karaman, Frazzoli, 2010This problem has been addressed in recent years by RRT*, BIT*, Fast-Marching Trees"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-2",
    "href": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: properties of the planning algorithm",
    "text": "RRT: properties of the planning algorithm\n#1: The RRT will eventually cover the space, i.e. it is a space-filling tree\n#2: The RRT will NOT compute the optimal path asymptotically\n#3: The RRT will exhibit “Voronoi bias,” i.e. new nodes will fall in free regions of Voronoi diagram (cells consist of points that are closest to a node)"
  },
  {
    "objectID": "lecs/w04/lec04.html#voronoi-diagram",
    "href": "lecs/w04/lec04.html#voronoi-diagram",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Voronoi diagram",
    "text": "Voronoi diagram"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-3",
    "href": "lecs/w04/lec04.html#rrt-properties-of-the-planning-algorithm-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT: properties of the planning algorithm",
    "text": "RRT: properties of the planning algorithm\n#1: The RRT will eventually cover the space, i.e. it is a space-filling tree\n#2: The RRT will NOT compute the optimal path asymptotically\n#3: The RRT will exhibit “Voronoi bias,” i.e. new nodes will fall in free regions of Voronoi diagram\n#4: The probability of RRT finding a path increases exponentially in the number of iterations\n\n#5: The distribution of RRT’s nodes is the same as the distribution used in SampleFree()"
  },
  {
    "objectID": "lecs/w04/lec04.html#rrt-variants-bidirectional-search",
    "href": "lecs/w04/lec04.html#rrt-variants-bidirectional-search",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "RRT variants: bidirectional search",
    "text": "RRT variants: bidirectional search"
  },
  {
    "objectID": "lecs/w04/lec04.html#probabilistic-roadmaps-prms",
    "href": "lecs/w04/lec04.html#probabilistic-roadmaps-prms",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Probabilistic RoadMaps (PRMs)",
    "text": "Probabilistic RoadMaps (PRMs)\n\nRRTs were good for single-query path planning\nYou need to re-plan from scratch for every query A -&gt; B\nPRM addresses this problem\nIt is good for multi-query path planning"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm",
    "href": "lecs/w04/lec04.html#prm",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-1",
    "href": "lecs/w04/lec04.html#prm-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-2",
    "href": "lecs/w04/lec04.html#prm-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-3",
    "href": "lecs/w04/lec04.html#prm-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM\n\n\n\nEach node is connected to its neighbors (e.g. within a radius)"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-4",
    "href": "lecs/w04/lec04.html#prm-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM\n\nIn the offline PRM\nconstruction phase we\nmaintain a matrix\nD[i, j] which contains the\ntotal distance of the\nshortest path from node i\nto node j.\nWe can do this with an\nall pairs shortest paths\nalgorithm and then\nincrementally update D\nas new nodes are added."
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-5",
    "href": "lecs/w04/lec04.html#prm-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM\n\nIn the online PRM\nquery phase we\nare given two endpoints\n(not vertices of the graph)\nand we want to find the\nshortest path between them,\nby making use of the matrix\nD[i, j] that was precomputed\nin the offline phase.\nWe can incorporate the\nendpoints in the graph and\nadd 1 row and 1 column\nto D"
  },
  {
    "objectID": "lecs/w04/lec04.html#prm-6",
    "href": "lecs/w04/lec04.html#prm-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PRM",
    "text": "PRM\n\n\n\n\n\n\nTo perform a query (A-&gt;B) we need to connect A and B to the PRM.\nWe can do this by nearest neighbor search (kd-trees, hashing etc.)"
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning\n\nFirst, draw lines of sight from the start and goal to all ’visible” vertices and corners of the world."
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning-1",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning\n\nSecond, draw lines of sight from every vertex of every obstacle like before. Remember lines along edges are also lines of sight."
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning-2",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning\n\nSecond, draw lines of sight from every vertex of every obstacle like before. Remember lines along edges are also lines of sight."
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning-3",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning\n\nRepeat until you’re done.\n\nVisibility graph\n\n\n\n\n\nCan use graph search on visibility graph to find shortest path"
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning-4",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning\n\n\nPotential problem:\nshortest path touches\nobstacle corners. Need\nto dilate obstacles."
  },
  {
    "objectID": "lecs/w04/lec04.html#visibility-graph-path-planning-5",
    "href": "lecs/w04/lec04.html#visibility-graph-path-planning-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Visibility Graph Path Planning",
    "text": "Visibility Graph Path Planning"
  },
  {
    "objectID": "lecs/w04/lec04.html#path-smoothing",
    "href": "lecs/w04/lec04.html#path-smoothing",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Path smoothing",
    "text": "Path smoothing\n\nPlans obtained from any of these planners are not going to be smooth\nA plan is a sequence of states: \\(\\pi = (\\mathbf{x}_{\\text{src}}, \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_N, \\mathbf{x}_{\\text{dest}})\\)\nWe can get a smoother path \\(\\text{smooth}(\\pi) = (\\mathbf{x}_{\\text{src}}, \\mathbf{y}_1, \\mathbf{y}_2, \\ldots, \\mathbf{y}_N, \\mathbf{x}_{\\text{dest}})\\) by minimizing the following cost function\n\n\\[\nf(\\mathbf{y}_1, \\ldots, \\mathbf{y}_N) = \\sum_{t=1}^{N} ||\\mathbf{y}_t - \\mathbf{x}_t||^2 + \\alpha \\sum_{t=1}^{N} ||\\mathbf{y}_t - \\mathbf{y}_{t-1}||^2\n\\]\n\n\n\nMay need to stop smoothing when smooth path comes close to obstacles."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use Conversations as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go Conversations), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Mine Çetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. ARC services are available free to any Duke undergraduate student, in any year, studying in any discipline. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact theARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness is of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below:\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu,\nDuWell: (919) 681-8421, duwell@studentaffairs.duke.edu, or studentaffairs.duke.edu/duwell\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach. Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS). CAPS helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000. studentaffairs.duke.edu/caps\nBlue Devils Care. A convenient and cost-effective way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu\nTwo-Click Support. Duke Student Government and DukeReach partnership that connects students to help in just two clicks. bit.ly/TwoClickSupport\nWellTrack. Sign up for WellTrack at app.welltrack.com."
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Instructor\n\nFlorian Shkurti is an assistant professor in computer science at the University of Toronto, where he leads the Robot Vision and Learning lab. He is a faculty member of the University of Toronto Robotics Institute, the Acceleration Consortium, and a faculty affiliate at Vector Institute. His research group develops methods that enable robots to learn to perceive, reason, plan, and act effectively and safely, particularly in dynamic environments and alongside humans. Application areas of his research include field robotics for environmental monitoring, visual navigation for autonomous vehicles, and mobile manipulation.\n\n\n\n\n\n\n\nOffice Hours\nLocation\n\n\n\n\nWednesdays 3-5pm ET\nZoom, In person office hours can be arranged by appointment\n\n\n\n\n\nTeaching Assistants\n\n\n\n\n\n\n\n\nTAs\nOffice Hours\nLocation\n\n\n\n\nYewoon Lee\nTuesday 11am - noon ET\nZoom\n\n\nYasasa Abeysirigoonawardena\nFriday 11am-noon ET\nZoom\n\n\nRadian Gondokaryono\nTBA\nZoom\n\n\n\nEmail : csc477-tas@cs.toronto.edu",
    "crumbs": [
      "Teaching Staff"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Fall 2024 - CSC 2626: Imitation Learning for Robotics",
    "section": "",
    "text": "Course Overview\nIn the next few decades we are going to witness millions of people, from various backgrounds and levels of technical expertise, needing to effectively interact with robotic technologies on a daily basis. As such, people will need to modify the behavior of their robots without explicitly writing code, but by providing only a small number of kinesthetic or visual demonstrations, or even natural language commands. At the same time, robots should try to infer and predict the human’s intentions and internal objectives from past interactions, in order to provide assistance before it is explicitly asked. This graduate-level course will examine some of the most important papers in imitation learning for robot control, placing more emphasis on developments in the last 10 years. Its purpose is to familiarize students with the frontiers of this research area, to help them identify open problems, and to enable them to make a research contribution.\nThis course will broadly cover the following areas:\n\nImitating the policies of demonstrators (people, expensive algorithms, optimal controllers)\nConnections between imitation learning, optimal control, and reinforcement learning\nLearning the cost functions that best explain a set of demonstrations\nShared autonomy between humans and robots for real-time control\n\n\n\nPrerequisites\nYou need to be comfortable with: introductory machine learning concepts (such as from CSC411/CSC413/ECE521 or equivalent), linear algebra, basic multivariable calculus, intro to probability. You also need to have strong programming skills in Python. Note: if you don’t meet all the prerequisites above please contact the instructor by email. Optional, but recommended: experience with neural networks, such as from CSC321, introductory-level familiarity with reinforcement learning and control.\n\n\nCourse Delivery Details\n\nLectures: In-person, Mondays @ 1pm-4pm ET, Carr Hall 404\nAnnouncements will be posted on Quercus\nDiscussions will take place on Piazza\nZoom recordings will be posted on Quercus after lectures\nAnonymous feedback form for suggested improvements"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html",
    "href": "ae/ae-2-dcbikeshare.html",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-2-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-2-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#data",
    "href": "ae/ae-2-dcbikeshare.html#data",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")\n\nSee AE 1 for the first part of this analysis."
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-2-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 1\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 2\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#modeling",
    "href": "ae/ae-2-dcbikeshare.html#modeling",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 6\nUsing the data you filtered in Exercise 5, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#synthesis",
    "href": "ae/ae-2-dcbikeshare.html#synthesis",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 7\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-0-movies.html",
    "href": "ae/ae-0-movies.html",
    "title": "Movie budgets and revenues",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is a demo only. You do not have a corresponding repository for it and you’re not expected to turn in anything for it.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(tidyverse) # for data analysis and visualisation\nlibrary(scales)    # for pretty axis labels\nlibrary(DT)        # for interactive table"
  },
  {
    "objectID": "ae/ae-0-movies.html#data",
    "href": "ae/ae-0-movies.html#data",
    "title": "Movie budgets and revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies\n\n# A tibble: 7,668 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.2 e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.3 e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# … with 7,658 more rows, and 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;,\n#   company &lt;chr&gt;, runtime &lt;dbl&gt;\n\n\nThe ___ dataset has ___ observations and ___ variables."
  },
  {
    "objectID": "ae/ae-0-movies.html#analysis",
    "href": "ae/ae-0-movies.html#analysis",
    "title": "Movie budgets and revenues",
    "section": "Analysis",
    "text": "Analysis\n\nGross over time\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\nThen, we will filter for these genres and visualize the average gross revenue over time.\n\nmovies %&gt;%\n  filter(genre %in% genre_list) %&gt;% \n  group_by(genre,year) %&gt;%\n  summarise(avg_gross = mean(gross)) %&gt;%\n  ggplot(mapping = aes(x = year, y = avg_gross, color= genre)) +\n    geom_point() + \n    geom_line() +\n    scale_color_viridis_d() +\n    scale_y_continuous(labels = label_dollar()) +\n    labs(\n      x = \"Year\",\n      y = \"Average Gross Revenue (US Dollars)\",\n      color = \"Genre\",\n      title = \"Gross Revenue Over Time\"\n    )\n\n`summarise()` has grouped output by 'genre'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 47 rows containing missing values (geom_point).\n\n\nWarning: Removed 23 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\n\n\nThe plot suggests …\n\n\nBudget and gross\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies %&gt;%\n  filter(genre %in% genre_list, budget &gt; 0) %&gt;% \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d() +\n  labs(\n    x = \"Log-transformed Budget\",\n    y = \"Log-transformed Gross Revenue\"\n  )\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 35 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 35 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-0-movies.html#exercises",
    "href": "ae/ae-0-movies.html#exercises",
    "title": "Movie budgets and revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nIn the remaining time, discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)?"
  },
  {
    "objectID": "ae/ae-0-movies.html#appendix",
    "href": "ae/ae-0-movies.html#appendix",
    "title": "Movie budgets and revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies %&gt;% \n  distinct(genre) %&gt;%\n  arrange(genre) %&gt;% \n  datatable()"
  },
  {
    "objectID": "ae/ae-9-odds.html",
    "href": "ae/ae-9-odds.html",
    "title": "AE 9: Odds",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-9-odds-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-9-odds.html#packages",
    "href": "ae/ae-9-odds.html#packages",
    "title": "AE 9: Odds",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nheart_disease &lt;- read_csv(here::here(\"ae\", \"data/framingham.csv\")) %&gt;%\n  select(totChol, TenYearCHD) %&gt;%\n  drop_na() %&gt;%\n  mutate(high_risk = as.factor(TenYearCHD)) %&gt;%\n  select(totChol, high_risk)"
  },
  {
    "objectID": "ae/ae-9-odds.html#linear-regression-vs.-logistic-regression",
    "href": "ae/ae-9-odds.html#linear-regression-vs.-logistic-regression",
    "title": "AE 9: Odds",
    "section": "Linear regression vs. logistic regression",
    "text": "Linear regression vs. logistic regression\nState whether a linear regression model or logistic regression model is more appropriate for each scenario:\n\nUse age and education to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "ae/ae-9-odds.html#heart-disease",
    "href": "ae/ae-9-odds.html#heart-disease",
    "title": "AE 9: Odds",
    "section": "Heart disease",
    "text": "Heart disease\n\nData: Framingham study\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to use the total cholesterol to predict if a randomly selected adult is high risk for heart disease in the next 10 years.\n\nhigh_risk:\n\n1: High risk of having heart disease in next 10 years\n0: Not high risk of having heart disease in next 10 years\n\ntotChol: total cholesterol (mg/dL)\n\n\n\nOutcome: high_risk\n\nggplot(data = heart_disease, aes(x = high_risk)) + \n  geom_bar() + \n  scale_x_discrete(labels = c(\"1\" = \"High risk\", \"0\" = \"Low risk\")) +\n  labs(\n    title = \"Distribution of 10-year risk of heart disease\", \n    x = NULL)\n\n\n\n\n\n\n\n\n\nheart_disease %&gt;%\n  count(high_risk)\n\n# A tibble: 2 × 2\n  high_risk     n\n  &lt;fct&gt;     &lt;int&gt;\n1 0          3555\n2 1           635\n\n\n\n\nCalculating probability and odds\n\nWhat is the probability a randomly selected person in the study is not high risk for heart disease?\nWhat are the odds a randomly selected person in the study is not high risk for heart disease?\n\n\n\nLogistic regression model\nFit a logistic regression model to understand the relationship between total cholesterol and risk for heart disease.\nLet \\(pi\\) be the probability an adult is high risk. The statistical model is\n\\[\\log\\Big(\\frac{\\pi_i}{1-\\pi_i}\\Big) = \\beta_0 + \\beta_1 TotChol_i\\]\n\nheart_disease_fit &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  fit(high_risk ~ totChol, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) %&gt;% kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.894\n0.230\n-12.607\n0\n\n\ntotChol\n0.005\n0.001\n5.268\n0\n\n\n\n\n\n\nWrite the regression equation. Round to 3 digits.\n\n\n\nCalculating log-odds, odds and probabilities\nBased on the model, if a randomly selected person has a total cholesterol of 250 mg/dL,\n\nWhat are the log-odds they are high risk for heart disease?\nWhat are the odds they are high risk for heart disease?\nWhat is the probability they are high risk for heart disease? Use the odds to calculate your answer.\n\n\n\nComparing observations\nSuppose a person’s cholesterol changes from 250 mg/dL to 200 mg/dL.\n\nHow do you expect the log-odds that this person is high risk for heart disease to change?\nHow do you expect the odds that this person is high risk for heart disease to change?"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html",
    "href": "ae/ae-1-dcbikeshare.html",
    "title": "AE 02: Bike rentals in DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-1-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 02: Bike rentals in DC",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#data",
    "href": "ae/ae-1-dcbikeshare.html#data",
    "title": "AE 02: Bike rentals in DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\nggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250)\n\n\n\n\n\n\n\nggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nExercise 2\nDescribe the distribution of daily bike rentals and the distribution of temperature based on the visualizations created in Exercise 1. Include the shape, center, spread, and presence of any potential outliers.\n[Add your answer here]\n\n\nExercise 3\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n[Add your answer here]\n\n\nExercise 4\nDescribe the relationship between daily bike rentals and temperature based on the visualization created in Exercise 1. Comment on how we expect the number of bike rentals to change as the temperature increases.\n[Add your answer here]\n\n\nExercise 5\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe the best fit for the data? Why or why not?\nNo."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 6\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 7\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 8\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 9\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#modeling",
    "href": "ae/ae-1-dcbikeshare.html#modeling",
    "title": "AE 02: Bike rentals in DC",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 10\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 11\nUsing the data you filtered in Exercise 10, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here\n\n\n\nExercise 12\nUse the output to write out the estimated regression equation.\n[Add your answer here]\n\n\nExercise 13\nInterpret the slope in the context of the data.\n[Add your answer here]\n\n\nExercise 14\nInterpret the intercept in the context of the data.\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#synthesis",
    "href": "ae/ae-1-dcbikeshare.html#synthesis",
    "title": "AE 02: Bike rentals in DC",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 15\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]\n\nThe following exercises will be completed only if time permits.\n\n\nExercise 16\nPick another season. Based on the visualization in Exercise 8, would you expect the slope of the relationship between temperature and daily bike rentals to be smaller or larger than the slope of the model you’ve been working with so far? Explain your reasoning.\n[Add your answer here]\n\n\nExercise 17\nFor this season you picked in Exercise 16, fit a linear model for predicting daily bike rentals from temperature. Note, you will need to filter your data for this season first. Use the output to write out the estimated regression equation and interpret the slope and the intercept of this model.\n\n# add your code here\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html",
    "href": "ae/ae-6-the-office-cv.html",
    "title": "AE 6: The Office",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-6-the-office-cv-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#packages",
    "href": "ae/ae-6-the-office-cv.html#packages",
    "title": "AE 6: The Office",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#load-data",
    "href": "ae/ae-6-the-office-cv.html#load-data",
    "title": "AE 6: The Office",
    "section": "Load data",
    "text": "Load data\n\noffice_episodes &lt;- read_csv(\"data/office_episodes.csv\")"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#split-data-into-training-and-testing",
    "href": "ae/ae-6-the-office-cv.html#split-data-into-training-and-testing",
    "title": "AE 6: The Office",
    "section": "Split data into training and testing",
    "text": "Split data into training and testing\nSplit your data into testing and training sets.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#specify-model",
    "href": "ae/ae-6-the-office-cv.html#specify-model",
    "title": "AE 6: The Office",
    "section": "Specify model",
    "text": "Specify model\nSpecify a linear regression model. Call it office_spec.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#create-recipe",
    "href": "ae/ae-6-the-office-cv.html#create-recipe",
    "title": "AE 6: The Office",
    "section": "Create recipe",
    "text": "Create recipe\nCreate the recipe from class. Call it office_rec1.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#create-workflow",
    "href": "ae/ae-6-the-office-cv.html#create-workflow",
    "title": "AE 6: The Office",
    "section": "Create workflow",
    "text": "Create workflow\nCreate the workflow that brings together the model specification and recipe. Call it office_wflow1.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#cross-validation",
    "href": "ae/ae-6-the-office-cv.html#cross-validation",
    "title": "AE 6: The Office",
    "section": "Cross validation",
    "text": "Cross validation\nConduct 10-fold cross validation.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#summarize-cv-metrics",
    "href": "ae/ae-6-the-office-cv.html#summarize-cv-metrics",
    "title": "AE 6: The Office",
    "section": "Summarize CV metrics",
    "text": "Summarize CV metrics\nSummarize metrics from your CV resamples.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#another-model---model-2",
    "href": "ae/ae-6-the-office-cv.html#another-model---model-2",
    "title": "AE 6: The Office",
    "section": "Another model - Model 2",
    "text": "Another model - Model 2\nCreate a different (simpler, involving fewer variables) recipe and call it office_rec2. Conduct 10-fold cross validation and summarize metrics. Describe how the two models compare to each other based on cross validation metrics."
  },
  {
    "objectID": "ae/ae-11-volcanoes.html",
    "href": "ae/ae-11-volcanoes.html",
    "title": "AE 11: Multinomial classification",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-11-volcanoes-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#packages",
    "href": "ae/ae-11-volcanoes.html#packages",
    "title": "AE 11: Multinomial classification",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(colorblindr)"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#data",
    "href": "ae/ae-11-volcanoes.html#data",
    "title": "AE 11: Multinomial classification",
    "section": "Data",
    "text": "Data\nFor this application exercise we will work with a dataset of on volcanoes. The data come from The Smithsonian Institution via TidyTuesday.\n\nvolcano &lt;- read_csv(here::here(\"ae\", \"data/volcano.csv\"))\n\nRows: 958 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): volcano_name, primary_volcano_type, last_eruption_year, country, r...\ndbl  (8): volcano_number, latitude, longitude, elevation, population_within_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFirst, a bit of data prep:\n\nvolcano &lt;- volcano %&gt;%\n  mutate(\n    volcano_type = case_when(\n      str_detect(primary_volcano_type, \"Stratovolcano\") ~ \"Stratovolcano\",\n      str_detect(primary_volcano_type, \"Shield\") ~ \"Shield\",\n      TRUE ~ \"Other\"\n    ),\n    volcano_type = fct_relevel(volcano_type, \"Stratovolcano\", \"Shield\", \"Other\")\n  ) %&gt;%\n  select(\n    volcano_type, latitude, longitude, \n    elevation, tectonic_settings, major_rock_1\n    ) %&gt;%\n  mutate(across(where(is.character), as_factor))"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#exploratory-data-analysis",
    "href": "ae/ae-11-volcanoes.html#exploratory-data-analysis",
    "title": "AE 11: Multinomial classification",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nCreate a map of volcanoes that is faceted by volcano_type.\n\n\nworld &lt;- map_data(\"world\")\n\nworld_map &lt;- ggplot() +\n  geom_polygon(\n    data = world, \n    aes(\n      x = long, y = lat, group = group),\n      color = \"white\", fill = \"gray50\", \n      size = 0.05, alpha = 0.2\n    ) +\n  theme_minimal() +\n  coord_quickmap() +\n  labs(x = NULL, y = NULL)\n\nworld_map +\n  geom_point(\n    data = volcano,\n    aes(x = longitude, y = latitude,\n        color = volcano_type, \n        shape = volcano_type),\n    alpha = 0.5\n  ) +\n  facet_wrap(~volcano_type) +\n  scale_color_OkabeIto()"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#build-a-new-model",
    "href": "ae/ae-11-volcanoes.html#build-a-new-model",
    "title": "AE 11: Multinomial classification",
    "section": "Build a new model",
    "text": "Build a new model\n\nBuild a new model that uses a recipe that includes geographic information (latitude and longitude). How does this model compare to the original? Note:\nUse the same test/train split as well as same cross validation folds. Code for these is provided below.\n\n\n# test/train split\nset.seed(1234)\n\nvolcano_split &lt;- initial_split(volcano)\nvolcano_train &lt;- training(volcano_split)\nvolcano_test  &lt;- testing(volcano_split)\n\n# cv folds\nset.seed(9876)\n\nvolcano_folds &lt;- vfold_cv(volcano_train, v = 5)\nvolcano_folds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits            id   \n  &lt;list&gt;            &lt;chr&gt;\n1 &lt;split [574/144]&gt; Fold1\n2 &lt;split [574/144]&gt; Fold2\n3 &lt;split [574/144]&gt; Fold3\n4 &lt;split [575/143]&gt; Fold4\n5 &lt;split [575/143]&gt; Fold5\n\n\nNew recipe, including geographic information:\n\nvolcano_rec2 &lt;- recipe(volcano_type ~ ., data = volcano_train) %&gt;%\n  step_other(tectonic_settings) %&gt;%\n  step_other(major_rock_1) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_center(all_predictors())\n\nOriginal model specification and new workflow:\n\nvolcano_spec &lt;- multinom_reg() %&gt;%\n  set_engine(\"nnet\")\n\nvolcano_wflow2 &lt;- workflow() %&gt;%\n  add_recipe(volcano_rec2) %&gt;%\n  add_model(volcano_spec)\n\nvolcano_wflow2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_other()\n• step_other()\n• step_dummy()\n• step_zv()\n• step_center()\n\n── Model ───────────────────────────────────────────────────────────────────────\nMultinomial Regression Model Specification (classification)\n\nComputational engine: nnet \n\n\nFit resamples:\n\nvolcano_fit_rs2 &lt;- volcano_wflow2 %&gt;%\n  fit_resamples(\n    volcano_folds, \n    control = control_resamples(save_pred = TRUE)\n    )\n\nvolcano_fit_rs2\n\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  &lt;list&gt;            &lt;chr&gt; &lt;list&gt;           &lt;list&gt;           &lt;list&gt;            \n1 &lt;split [574/144]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n2 &lt;split [574/144]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n3 &lt;split [574/144]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n4 &lt;split [575/143]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [143 × 7]&gt;\n5 &lt;split [575/143]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [143 × 7]&gt;\n\n\nCollect metrics:\n\ncollect_metrics(volcano_fit_rs2)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy multiclass 0.606     5  0.0138 Preprocessor1_Model1\n2 roc_auc  hand_till  0.695     5  0.0245 Preprocessor1_Model1\n\n\nROC curves:\n\nvolcano_fit_rs2 %&gt;%\n  collect_predictions() %&gt;%\n  group_by(id) %&gt;%\n  roc_curve(\n    truth = volcano_type,\n    .pred_Stratovolcano:.pred_Other\n  ) %&gt;%\n  autoplot()"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#roc-curves",
    "href": "ae/ae-11-volcanoes.html#roc-curves",
    "title": "AE 11: Multinomial classification",
    "section": "ROC curves",
    "text": "ROC curves\n\nRecreate the ROC curve from the slides.\n\n\nfinal_fit &lt;- last_fit(\n  volcano_wflow2, \n  split = volcano_split\n  )\n\ncollect_predictions(final_fit) %&gt;%\n  roc_curve(truth = volcano_type, .pred_Stratovolcano:.pred_Other) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = .level)) +\n  geom_path(size = 1) +\n  scale_color_OkabeIto() +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\") +\n  theme_minimal() +\n  labs(color = NULL)"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#acknowledgement",
    "href": "ae/ae-11-volcanoes.html#acknowledgement",
    "title": "AE 11: Multinomial classification",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThis exercise was inspired by https://juliasilge.com/blog/multinomial-volcano-eruptions."
  },
  {
    "objectID": "weekly-material.html",
    "href": "weekly-material.html",
    "title": "Weekly Materials",
    "section": "",
    "text": "Software Installations\n\n\n\nSlides & Recordings\n\n\n\nNo tutorials/labs this week but please complete the Pre-Requisite Math Problems\nSuggested Review :\n\nLinear Algebra review \nProbability review"
  },
  {
    "objectID": "weekly-material.html#week-1",
    "href": "weekly-material.html#week-1",
    "title": "Weekly Materials",
    "section": "",
    "text": "Software Installations\n\n\n\nSlides & Recordings\n\n\n\nNo tutorials/labs this week but please complete the Pre-Requisite Math Problems\nSuggested Review :\n\nLinear Algebra review \nProbability review"
  },
  {
    "objectID": "weekly-material.html#week-2",
    "href": "weekly-material.html#week-2",
    "title": "Weekly Materials",
    "section": "Week 2",
    "text": "Week 2\n\nLecture\nSlides & Recordings\nProf. Roger Grosse’s notes on backdrop\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: PyTorch basics with linear models lab01\n\n\nQuiz\nLec2 pre-recorded videos with quizzes"
  },
  {
    "objectID": "weekly-material.html#week-3",
    "href": "weekly-material.html#week-3",
    "title": "Weekly Materials",
    "section": "Week 3",
    "text": "Week 3\n\nLecture\nGloVe embedding demo \nVideo on autodiff\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: numerical gradients / word embeddings lab02\n\n\nQuiz\nLec3 pre-recorded videos with quizzes\n\n\nAdditional Resources\nProf. Roger Grosse’s notes on autodiff and word embeddings\nNotes on Backpropagation https://cs231n.github.io/optimization-2/\nAutomatic Differentiation in Machine Learning: a Survey (2018) https://arxiv.org/pdf/1502.05767.pdf"
  },
  {
    "objectID": "weekly-material.html#week-4",
    "href": "weekly-material.html#week-4",
    "title": "Weekly Materials",
    "section": "Week 4",
    "text": "Week 4\n\nLecture\nSlides & Recordings\nDemo: Colab Notebook\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: classification and medical MNIST lab03\n\n\nQuiz\nLecture 4 pre-recorded videos and quizzes\n\n\nAssignment\nMath Assignment 1 posted"
  },
  {
    "objectID": "weekly-material.html#week-5",
    "href": "weekly-material.html#week-5",
    "title": "Weekly Materials",
    "section": "Week 5",
    "text": "Week 5\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nTutorial: how to implement SGD with momentum neural network optimization\n\n\nQuiz\nLecture 5 pre-recorded videos and quizzes\n\n\nAdditional Resources\nTaylor Series https://www.youtube.com/watch?v=3d6DsjIBzJ4"
  },
  {
    "objectID": "weekly-material.html#week-6",
    "href": "weekly-material.html#week-6",
    "title": "Weekly Materials",
    "section": "Week 6",
    "text": "Week 6\n\nLecture\nSlides & Recordings\nEnsembling code skeleton\nThe definition of differential privacy\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: optimization and differential privacy lab05\n\n\nQuiz\nLecture 6 pre-recorded videos and quizzes\n\n\nAssignment\nMath assignment 1 due"
  },
  {
    "objectID": "weekly-material.html#week-7",
    "href": "weekly-material.html#week-7",
    "title": "Weekly Materials",
    "section": "Week 7",
    "text": "Week 7\n\nLecture\nSlides & Recordings\nTroubleshooting Deep Neural Networks\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person midterm #1 which covers weeks 1-5. Held during the tutorial / lab sessions\n\n\nAssignment\nMath assignment 2 posted"
  },
  {
    "objectID": "weekly-material.html#week-8",
    "href": "weekly-material.html#week-8",
    "title": "Weekly Materials",
    "section": "Week 8",
    "text": "Week 8\n\nLecture\nSlides\nMissing recording due to technical issue\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: transfer learning and double descent lab07\n\n\nQuiz\nLecture 8 pre-recorded videos and quizzes"
  },
  {
    "objectID": "weekly-material.html#week-9",
    "href": "weekly-material.html#week-9",
    "title": "Weekly Materials",
    "section": "Week 9",
    "text": "Week 9\nFall reading week. No lecture.\nMath assignment 2 due."
  },
  {
    "objectID": "weekly-material.html#week-10",
    "href": "weekly-material.html#week-10",
    "title": "Weekly Materials",
    "section": "Week 10",
    "text": "Week 10\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: gradcam and input gradients lab09\n\n\nFinal Project\nDeadline to form project groups on Markus, and submit a project proposal\n\n\nAdditional Resources\nTransformer video: https://www.youtube.com/watch?v=XSSTuhyAmnI\nhttps://nlp.seas.harvard.edu/2018/04/03/attention.html\nhttp://peterbloem.nl/blog/transformers\nLast year’s A3 (a seq2seq autoencoder) http://modelai.gettysburg.edu/2021/headlines/"
  },
  {
    "objectID": "weekly-material.html#week-11",
    "href": "weekly-material.html#week-11",
    "title": "Weekly Materials",
    "section": "Week 11",
    "text": "Week 11\n\nLecture\nSlides & Recordings\nAutoencoder Notebook\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person midterm #2 which covers weeks 6-9. Held during the tutorial / lab sessions\n\n\nQuiz\nLecture 10 pre-recorded videos and quizzes\n\n\nFinal Project\nWritten feedback on project proposals sent by TAs and instructors."
  },
  {
    "objectID": "weekly-material.html#week-12",
    "href": "weekly-material.html#week-12",
    "title": "Weekly Materials",
    "section": "Week 12",
    "text": "Week 12\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: RNN text classification lab10"
  },
  {
    "objectID": "weekly-material.html#week-13",
    "href": "weekly-material.html#week-13",
    "title": "Weekly Materials",
    "section": "Week 13",
    "text": "Week 13\n\nLecture\nSlides & Recordings\nIf you are interested in both groups’ research, it is worth attending or watching both lectures this week.\n\n\nTutorials/Labs\nIn-person lab session: text generation with transformers lab11"
  },
  {
    "objectID": "weekly-material.html#week-14",
    "href": "weekly-material.html#week-14",
    "title": "Weekly Materials",
    "section": "Week 14",
    "text": "Week 14\nFinal project submission"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful Resources and Links",
    "section": "",
    "text": "Recommended Simulators\nYou are encouraged to use the simplest possible simulator to accomplish the task you are interested in. You can submit links to simulators not included here by opening a github issue.\n\n\n\nSimulately\nA detailed wiki comparing various widely-used robotics simulators. Read this first. The rest of this table shows simulators and environments not mentioned by Simulately.\n\n\nIsaac Lab (formerly Isaac Orbit / Isaac Gym)\nLayer of abstraction and tools to make using Isaac Sim easier.\n\n\nDrake Simulator\nA framework of simulation, analysis and control tools for robotics.\n\n\nDeepmind Control Suite\nSet of robotics environments on top of Mujoco.\n\n\nMujoco Menagerie\nHigh-quality description files and assets for robots, built on top of Mujoco.\n\n\nOpenAI Gym\nAtari, Mujoco, classic control, and third-party environments for RL.\n\n\nRoboSuite\nRobotics simulation environments on top of Mujoco. Also a benchmark.\n\n\nKlampt\nModeling, simulating, planning, and optimization for complex robots, particularly for manipulation and locomotion tasks.\n\n\nDART\nPhysics simulator for robotics and animation.\n\n\nCARLA\nSelf-driving environment and benchmarks on top of the Unreal simulation engine.\n\n\nAirSim\nRobotics simulation environments for flying and driving, built on top of Unreal engine.\n\n\ngym-pybullet-drones\nRobotics simulation environments and tools for quadrotors on top of PyBullet.\n\n\nHabitat 3.0\nSimulation of indoor scenes, humans, and robots. Good for visual navigation and social navigation tasks.\n\n\nGPUDrive\nGPU-accelerated multi-agent driving simulator.\n\n\nProcGen\nProcedurally generated simulation environments (not robotics, but useful).\n\n\nRaiSim\nRigid body physics engine. Supports biomechanics of human motion, as well as quadrupeds.\n\n\nFlightmare\nSimulation environment for flying vehicles built on top of the Unity simulation engine.\n\n\nIKEA Furniture Assembly\nIKEA furniture assembly environment.\n\n\nFurnitureBench\nSimulators, datasets, and real environments for furniture assembly\n\n\nRLBench\nSimulation environments for manipulation, built on top of the CoppeliaSim simulator.\n\n\nALFRED\nSimulation environments for visual and language-based navigation and manipulation tasks.\n\n\nMyoSuite\nMuscosceletal simulation environments for biomechanics, based on Mujoco.\n\n\nMetaWorld\nMulti-task RL environments and benchmarks.\n\n\nBimanual Manipulation Gym\nBimanual manipulation environments\n\n\n\n\n\nRecommended datasets\n\n\n\nSimulately\nA detailed wiki comparing various widely-used robotics datasets. Read this first. The rest of this table shows datasets not mentioned by Simulately.\n\n\nD4RL\nManipulation and navigation datasets for offline RL\n\n\nRoboMimic\nManipulation datasets and imitation learning algorithms\n\n\nMimicGen\nAutomatic augmentation of manipulation datasets starting from human demonstrations\n\n\nOptimus\nAutomatically generating long-horizon manipulation dataset from Task and Motion Planners.\n\n\nDROID\nManipulation dataset across various labs and robots\n\n\nD4RL\nManipulation and navigation datasets for offline RL\n\n\n\n\n\nRecommended RL, IL, trajectory optimization, and motion planning libraries\n\n\n\nSimulately\nA detailed wiki comparing various widely-used RL libaries. Read this first. The rest of this table shows libraries not mentioned by Simulately.\n\n\nRSL RL\nRL library used for training quadrupeds at the RSL lab at ETHZ. Used in Isaac Lab.\n\n\nSTORM\nMPC motion planner on the GPU\n\n\nOMPL\nOpen motion planning library\n\n\nMink\nInverse kinematics library, built on top of pink and pinocchio\n\n\nPureJaxRL\nRL library in JAX, with training and environments running fully on GPU\n\n\nCleanRL\nClean implementations of Online RL baselines\n\n\nClean Offline RL\nClean implementations of Offline RL baselines\n\n\nrliable\nMethod and library for reliable evaluation of RL algorithms\n\n\nDiffusion policy\nImplementation of diffusion policy in action space for imitation learning\n\n\nImplicit behavior cloning\nImplementation of behavior cloning with energy based models\n\n\nTheseus\nA library for differentiable nonlinear optimization in Pytorch\n\n\nModel-based RL algorithms\nList of model-based RL algorithms"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "ae/ae-5-the-office.html",
    "href": "ae/ae-5-the-office.html",
    "title": "AE 5: The Office",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-5-the-office-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-5-the-office.html#packages",
    "href": "ae/ae-5-the-office.html#packages",
    "title": "AE 5: The Office",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-5-the-office.html#load-data",
    "href": "ae/ae-5-the-office.html#load-data",
    "title": "AE 5: The Office",
    "section": "Load data",
    "text": "Load data\n\noffice_ratings &lt;- read_csv(\"data/office_ratings.csv\")\n\nRows: 188 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): title\ndbl  (4): season, episode, imdb_rating, total_votes\ndate (1): air_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "ae/ae-5-the-office.html#exploratory-data-analysis",
    "href": "ae/ae-5-the-office.html#exploratory-data-analysis",
    "title": "AE 5: The Office",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nRecreate at least one of the exploratory visualizations from class."
  },
  {
    "objectID": "ae/ae-5-the-office.html#testtrain-split",
    "href": "ae/ae-5-the-office.html#testtrain-split",
    "title": "AE 5: The Office",
    "section": "Test/train split",
    "text": "Test/train split\nSplit your data into testing and training sets."
  },
  {
    "objectID": "ae/ae-5-the-office.html#build-a-recipe",
    "href": "ae/ae-5-the-office.html#build-a-recipe",
    "title": "AE 5: The Office",
    "section": "Build a recipe",
    "text": "Build a recipe\nBuild the recipe from class.\n\nTime permitting…"
  },
  {
    "objectID": "ae/ae-5-the-office.html#workflows-and-model-fitting",
    "href": "ae/ae-5-the-office.html#workflows-and-model-fitting",
    "title": "AE 5: The Office",
    "section": "Workflows and model fitting",
    "text": "Workflows and model fitting\nBuild the modeling workflow and fit the model to the training data after feature engineering with the recipe."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html",
    "href": "ae/ae-4-exam-1-review.html",
    "title": "AE 4: Exam 1 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-4-exam-1-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#packages",
    "href": "ae/ae-4-exam-1-review.html#packages",
    "title": "AE 4: Exam 1 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggfortify)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "href": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "title": "AE 4: Exam 1 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "href": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "title": "AE 4: Exam 1 Review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nVisualize, summarize, and describe the relationship between Party and Tip.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#modeling",
    "href": "ae/ae-4-exam-1-review.html#modeling",
    "title": "AE 4: Exam 1 Review",
    "section": "Modeling",
    "text": "Modeling\nLet’s start by fitting a model using Party to predict the Tip at this restaurant.\n\nWrite the statistical model.\nFit the regression line and write the regression equation. Name the model tips_fit and display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret the slope.\nDoes it make sense to interpret the intercept? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#inference",
    "href": "ae/ae-4-exam-1-review.html#inference",
    "title": "AE 4: Exam 1 Review",
    "section": "Inference",
    "text": "Inference\n\nInference for the slope\n\nThe following code can be used to create a bootstrap distribution for the slope (and the intercept, though we’ll focus primarily on the slope in our inference). Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\n\nset.seed(1234)\n\nboot_dist &lt;- tips %&gt;%\n  specify(Tip ~ Party) %&gt;%\n  generate(reps = 100, type = \"bootstrap\") %&gt;%\n  fit()\n\n\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the slope using bootstrapping and the percentile method and interpret it in context of the data.\n\n\n# add your code here\n\n\nConduct a hypothesis test at the equivalent significance level using permutation. State the hypotheses and the significance level you’re using explicitly. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercises 7 and 8. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\nNow repeat Exercises 7 and 8 using approaches based on mathematical models.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercise 9. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\n\nInference for a prediction\n\nBased on your model, predict the tip for a party of 4.\n\n\n# add your code here\n\n\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in Exercise 11. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\nNow construct the intervals from Exercise 12 and comment on whether your guess is confirmed.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "href": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "title": "AE 4: Exam 1 Review",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nLeverage (Outliers in x direction)\n\nWhat is the threshold used to identify observations with high leverage? Calculate the threshold and save the value as leverage_threshold.\n\n\n# add your code here\n\n\nMake a plot of the standardized residuals vs. leverage (you can do this with ggplot() or with autoplot(which = 5)). Use geom_vline() to add a vertical line to help identify points with high leverage.\n\n\n# add your code here\n\n\nLet’s dig into the data further. Which observations have high leverage? Why do these points have high leverage?\n\n\n# add your code here\n\n\n\nIdentifying outliers (outliers in y direction)\n\nMake a plot of the residuals vs. fitted values and a plot of the square root of the absolute value of standardized residuals vs. fitted (You can use autoplot(which = c(1, 3)) to display the plots side-by-side).\n\n\nHow are the plots similar? How do they differ?\nWhat is an advantage of using the plot of the residuals vs. fitted to check conditions and model diagnostics?\nWhat is an advantage of using the plot of the \\(\\sqrt{|\\text{standardized residuals}|}\\) vs. fitted to check conditions and model diagnostics?\n\n\n# add your code here\n\n\nAre there any observations that are outliers?\n\n\n# add your code here\n\n\n\nCook’s distance\n\nMake a plot to check Cook’s distance (autoplot(which = 4)). Based on this plot, are there any points that have a strong influence on the model coefficients?\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "href": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "title": "AE 4: Exam 1 Review",
    "section": "Adding another variable",
    "text": "Adding another variable\n\nAdd another variable, Alcohol, to your exploratory visualization. Describe any patterns that emerge.\n\n\n# add your code here\n\n\nFit a multiple linear regression model predicting Tip from Party and Alcohol. Display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret each of the slopes.\nDoes it make sense to interpret the intercept? Explain your reasoning.\nAccording to this model, is the rate of change in tip amount the same for various sizes of parties regardless of alcohol consumption or are they different? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#footnotes",
    "href": "ae/ae-4-exam-1-review.html#footnotes",
    "title": "AE 4: Exam 1 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html",
    "href": "ae/ae-8-rail-trail.html",
    "title": "AE 8: Rail Trail",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-8-rail-trail-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#packages-and-data",
    "href": "ae/ae-8-rail-trail.html#packages-and-data",
    "title": "AE 8: Rail Trail",
    "section": "Packages and data",
    "text": "Packages and data\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nrail_trail &lt;- read_csv(\"data/rail_trail.csv\")"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-1",
    "href": "ae/ae-8-rail-trail.html#exercise-1",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 1",
    "text": "Exercise 1\nFit a model predicting volume from hightemp and season.\n\nrt_mlr_main_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(volume ~ hightemp + season, data = rail_trail)\n\ntidy(rt_mlr_main_fit)\n\n# A tibble: 4 × 5\n  term         estimate std.error statistic       p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   -125.       71.7     -1.75  0.0841       \n2 hightemp         7.54      1.17     6.43  0.00000000692\n3 seasonSpring     5.13     34.3      0.150 0.881        \n4 seasonSummer   -76.8      47.7     -1.61  0.111        \n\n\nRecreate the following visualization which displays the three regression lines we can draw based on the results of this model.\n\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-2",
    "href": "ae/ae-8-rail-trail.html#exercise-2",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 2",
    "text": "Exercise 2\nAdd an interaction effect between hightemp and season and comment on the significance of the interaction predictors. Time permitting, visualize the interaction model as well.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-3",
    "href": "ae/ae-8-rail-trail.html#exercise-3",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model predicting volume from all available predictors.\n\nrt_full_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(volume ~ ., data = rail_trail)\n\ntidy(rt_full_fit)\n\n# A tibble: 8 × 5\n  term            estimate std.error statistic p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)        17.6      76.6      0.230 0.819  \n2 hightemp            7.07      2.42     2.92  0.00450\n3 avgtemp            -2.04      3.14    -0.648 0.519  \n4 seasonSpring       35.9      33.0      1.09  0.280  \n5 seasonSummer       24.2      52.8      0.457 0.649  \n6 cloudcover         -7.25      3.84    -1.89  0.0627 \n7 precip            -95.7      42.6     -2.25  0.0273 \n8 day_typeWeekend    35.9      22.4      1.60  0.113  \n\n\nRecreate the following visualization which displays a histogram of residuals and a normal density curve overlaid.\n\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html",
    "href": "ae/ae-12-exam-3-review.html",
    "title": "AE 12: Exam 3 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-12-exam-3-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#packages",
    "href": "ae/ae-12-exam-3-review.html#packages",
    "title": "AE 12: Exam 3 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data)\nlibrary(rms)\nlibrary(nnet)"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#data",
    "href": "ae/ae-12-exam-3-review.html#data",
    "title": "AE 12: Exam 3 Review",
    "section": "Data",
    "text": "Data\nAs part of a study of the effects of predatory intertidal crab species on snail populations, researchers measured the mean closing forces and the propodus heights of the claws on several crabs of three species.\n\n\nclaws &lt;- read_csv(here::here(\"ae\", \"data/claws.csv\"))\n\nWe will use the following variables:\n\nforce: Closing force of claw (newtons)\nheight: Propodus height (mm)\nspecies: Crab species - Cp(Cancer productus), Hn (Hemigrapsus nudus), Lb(Lophopanopeus bellus)\nlb: 1 if Lophopanopeus bellus species, 0 otherwise\nhn: 1 if Hemigrapsus nudus species, 0 otherwise\ncp: 1 if Cancer productus species, 0 otherwise\nforce_cent: mean centered force\nheight_cent: mean centered height\n\nBefore we get started, let’s make the categorical and indicator variables factors.\n\nclaws &lt;- claws %&gt;%\n  mutate(\n    species = as_factor(species),\n    lb = as_factor(lb),\n    hn = as_factor(hn),\n    cp = as_factor(cp)\n  )"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#probabilities-vs.-odds-vs.-log-odds",
    "href": "ae/ae-12-exam-3-review.html#probabilities-vs.-odds-vs.-log-odds",
    "title": "AE 12: Exam 3 Review",
    "section": "Probabilities vs. odds vs. log-odds",
    "text": "Probabilities vs. odds vs. log-odds\nWhy we use log-odds as response variable: https://sta210-s22.github.io/website/slides/lec-18.html#/do-teenagers-get-7-hours-of-sleep"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-1",
    "href": "ae/ae-12-exam-3-review.html#exercise-1",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nFill in the blanks:\n\nUse log-odds to fit the model (outcome)\nUse odds to interpret model results\nUse probabilities to make predictions for individual observations and ultimately to make classification decisions"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-2",
    "href": "ae/ae-12-exam-3-review.html#exercise-2",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose we want to use force to determine whether or not a crab is from the Lophopanopeus bellus (Lb) species. Why should we use a logistic regression model for this analysis?\n\nclaws %&gt;%\n  distinct(lb)\n\n# A tibble: 2 × 1\n  lb   \n  &lt;fct&gt;\n1 0    \n2 1"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-3",
    "href": "ae/ae-12-exam-3-review.html#exercise-3",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe will use the mean-centered variables for force in the model. The model output is below. Write the equation of the model produced by R. Don’t forget to fill in the blanks for ….\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.798\n0.358\n-2.233\n0.026\n-1.542\n-0.123\n\n\nforce_cent\n0.043\n0.039\n1.090\n0.276\n-0.034\n0.123\n\n\n\n\n\nLet \\(\\pi\\) be probability that a crab is from Lb species.\n\\[\n\\log\\Big(\\frac{\\hat{\\pi}}{1 - \\hat{\\pi}}\\Big) = -0.798 + 0.043 * force\\_cent\n\\]"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-4",
    "href": "ae/ae-12-exam-3-review.html#exercise-4",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nInterpret the intercept in the context of the data.\n\nmean_force &lt;- round(mean(claws$force), 2)\n\nFor crabs with average closing force (12.13 newtons), we expect odds of the crab being Lophopanopeus bellus is 0.45 (exp(-0.798))."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-5",
    "href": "ae/ae-12-exam-3-review.html#exercise-5",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nInterpret the effect of force in the context of the data.\nWhen x goes up by 1 unit, we expect y to change by (slope) units.\nFor each additional unit increase in closing force, the odds of crab being from lb species multiplies on average by a factor of 1.0439379."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-6",
    "href": "ae/ae-12-exam-3-review.html#exercise-6",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nNow let’s consider adding height_cent to the model. Fit the model that includes height_cent. Then use AIC to choose the model that best fits the data.\n\nlb_fit_2 &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  fit(lb ~ force_cent + height_cent, data = claws)\n\ntidy(lb_fit_2, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   -1.13     0.463      -2.44  0.0146  -2.17      -0.306\n2 force_cent     0.211    0.0925      2.28  0.0227   0.0563     0.424\n3 height_cent   -0.895    0.398      -2.25  0.0245  -1.82      -0.234\n\nglance(lb_fit_1)$AIC\n\n[1] 50.19535\n\nglance(lb_fit_2)$AIC\n\n[1] 44.11812"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-7",
    "href": "ae/ae-12-exam-3-review.html#exercise-7",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat do the following mean in the context of this data. Explain and calculate them.\n\nSensitivity: P(predict lb | actual lb) = 6 / 12\nSpecificity: P(predict not lb | actual not lb) = 4/ 26\nNegative predictive power: P(actual not lb | predict not lb) = 22 / 28\nPositive predictive power: P(actual lb | predict lb) = 6 / 10\n\n\n\n\nActual\nPredict lb\nPredict not lb\nTOTAL predicted\n\n\n\n\nLb\n6\n6\n12\n\n\nNot lb\n4\n22\n26\n\n\nTOTAL actual\n10\n28\n38"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-8",
    "href": "ae/ae-12-exam-3-review.html#exercise-8",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 8",
    "text": "Exercise 8\nWrite the equation of the model.\n\\[\\log\\Big(\\frac{\\hat{\\pi}_{Hn}}{\\hat{\\pi}_{Cp}}\\Big) = \\]\n\\[\\log\\Big(\\frac{\\hat{\\pi}_{Lb}}{\\hat{\\pi}_{Cp}}\\Big) = \\]"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-9",
    "href": "ae/ae-12-exam-3-review.html#exercise-9",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nInterpret the intercept for the odds a crab is Hn vs. Cp species.\nInterpret the effect of force on the odds a crab is Lb vs. Cp species."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-10",
    "href": "ae/ae-12-exam-3-review.html#exercise-10",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the effect of force on the odds a crab is in the Hn vs. Lb species.\nCAUTION: We can write an interpretation based on the estimated coefficients; however, we can’t make any inferential conclusions for this question based on the current model. We would need to refit the model with Lb as the baseline category to do so."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-11",
    "href": "ae/ae-12-exam-3-review.html#exercise-11",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 11",
    "text": "Exercise 11\nConditions for multinomial logistic (and logistic models as well):\n\nIndependence:\nRandomness:\nLinearity:\n\nemplogitplot1(lb ~ force, data = claws, ngroups = 10)\nemplogitplot1(lb ~ height, data = claws, ngroups = 10)\n\n\n\n\n\n\n\n\n\n\n# add code here for other species here\n\n\n\n# add code here for other species here"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#checking-for-multicollinearity-in-logistic-and-multinomial-logistic",
    "href": "ae/ae-12-exam-3-review.html#checking-for-multicollinearity-in-logistic-and-multinomial-logistic",
    "title": "AE 12: Exam 3 Review",
    "section": "Checking for multicollinearity in logistic and multinomial logistic",
    "text": "Checking for multicollinearity in logistic and multinomial logistic\nSimilar to multiple linear regression, we can also check for multicollinearity in logistic and multinomial logistic models.\n\nUse the vif function to check for multicollinearity in logistic regression.\n\n\nThe vif function doesn’t work for the multinomial logistic regression models, so we can look at a correlation matrix of the predictors as a way to assess if the predictors are highly correlated:"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html",
    "href": "ae/ae-7-exam-2-review.html",
    "title": "AE 7: Exam 2 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-7-exam-2-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#packages",
    "href": "ae/ae-7-exam-2-review.html#packages",
    "title": "AE 7: Exam 2 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(openintro)\n\n# fix data!\nloans_full_schema &lt;- droplevels(loans_full_schema)"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#goal",
    "href": "ae/ae-7-exam-2-review.html#goal",
    "title": "AE 7: Exam 2 Review",
    "section": "Goal",
    "text": "Goal\nCreate a model for precicting interest_rate."
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#view-data",
    "href": "ae/ae-7-exam-2-review.html#view-data",
    "title": "AE 7: Exam 2 Review",
    "section": "View data",
    "text": "View data\nNote the dimensions of the data and the variable names. Review the data dictionary.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#split-data-into-training-and-testing",
    "href": "ae/ae-7-exam-2-review.html#split-data-into-training-and-testing",
    "title": "AE 7: Exam 2 Review",
    "section": "Split data into training and testing",
    "text": "Split data into training and testing\nSplit your data into testing and training sets.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#write-the-model",
    "href": "ae/ae-7-exam-2-review.html#write-the-model",
    "title": "AE 7: Exam 2 Review",
    "section": "Write the model",
    "text": "Write the model\nWrite the model for predicting interest rate (interest_rate) from debt to income ratio (debt_to_income), the term of loan (term), the number of inquiries (credit checks) into the applicant’s credit during the last 12 months (inquiries_last_12m), whether there are any bankruptcies listed in the public record for this applicant (bankrupt), and the type of application (application_type). The model should allow for the effect of to income ratio on interest rate to vary by application type.\nAdd model here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#exploration",
    "href": "ae/ae-7-exam-2-review.html#exploration",
    "title": "AE 7: Exam 2 Review",
    "section": "Exploration",
    "text": "Exploration\nExplore characteristics of the variables you’ll use for the model using the training data only.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#specify-model",
    "href": "ae/ae-7-exam-2-review.html#specify-model",
    "title": "AE 7: Exam 2 Review",
    "section": "Specify model",
    "text": "Specify model\nSpecify a linear regression model. Call it office_spec.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#create-recipe",
    "href": "ae/ae-7-exam-2-review.html#create-recipe",
    "title": "AE 7: Exam 2 Review",
    "section": "Create recipe",
    "text": "Create recipe\n\nPredict interest_rate from debt_to_income, term, inquiries_last_12m, public_record_bankrupt, and application_type.\nMean center debt_to_income.\nMake term a factor.\nCreate a new variable: bankrupt that takes on the value “no” if public_record_bankrupt is 0 and the value “yes” if public_record_bankrupt is 1 or higher. Then, remove public_record_bankrupt.\nInteract application_type with debt_to_income.\nCreate dummy variables where needed and drop any zero variance variables.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#create-workflow",
    "href": "ae/ae-7-exam-2-review.html#create-workflow",
    "title": "AE 7: Exam 2 Review",
    "section": "Create workflow",
    "text": "Create workflow\nCreate the workflow that brings together the model specification and recipe.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#cross-validation",
    "href": "ae/ae-7-exam-2-review.html#cross-validation",
    "title": "AE 7: Exam 2 Review",
    "section": "Cross validation",
    "text": "Cross validation\nConduct 10-fold cross validation.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#summarize-cv-metrics",
    "href": "ae/ae-7-exam-2-review.html#summarize-cv-metrics",
    "title": "AE 7: Exam 2 Review",
    "section": "Summarize CV metrics",
    "text": "Summarize CV metrics\nSummarize metrics from your CV resamples.\n\n# add code here\n\nWhy are we focusing on R-squared and RMSE instead of adjusted R-squared, AIC, BIC?\n[Add response here]"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#next-steps",
    "href": "ae/ae-7-exam-2-review.html#next-steps",
    "title": "AE 7: Exam 2 Review",
    "section": "Next steps…",
    "text": "Next steps…\nDepending on time, either\n\nCreate a workflow for another model with a new recipe (omitting the interaction variable), conduct CV, do model selection between these two, and then interpret the coefficients for the selected model.\nOr interpret the coefficients for the one model you fit.\n\nMake sure to interpret the intercept and slope coefficient for at least one numerical, one categorical, and one interaction predictor."
  },
  {
    "objectID": "ae/ae-3-duke-forest.html",
    "href": "ae/ae-3-duke-forest.html",
    "title": "AE 3: Duke Forest houses",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-3-duke-forest-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#packages",
    "href": "ae/ae-3-duke-forest.html#packages",
    "title": "AE 3: Duke Forest houses",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#predict-sale-price-from-area",
    "href": "ae/ae-3-duke-forest.html#predict-sale-price-from-area",
    "title": "AE 3: Duke Forest houses",
    "section": "Predict sale price from area",
    "text": "Predict sale price from area\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#model-conditions",
    "href": "ae/ae-3-duke-forest.html#model-conditions",
    "title": "AE 3: Duke Forest houses",
    "section": "Model conditions",
    "text": "Model conditions\n\nExercise 1\nThe following code produces the residuals vs. fitted values plot for this model. Comment out the layer that defines the y-axis limits and re-create the plot. How does the plot change? Why might we want to define the limits explicitly?\n\ndf_aug &lt;- augment(df_fit$fit)\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )\n\n\n\n\n\n\n\n\n\n\nExercise 2\nImprove how the values on the axes of the plot are displayed by modifying the code below.\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html",
    "href": "ae/ae-10-flight-delays.html",
    "title": "AE 10: Flight delays",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-10-flight-delays-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#packages",
    "href": "ae/ae-10-flight-delays.html#packages",
    "title": "AE 10: Flight delays",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#data",
    "href": "ae/ae-10-flight-delays.html#data",
    "title": "AE 10: Flight delays",
    "section": "Data",
    "text": "Data\nFor this application exercise we will work with a dataset of 25,000 randomly sampled flights that departed one of three NYC airports (JFK, LGA, EWR) in 2013.\n\nflight_data &lt;- read_csv(\"data/flight-data.csv\")\n\nRows: 25000 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): origin, dest, carrier, arr_delay\ndbl  (4): dep_time, flight, air_time, distance\ndttm (1): time_hour\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nConvert arr_delay to factor with levels \"late\" (first level) and \"on_time\" (second level). This variable is our outcome and it indicates whether the flight’s arrival was more than 30 minutes.\n\n\nflight_data &lt;- flight_data %&gt;%\n  mutate(arr_delay = as.factor(arr_delay))\n\nlevels(flight_data$arr_delay)\n\n[1] \"late\"    \"on_time\"\n\n\n\nLet’s get started with some data prep: Convert all variables that are character strings to factors.\n\n\n#flight_data &lt;- flight_data %&gt;%\n#  mutate(\n#    origin = as.factor(origin),\n#    carrier = as.factor(carrier),\n#    dest = as.factor(dest)\n#    )\n\nflight_data &lt;- flight_data %&gt;%\n  #go across all columns and convert that are characters to factors\n  #go across all columns and convert if is.character = TRUE to factors\n  #go across all columns and if is.character apply as.factor\n  mutate(across(where(is.character), as.factor))"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#modeling-prep",
    "href": "ae/ae-10-flight-delays.html#modeling-prep",
    "title": "AE 10: Flight delays",
    "section": "Modeling prep",
    "text": "Modeling prep\n\nSplit the data into testing (75%) and training (25%), and save each subset.\n\n\nset.seed(222)\n\nflight_split &lt;- initial_split(flight_data)\n\nflight_train &lt;- training(flight_split)\nflight_test &lt;- testing(flight_split)\n\n\nSpecify a logistic regression model that uses the \"glm\" engine.\n\n\nflight_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\")\n\nNext, we’ll create two recipes and workflows and compare them to each other."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#model-1-everything-and-the-kitchen-sink",
    "href": "ae/ae-10-flight-delays.html#model-1-everything-and-the-kitchen-sink",
    "title": "AE 10: Flight delays",
    "section": "Model 1: Everything and the kitchen sink",
    "text": "Model 1: Everything and the kitchen sink\n\nDefine a recipe that predicts arr_delay using all variables except for flight and time_hour, which, in combination, can be used to identify a flight. Also make sure this recipe handles dummy coding as well as issues that can arise due to having categorical variables with some levels apparent in the training set but not in the testing set. Call this recipe flights_rec1.\n\n\nflights_rec1 &lt;- recipe(arr_delay ~ ., data = flight_train) %&gt;%\n  update_role(flight, time_hour, new_role = \"id\") %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())\n\n\nCreate a workflow that uses flights_rec1 and the model you specified.\n\n\nflight_wflow1 &lt;- workflow() %&gt;%\n  add_recipe(flights_rec1) %&gt;%\n  add_model(flight_spec)\n\n\nFit the this model to the training data using your workflow and display a tidy summary of the model fit.\n\n\nflight_fit1 &lt;- flight_wflow1 %&gt;%\n  fit(data = flight_train)\n\ntidy(flight_fit1)\n\n# A tibble: 119 × 5\n   term          estimate   std.error statistic   p.value\n   &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)  13.3      287.          0.0464  9.63e-  1\n 2 dep_time     -0.00164    0.0000504 -32.6     1.04e-233\n 3 air_time     -0.0349     0.00179   -19.5     1.75e- 84\n 4 distance      0.00533    0.00523     1.02    3.08e-  1\n 5 date          0.000227   0.000198    1.15    2.51e-  1\n 6 origin_JFK    0.0830     0.102       0.815   4.15e-  1\n 7 origin_LGA   -0.0360     0.0983     -0.366   7.14e-  1\n 8 dest_ACK    -12.4      287.         -0.0434  9.65e-  1\n 9 dest_ALB    -12.4      287.         -0.0433  9.65e-  1\n10 dest_ANC     -3.75     928.         -0.00404 9.97e-  1\n# … with 109 more rows\n\n\n\nPredict arr_delay for the testing data using this model.\n\n\nflight_aug1 &lt;- augment(flight_fit1, flight_test)\n\n\nPlot the ROC curve and find the area under the curve. Comment on how well you think this model has done for predicting arrival delay.\n\n\nflight_aug1 %&gt;%\n  roc_curve(\n    truth = arr_delay,\n    .pred_late\n  ) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\nflight_aug1 %&gt;%\n  roc_auc(\n    truth = arr_delay,\n    .pred_late\n  )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.734"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#model-2-lets-be-a-bit-more-thoughtful",
    "href": "ae/ae-10-flight-delays.html#model-2-lets-be-a-bit-more-thoughtful",
    "title": "AE 10: Flight delays",
    "section": "Model 2: Let’s be a bit more thoughtful",
    "text": "Model 2: Let’s be a bit more thoughtful\n\nDefine a new recipe, flights_rec2, that, in addition to what was done in flights_rec1, adds features for day of week and month based on date and also adds indicators for all US holidays (also based on date). A list of these holidays can be found in timeDate::listHolidays(\"US\"). Once these features are added, date should be removed from the data. Then, create a new workflow, fit the same model (logistic regression) to the training data, and do predictions on the testing data. Finally, draw another ROC curve and find the area under the curve. Compare the predictive performance of this new model to the previous one. Based on the area under the curve statistic, which model does better?"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#putting-it-altogether",
    "href": "ae/ae-10-flight-delays.html#putting-it-altogether",
    "title": "AE 10: Flight delays",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\nCreate an ROC curve that plots both models, in different colors, and adds a legend indicating which model is which."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#acknowledgement",
    "href": "ae/ae-10-flight-delays.html#acknowledgement",
    "title": "AE 10: Flight delays",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThis exercise was inspired by https://www.tidymodels.org/start/recipes/."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#data-sources",
    "href": "project-tips-resources.html#data-sources",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %&gt;%\n  count(manufacturer) %&gt;%\n  mutate(manufacturer = str_to_title(manufacturer)) %&gt;%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fall 2024 - CSC477/CSC2630: Introduction to Mobile Robotics",
    "section": "",
    "text": "Course Overview\nThis cross-listed course (undergraduate version CSC477H, graduate version CSC2630H) provides an introduction to robotic systems from a computational perspective. A robot is regarded as an intelligent computer that can use sensors and act on the world. We will consider the definitional problems in robotics and look at how they are being solved in practice and by the research community. The emphasis is on algorithms, probabilistic reasoning, optimization, inference mechanisms, and behavior strategies, as opposed to electromechanical systems design. This course aims to help students improve their probabilistic modeling skills and instill the idea that a robot that explicitly accounts for its uncertainty works better than a robot that does not.\n\n\nPrerequisites\nRequired: CSC209H5; STA256H5; MAT223H5/MAT240H5; MAT232H5; CSC376\nRecommended: MAT224H5; CSC384H5; CSC311H5;\n\n\nCourse Delivery Details\n\nLectures: Wednesdays @ 3-5pm ET, MN3190 & Livstreamed on Zoom at MY580\nTutorials: Wednesdays @ 5-6pm ET, DH2020 & Livstreamed on Zoom at MY580\nOffice Hours will be delivered on Zoom. In-person office hours can be arranged by appointment.\nZoom links & Announcements will be posted on Quercus\nDiscussions will take place on Piazza\nAnonymous feedback form for suggested improvements\nCourse Syllabus",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "course-schedule.html",
    "href": "course-schedule.html",
    "title": "Fall 2024 - CSC477/CSC2630: Introduction to Mobile Robotics",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nNotebooks\nAssignments\nProject\n\n\n\n\n1\nSep 14\nIntroduction\n📖\n🖥️\n\n\n\n\n\n\n\nSensors and Actuators\n📖\n\n\n\n\n\n\n2\nSep 21\nKinematics\n📖\n🖥️\n\n\n\n\n\n\n\nDynamics\n📖\n\n\n\n\n\n\n3\nSep 28\nPID Control\n📖\n🖥️\n\n\n\n\n\n\n\nArtificial Potential Fields and Obstacle Avoidance\n📖\n\n📋\n\n\n\n\n4\nOct 5\nPlanning\n📖\n🖥️\n📋\n\n\n\n\n\nOct 12\nReading Week\n\n\n\n\n\n\n\n5\nOct 19\nLinear Quadratic Regulator (LQR)\n\n🖥️\n\n\n\n\n\n6\nOct 26\nMap Representations and Map Alignment\n\n🖥️\n\n\n📂\n\n\n\n\nOccupancy Grid Mapping With Known Robot Poses\n\n\n\n\n\n\n\n7\nNov 2\nMaximum Likelihood, Least Squares Estimation, Maximum A Posteriori Estimation\n📖\n🖥️\n📋\n\n\n\n\n\n\nGraphSLAM\n📖\n\n📋\n\n\n\n\n8\nNov 9\nKalman Filter\n\n🖥️\n\n\n\n\n\n\n\nBayes’ Filter and Kalman Filter\n\n\n\n\n\n\n\n9\nNov 16\nExtended Kalman Filter (EKF)\n📖\n🖥️\n📋\n\n\n\n\n10\nNov 23\nParticle Filter\n📖\n🖥️\n📋\n\n\n\n\n\n\nImitation with a human in the loop\n📖\n\n📋\n\n\n\n\n\n\nTeleoperation\n📖\n\n📋\n\n\n\n\n11\nNov 30\nCamera Optics and Multi-view Geometry\n📖\n🖥️\n📋\n\n\n\n\n\n\nCausal confusion in imitation learning\n📖\n\n📋\n\n\n\n\n12\nDec 7\nVisual odometry and Visual SLAM\n📖\n🖥️\n📋\n\n\n\n\n\n\nGeneralization and safety guarantees for imitation\n📖\n\n📋\n\n\n\n\n13\nDec 8\nStudy break, beginning of exams",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Final Project Guidelines",
    "section": "",
    "text": "The project in this course is an opportunity to develop deep learning application in an area of your own choosing. It also provides the chance to complete a deep learning project that is much closer to a real-world application area, for example in medicine, finance, robotics, commerce, biology, chemistry, physics (or other sciences), social media, or other fields.\nWhile this project has some structure, you will be required to deal with the ambiguity and significant decision making that make up the life of a deep learning practitioner."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Final Project Guidelines",
    "section": "Project Proposal",
    "text": "Project Proposal\n\nLogistics\nProjects must be done in groups of 3-4. Please form groups on Markus by March 17, 10pm. Exceptions to this rule can be made only in rare cases provided there is good reason to do so. Email the instructors if this applies to you. If you do not know anyone in class feel free to post a message on Piazza. We will also set aside some time during the tutorial for students who are looking for collaborators to find each other and discuss forming a group.\nA 1-2 page project proposal is due March 21, 10pm. You will also be asked to summarize the data set that you are using for this proposal.\nEach team will submit a github repository page that describes the deep learning model built in the project. The repository should also contain the code that you wrote.\n\n\nProject Requirements\nBy default, your project must either take a sequence (of variable length) as an input, or produce a sequence as an output, or both. If you have a project proposal that does not involve sequences, please contact the instructors.\nYour model should thus involve an RNN or a Transformer component. Students who want to use methods that we have not covered in the course (e.g. diffusion models, neural ODEs) are free to do so, as long as they confirm their methodology with the instructors before they submit this project proposal. There is also flexibility for students to pursue an open research problem. If any groups want to attempt this, they need to discuss this with one of the instructors before the prject proposal deadline.\nHere are some examples of possible projects:\n\nUsing an RNN (or transformer) to classify sequences (e.g. whether a restaurant review is positive or negative)\nUsing a generative RNN to produce sequences (e.g. South Park TV scripts)\nUsing a Siamese network to determine whether two StackOverflow questions are duplicates\nPredict the next item in a sequence (e.g. Stock market)\nPredict the outcome of a patient based on some sequential factors\nPredict the dynamics of objects under contact and collision (e.g. robotics and graphics)\nGenerate molecules, or predict properties of molecules\n\nBefore choosing a project, consider whether there is data available for you. Since the project deadline is about a month away, consider tailoring your project ideas to what data is available to you.\nYou are encouraged to use transfer learning and data augmentation ideas in your project.\nYou can use deep learning packages (e.g. pytorch, huggingface). However, you should be able to explain the steps involved in the forward pass computation of your model.\n\n\nProject Proposal\nA 1-2 page project proposal is due March 21, 10pm. Please use 12-point font and standard margins. You will also be asked to summarize the data set that you are using for this proposal.\nThe proposal should:\n\nClearly describe the task that your model will perform. (2pt)\n\n2/2 for clearly describing the task using standard deep learning terminology\n1.5/2 for describing the task in a way that is understandable to the grader, but that uses non-standard terminology\n1/2 for describing the task generally (e.g. “sequence classification” without stating the exact classes)\n0/2 for a proposal that does not align with the project requirements\n\nClearly describe the model that you intend to use (2pt)\n\n2/2 for clearly describing the model using standard deep learning terminology; the grader can picture exactly how the model could be used.\n1.5/2 for describing the task in a way that is understandable to the grader, but that uses non-standard terminology\n1/2 for describing the models generally (e.g. sequence-to-sequence model, without describing which ones)\n0/2 for a model that does not align with the project requirements\n\nOutline the data set that you intend to use, and provide some statistics about the amount/type of data that is available (4pt)\n\n1 point for convincing the grader that you are able to acquire the data that you need (with the appropriate license/permission for educational use)\n1 point for convincing the grader that the type and amount of data is sufficient (e.g. via summary statistics, examples data set)\n2 points for convincing the grader that you have explored the data, and considered information about your data relevant to your model (like in A1 Q1)\n\nDiscuss any ethical implications of your model—how might the use (or misuse) of this model help or hurt people? (2pt)\n\n2/2 For a thoughtful discussion that considers the ethical implications across many groups of people (that different groups may be impacted differently).\n1/2 For a discussion that is generic, or considers the ethical implications for only one group of people.\n\nDescribe how work will be divided amongst the team members. We recommend pair-coding for parts of the project, but consider the work that it might take to load/format your data, write a first model, “overfit” to a single data point, etc… (2pt)\n\n2/2 The description provides enough detail so that if a team member is replaced, they know exactly what their responsibilities will be.\n1/2 There is clearly an attempt to describe the division of tasks, but the communication is unclear and/or only the tasks listed above are assigned.\n0/2 Only vague assertions are made (e.g. “we will divide the work equally”, “everyone will work on everything”, or “we will determine who will work on what as the project progresses).\n\nProper formatting (2pt)\n\n2/2 Proposal is 1-2 pages. The proposal is formatted so that readers can find specific information quickly (e.g. via the use of paragraphs and topic sentences)\n1/2 Proposal is slightly over the length limit. There was clearly an attempt to format the proposal, but information is still scattered in various places.\n0/2 Proposal runs extremely long. It is difficult to understand the structure of the proposal."
  },
  {
    "objectID": "project-description.html#final-project",
    "href": "project-description.html#final-project",
    "title": "Final Project Guidelines",
    "section": "Final Project",
    "text": "Final Project\n\nSubmission\nPlease submit a file called github.txt containing a link to the github repository. If your repository will be private, please email the instructors by April 7, 10pm so that TAs and instructors can be added—even if you use tokens.\n\n\nRepository Content\nThe repository should contain:\n\nThe code you used to pre-process the data, but not the data itself. It is generally a bad idea to include data in your github repository, since git is great for lots of small files, but a poor choice for sharing large files. Moreover, most groups are using data collected by other people. While you should share the source of your data, you should generally not share a copy of the data.\nThe code you used to train your model. You may opt to share model weights, or not.\nA README file with the following component:\n\n\nIntroduction that states the deep learning model that you are building\nModel:\n\nA figure/diagram of the model architecture that demonstrates understanding of the steps involved in computing the forward pass\nCount the number of parameters in the model, and a description of where the parameters come from\nExamples of how the model performs on two actual examples from the test set: one successful and one unsuccessful\n\nData:\n\nDescribe the source of your data\nProvide summary statistics of your data to help interpret your results (similar to in the proposal)\nDescribe how you transformed the data (e.g. any data augmentation techniques)\nIf appropriate to your project, describe how the train/validation/test set was split. (Note that splitting the training/validation/test set is not always straightforward!)\n\nTraining:\n\nThe training curve of your final model\nA description how you tuned hyper-parameters\n\nResults:\n\nDescribe the quantitative measure that you are using to evaluate your result\nDescribe the quantitative and qualitative results\nA justification that your implemented method performed reasonably, given the difficulty of the problem—or a hypothesis for why it doesn’t (this is extremely important)\n\nEthical Consideration:\n\nDescription of a use of the system that could give rise to ethical issues. Are there limitations of your model? Your training data?\n\nAuthors\n\nA description of how the work was split—i.e. who did what in this project.\n\n\n\n\nMarking Scheme\nHere is the marking scheme that we will use. Note that you model must be able to make reasonable predictions for your project to receive a passing project grade. In particular, without a reasonable model, you won’t be able to earn credit for Model Examples, Training Curve, Hyperparameter Tuning, Qualitative/Quantitative Results, etc.\nREADME/Writeup (70 points)\n\nIntroduction (4 points): What deep learning model are you building? We are looking for a clear and concise description that uses standard deep learning terminology. Clearly describe the type of task that you are solving, and what your input/outputs are.\nModel Figure (4 points): A figure/diagram of the model architecture that demonstrates understanding of the steps involved in computing the forward pass. We are looking to see if you understand the steps involved in the model computation (i.e. are you treating the model as a black box or do you understand what it’s doing?)\nModel Parameters(4 points): Count the number of parameters in the model, and a description of where the parameters come from. Again, we are looking to see if you understand what the model is doing, and what parameters are being tuned.\nModel Examples (4 points): Examples of how the model performs on two actual examples from the test set: one successful and one unsuccessful.\nData Source (1 point): Describe the source of your data.\nData Summary (4 points): Provide summary statistics of your data to help interpret your results, similar to in the proposal. Please review the feedback provided in the proposal for some guidance on what information is helpful for interpreting your model behaviour.\nData Transformation (3 points): Describe how you transformed the data, i.e. the steps you took to turn the data from what you downloaded, to something that a neural network can use as input. We are looking for a concise description that has just enough information for another person to replicate your process.\nData Split (2 points): If appropriate to your project, describe how the train/validation/test set was split. Note that splitting strategy is not always straightforward, so we are looking to see a split that can be justified.\nTraining Curve (4 points): The training curve of your final model. We are looking for a curve that shows both training and validation performance (if applicable). Your training curve should look reasonable for the problem that you are solving.\nHyperparamter Tuning (4 points): A description how you tuned hyper-parameters. We are looking for hyperparameter choices that makes sense.\nQuantitative Measures (2 points): A description and justification of the quantitative measure that you are using to evaluate your results. For some problems this will be straightforward. For others, please justify the measure that you chose.\nQuantitative and Qualitative Results (8 points): Describe the quantitative and qualitative results. You may choose to use a table or figure to aid in your description. We are looking for both a clear presentation, and a result that makes sense given your data summary. (As an extreme example, you should not have a result that performs worse than a model that, say, predicts the most common class.)\nJustification of Results (20 points): A justification that your implemented method performed reasonably, given the difficulty of the problem—or a hypothesis for why it doesn’t. This is extremely important. We are looking for an interpretation of the result. You may want to refer to your data summary and hyperparameter choices to make your argument.\nEthical Consideration (4 points): Description of a use of the system that could give rise to ethical issues. Are there limitations of your model? Your training data? Please review the feedback provided in the proposal for some guidance on how to think deeply about these issues.\nAuthors (2 points): A description of how the work was split—i.e. who did what in this project. If there are significant issues with the way that work is split, we may follow up with individual teams, and not award equal points to all team members.\n\nCode/Documentation (20 points) We are looking for whether TAs can generally understand what your code does, how it is organized, and the steps that needs to be taken to replicate your model and results. Your code must be in working order (otherwise the TA will not be able to replicate your results)\nAdvanced Concept (10 points). Your project involves at least one of the following:\n\nData Augmentation applied in a way that makes sense for your domain\nTransformer\nGenerative Model, Sequence-to-Sequence Architecture (e.g. that uses teacher-forcing)"
  },
  {
    "objectID": "lecs/w03/lec03.html#feedback-control",
    "href": "lecs/w03/lec03.html#feedback-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Feedback Control",
    "text": "Feedback Control\n\nMain question: what are the controls that will take the system from state A to B?"
  },
  {
    "objectID": "lecs/w03/lec03.html#example-wallline-following-at-fixed-speed",
    "href": "lecs/w03/lec03.html#example-wallline-following-at-fixed-speed",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: wall/line following at fixed speed",
    "text": "Example: wall/line following at fixed speed\n\n\n\nYou have to control the angular velocity \\(w\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#why-bother-with-wallline-following",
    "href": "lecs/w03/lec03.html#why-bother-with-wallline-following",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why bother with wall/line following?",
    "text": "Why bother with wall/line following?\n\nBecause it enables arbitrary path following where the line is the local tangent of the curved path"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-1-bang-bang-control",
    "href": "lecs/w03/lec03.html#idea-1-bang-bang-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 1: bang-bang control",
    "text": "Idea 1: bang-bang control\n\\[\n\\omega = \\begin{cases}\n\\omega_{\\text{max}} & \\text{if } \\text{CTE} &gt; 0 \\\\\n-\\omega_{\\text{max}} & \\text{if } \\text{CTE} &lt; 0 \\\\\n0\n\\end{cases}\n\\]\nWhat’s wrong with this?"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-2-proportional-p-control",
    "href": "lecs/w03/lec03.html#idea-2-proportional-p-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 2: proportional (P-)control",
    "text": "Idea 2: proportional (P-)control\n\\[\nw = K_{p}e(t)\n\\]\nWill the car reach the target line?\nWill the car overshoot the target line?\nIs the asymptotic (steady-state) error zero?"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-2-proportional-p-control-1",
    "href": "lecs/w03/lec03.html#idea-2-proportional-p-control-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 2: proportional (P-)control",
    "text": "Idea 2: proportional (P-)control\n\\[\nw = K_{p}e(t)\n\\]\n\nWill the car reach the target line? YES\nWill the car overshoot the target line? YES\nIs the asymptotic (steady-state) error zero? NO"
  },
  {
    "objectID": "lecs/w03/lec03.html#addressing-the-oscillation-problem",
    "href": "lecs/w03/lec03.html#addressing-the-oscillation-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Addressing the oscillation problem",
    "text": "Addressing the oscillation problem\n\nNeed to reduce turning rate well before the line is approached\nIdea: have a small proportional gain \\(K_p\\)\nProblem: that means the car doesn’t turn very much\nIdea: need to predict the error in the near future\nThis is good, as long as the error does not oscillate at a very high frequency"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-3-proportional-derivative-pd-control",
    "href": "lecs/w03/lec03.html#idea-3-proportional-derivative-pd-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 3: proportional-derivative (PD-)control",
    "text": "Idea 3: proportional-derivative (PD-)control\n\\[\nW = K_{p}e(t) + K_{d}\\dot e(t)\n\\]\n\nHow do we set the gains?\nWhat if there are systematic errors/biases?\nWhat if the error estimate is very noisy?"
  },
  {
    "objectID": "lecs/w03/lec03.html#handling-systematic-biases-the-integral-term",
    "href": "lecs/w03/lec03.html#handling-systematic-biases-the-integral-term",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Handling systematic biases: the integral term",
    "text": "Handling systematic biases: the integral term\n\nExamples of systematic biases:\n\nwheels are misaligned\ncar is much heavier on one side\n\nAdd integral of the error from the beginning of time: \\(\\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau\\)\n\n\n\nCan the PI-controller have nonzero error asymptotically (in steady-state)?\n\nNO. In steady state both the control \\(w_\\infty\\) and the error \\(e_\\infty\\) must be constant. If the asymptotic error is nonzero then the control is not constant: \\(\\omega_\\infty = K_p e_\\infty + K_i e_\\infty t\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-problem-integrator-windup",
    "href": "lecs/w03/lec03.html#potential-problem-integrator-windup",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential problem: integrator windup",
    "text": "Potential problem: integrator windup\n\nWhat happens if the control variable reaches the actuator’s limits?\nI.e. the car can’t turn as fast as the controller commands it.\nActuator may remain at its limit for a long time while the controller modifies its commands\nError increases, integral term winds up while controller goes back to issuing commands in the feasible region."
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-problem-integrator-windup-1",
    "href": "lecs/w03/lec03.html#potential-problem-integrator-windup-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential problem: integrator windup",
    "text": "Potential problem: integrator windup\n\nHeuristic fixes:\n\nLimit integral error values\nStop integral error while the commands are in the non feasible region\nReduce gain of integral error term"
  },
  {
    "objectID": "lecs/w03/lec03.html#pid-controller",
    "href": "lecs/w03/lec03.html#pid-controller",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PID controller",
    "text": "PID controller\n\\[\n\\omega(t) = K_p e(t) + K_d \\dot{e}(t) + K_i \\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau\n\\]\nPerhaps the most widely used controller in industry and robotics.\nPerhaps the easiest to code.\n\f\nYou will also see it as:\n\\[\n\\omega(t) = K_p \\left[ e(t) + T_d \\dot{e}(t) + \\frac{1}{T_i} \\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau \\right]\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-implement-pid",
    "href": "lecs/w03/lec03.html#tips-how-to-implement-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to implement PID",
    "text": "Tips: how to implement PID\n\n\nAssume time is discrete\nIdentify your error function e(t)= current_state(t)- target_state(t)\nIs the measurement of the state reliable?\nIf the measurement of the current state is very noisy you might want to smooth/filter it, using:\n\nMoving average filter with uniform weights \\[\n\\hat{x}_t = \\frac{x_t + x_{t-1} + \\ldots + x_{t-k+1}}{k} = \\hat{x}_{t-1} + \\frac{x_t - x_{t-k}}{k}\n\\]\nPotential problem: the larger the window of the filter the slower it is going to register changes.\nExponential filter \\[\n\\hat{x}_t = \\alpha \\hat{x}_{t-1} + (1 - \\alpha) x_t, \\quad \\alpha \\in [0, 1]\n\\]\nPotential problem: the closer is to 1 the slower it is going to register changes."
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-implement-pid-1",
    "href": "lecs/w03/lec03.html#tips-how-to-implement-pid-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to implement PID",
    "text": "Tips: how to implement PID\n\nApproximate the integral of error by a sum\nApproximate the derivative of error by:\n\nFinite differences \\(\\dot{e}(t_k) \\approx \\frac{e(t_k) - e(t_{k-1})}{\\delta t}\\)\nFiltered finite differences, e.g. \\(\\dot{e}(t_k) \\approx \\alpha \\dot{e}(t_{k-1}) + (1 - \\alpha) \\frac{e(t_k) - e(t_{k-1})}{\\delta t}\\)\n\nLimit the computed controls\nLimit or stop the integral term when detecting large errors and windup"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nManually:\n\nFirst, use only the proportional term. Set the other gains to zero.\nWhen you see oscillations slowly add derivative term\n\nIncreasing \\(K_d\\) increases the duration in which linear error prediction is assumed to be valid\n\nAdd a small integral gain"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-1",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nZiegler-Nichols heuristic:\n\nFirst, use only the proportional term. Set the other gains to zero.\nWhen you see consistent oscillations, record the proportional gain \\(K_u\\) and the oscillation period \\(T_u\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-2",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nAfter manual or Z-N tweaking you might want to use coordinate ascent to search for a better set of parameters automatically:\n\n\n\n\n\n\n\nSee Sebastian Thrun’s online class\n“AI for robotics” on Udacity for more\ndetails on this. He calls the algorithm\nTwiddle and it is in Lesson 5.\nOther names for this are\n“Self-tuning PID controllers”"
  },
  {
    "objectID": "lecs/w03/lec03.html#when-is-pid-insufficient",
    "href": "lecs/w03/lec03.html#when-is-pid-insufficient",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "When is PID insufficient?",
    "text": "When is PID insufficient?\n\nSystems with large time delays\nControllers that require completion time guarantees\n\nE.g. the system must reach target state within 2 secs\n\nSystems with high-frequency oscillations\nHigh-frequency variations on the target state"
  },
  {
    "objectID": "lecs/w03/lec03.html#example-applications-self-driving-cars",
    "href": "lecs/w03/lec03.html#example-applications-self-driving-cars",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example applications: self-driving cars",
    "text": "Example applications: self-driving cars"
  },
  {
    "objectID": "lecs/w03/lec03.html#cascading-pid",
    "href": "lecs/w03/lec03.html#cascading-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Cascading PID",
    "text": "Cascading PID\n\nSometimes we have multiple error sources (e.g. multiple sensors) and one actuator to control.\nWe can use a master PID loop that sets the setpoint for the slave PID loop. Master (outer loop) runs at low rate, while slave (inner loop) runs at higher rate.\nOne way of getting hierarchical control behavior."
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-fields-main-motivation",
    "href": "lecs/w03/lec03.html#potential-fields-main-motivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential Fields Main Motivation",
    "text": "Potential Fields Main Motivation\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?"
  },
  {
    "objectID": "lecs/w03/lec03.html#main-motivation",
    "href": "lecs/w03/lec03.html#main-motivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main Motivation",
    "text": "Main Motivation\n\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nAssume omnidirectional robot."
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\n\n\n\n\n\n\n\\[\n\\begin{align}\nU(x) &= \\frac{1}{2}kx^2 \\\\\nF(x) &= -kx\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces-1",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\n\n\n\n\n\n\n\\[\n\\begin{align}\nU(x) &= mgx \\\\\nF(x) &= -mg\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces-2",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\nIn both cases we have conversion from kinetic energy to potential energy U(x).\nIn both cases there is a force resulting from the potential field, and F(x)=-dU(x)/dx.\nThis is a general rule for conservative systems with no external forces."
  },
  {
    "objectID": "lecs/w03/lec03.html#main-motivation-1",
    "href": "lecs/w03/lec03.html#main-motivation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main Motivation",
    "text": "Main Motivation\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields",
    "href": "lecs/w03/lec03.html#artificial-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nA: Place a repulsive potential field around obstacles"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-1",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nA: Place a repulsive potential field around obstacles and an attractive potential field around the goal"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-2",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-3",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\n\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]\n\n\n \n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-1",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-2",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-3",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#attractive-and-repulsive-potential-fields",
    "href": "lecs/w03/lec03.html#attractive-and-repulsive-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Attractive and Repulsive Potential Fields",
    "text": "Attractive and Repulsive Potential Fields\n\n\\(U(x) = \\alpha U\\_{\\text{attractive}}(x) + \\beta U\\_{\\text{repulsive}}(x)\\)\n\nQ1: How do we reach the goal state\nfrom an arbitrary state?\nQ2: In this example there is an unambiguous way\nto reach the goal from any state. Is this true in\ngeneral?"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]\n\n\n\n\n\\[\nF_{\\text{attractive}}(x) = -\\nabla_x U_\\text{attractive}(x) = -2(x - x_{\\text{goal}})\n\\]\n\n\n\n\n\nAttractive force makes state x go to the bottom of the potential energy bowl. Bottom=Goal = low-energy state.\n\n\n\n\n\n\nMove the robot using F=ma, for m=1: \\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]\nGradient descent down the potential bowl"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces-1",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]\n\n\n\n\n\\[\nF_{\\text{attractive}}(x) = -\\nabla_x U_\\text{attractive}(x) = -2(x - x_{\\text{goal}})\n\\]\n\n\n\n\n\nAttractive force makes state x go to the bottom of the potential energy bowl. Bottom=Goal = low-energy state.\n\nQ: Do you see any problems with this potential energy and force if x is far away from goal?\n\nA: The farther the robot is the stronger the force. May need to normalize the force vector. Alternatively:\n\\[\nU_{\\text{attractive}}(x) = d(x, x_{\\text{goal}}) \\Rightarrow F_{\\text{attractive}}(x) = -\\frac{(x - x_{\\text{goal}})}{d(x, x_{\\text{goal}})}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces-2",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]\n\n\n\n\n\\[\nF_{\\text{repulsive}}(x) = \\begin{cases}\n2\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right) \\frac{\\nabla_x d(x,\\text{obs})}{d(x,\\text{obs})^2} & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\n\n\nRepulsive force makes state x go away from the obstacle to lower potential energy states. Free space = {low-energy states}\n\n\n\n\n\nMove the robot using F=ma, for m=1:\n\\[\n\\dot x_{t+1} = \\dot x_t + \\delta t F(x_t)\n\\]\nGradient descent until obstacle is cleared"
  },
  {
    "objectID": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces",
    "href": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining Attractive and Repulsive Forces",
    "text": "Combining Attractive and Repulsive Forces\n\nPotential energy\n\\[\nU_{\\text{total}}(x) = \\alpha U_{\\text{attractive}}(x) + \\beta U_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nresults in forces\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nmakes robot accelerate\n\\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-example",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-example",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields: Example",
    "text": "Artificial Potential Fields: Example\n\n\nAdvantages of potential fields:\n\nCan handle moving obstacles\nFast and easy to compute\nFairly reactive"
  },
  {
    "objectID": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces-1",
    "href": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining Attractive and Repulsive Forces",
    "text": "Combining Attractive and Repulsive Forces\n\nPotential energy\n\\[\nU_{\\text{total}}(x) = \\alpha U_{\\text{attractive}}(x) + \\beta U_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nresults in forces\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nmakes robot accelerate\n\\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]\n\nQ: What’s a possible problem\nwith addition of forces?"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-4",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\n\n\n\nWhat’s the total potential here?\n\nIt’s zero. The repulsive force is exactly the opposite of the attractive force (assuming alpha = beta)\n\n\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x) = 0\n\\]\nProblem: gradient descent gets stuck"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Stuck",
    "text": "Local Minima on the Potential Field: Getting Stuck\nStates of zero total force correspond to local minima in the potential function:"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck-1",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Stuck",
    "text": "Local Minima on the Potential Field: Getting Stuck\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-randomly",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-randomly",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Unstuck Randomly",
    "text": "Local Minima on the Potential Field: Getting Unstuck Randomly\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min\nSolution #1: Do random move in case\nit helps you get unstuck."
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-by-backing-up",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-by-backing-up",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Unstuck By Backing Up",
    "text": "Local Minima on the Potential Field: Getting Unstuck By Backing Up\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min\nSolution #2: back up and get out from\nthe dead end, just like you entered it."
  },
  {
    "objectID": "lecs/w03/lec03.html#drawbacks-of-potential-fields",
    "href": "lecs/w03/lec03.html#drawbacks-of-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Drawbacks of potential fields",
    "text": "Drawbacks of potential fields\n\nLocal minima\n\nAttractive and repulsive forces can balance, so robot makes no progress.\nClosely spaced obstacles, or dead end.\n\nUnstable oscillation\n\nThe dynamics of the robot/environment system can become unstable.\nHigh speeds, narrow corridors, sudden changes"
  },
  {
    "objectID": "lecs/w03/lec03.html#avoiding-local-minima-on-the-potential-field-navigation-functions",
    "href": "lecs/w03/lec03.html#avoiding-local-minima-on-the-potential-field-navigation-functions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Avoiding Local Minima on the Potential Field: Navigation Functions",
    "text": "Avoiding Local Minima on the Potential Field: Navigation Functions\nPotential energy function \\(\\phi(x)\\) with a single global minimum at the goal, and no local minima.\nFor any state x there exists a neighboring state x’ such that \\(\\phi(x') &lt; \\phi(x)\\)\n\n\n\nSo far not used in practice very much because they are usually as hard to compute as a planned path from the current state to the goal."
  },
  {
    "objectID": "lecs/w03/lec03.html#addressing-the-drawbacks-of-potential-fields",
    "href": "lecs/w03/lec03.html#addressing-the-drawbacks-of-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Addressing the Drawbacks of Potential Fields",
    "text": "Addressing the Drawbacks of Potential Fields\n\nVector Field Histogram (VFH)\nDynamic Window Approach\n\nBoth methods for local obstacle avoidance"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-1",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)\n\n\n\n\n\n\n\n\n\n\n\nHigh risk for cells with high probability of being occupied.\nRisk inversely proportional to distance."
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-2",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-3",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-4",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#dwa-dynamic-window-approach",
    "href": "lecs/w03/lec03.html#dwa-dynamic-window-approach",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "DWA (Dynamic Window Approach)",
    "text": "DWA (Dynamic Window Approach)\n\n\nLocal, reactive controller\n\nSample a set of controls for x,y,theta\nSimulate where each control is going to take the robot\nEliminate those that lead to collisions.\nReward those that agree with a navigation plan.\nReward high-speeds\nReward proximity to goal.\nPick control with highest score that doesn’t lead to collision."
  },
  {
    "objectID": "lecs/w05/lec05.html#todays-agenda",
    "href": "lecs/w05/lec05.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\nIntro to Control\nLinear Quadratic Regulator (LQR)\n\n\n\n\n\n\nAcknowledgments\nToday’s slides have been influenced by: Pieter Abbeel (ECE287), Sergey Levine (DeepRL), Ben Recht (ICML’18), Emo Todorov, Zico Kolter"
  },
  {
    "objectID": "lecs/w05/lec05.html#section-2",
    "href": "lecs/w05/lec05.html#section-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\operatorname*{minimize}_{\\pi_0, \\ldots, \\pi_{T-1}} \\quad &\\mathbb{E}_{e_t} \\left[ \\sum_{t=0}^{T} c(\\mathbf{x}_t, \\mathbf{u}_t) \\right] \\\\\n\\text{subject to} \\quad &\\mathbf{x}_{t+1} = f_t(\\mathbf{x}_t, \\mathbf{u}_t, e_t) \\quad \\color{red}{\\text{known dynamics}} \\\\\n&\\mathbf{u}_t = \\pi_t(\\mathbf{x}_{0:t}, \\mathbf{u}_{0:t-1}) \\\\\n& \\color{red}\\text{control law / policy}\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#todays-agenda-1",
    "href": "lecs/w05/lec05.html#todays-agenda-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\n\n\nIntro to Control\n\n\n\nLinear Quadratic Regulator (LQR)\n\n\n\n\n\n\nAcknowledgments\nToday’s slides have been influenced by: Pieter Abbeel (ECE287), Sergey Levine (DeepRL), Ben Recht (ICML’18), Emo Todorov, Zico Kolter"
  },
  {
    "objectID": "lecs/w05/lec05.html#what-you-can-do-with-lqr-control",
    "href": "lecs/w05/lec05.html#what-you-can-do-with-lqr-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What you can do with LQR control",
    "text": "What you can do with LQR control"
  },
  {
    "objectID": "lecs/w05/lec05.html#what-you-can-do-with-variants-of-lqr-control",
    "href": "lecs/w05/lec05.html#what-you-can-do-with-variants-of-lqr-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What you can do with (variants of) LQR control",
    "text": "What you can do with (variants of) LQR control\n\nPieter Abbeel, Helicopter Aerobatics"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-assumptions",
    "href": "lecs/w05/lec05.html#lqr-assumptions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR: assumptions",
    "text": "LQR: assumptions\n\nYou know the dynamics model of the system\nIt is linear: \\(x_{t+1} = Ax_t + Bu_t\\)\n\n \n\n\n\n\n \n\n\n\\[\n\\mathbb{R}^d \\qquad\\qquad\\qquad\\qquad \\mathbb{R}^k\n\\]\n\n\n\n\n\n\n \n\n\n\\[\nA \\in \\mathbb{R}^{d \\times d} \\qquad\\qquad\\qquad\\qquad B \\in \\mathbb{R}^{d \\times k}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#which-systems-are-linear",
    "href": "lecs/w05/lec05.html#which-systems-are-linear",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Which systems are linear?",
    "text": "Which systems are linear?\n\n\n\n\nOmnidirectional robot\n\n\n\\[\n\\begin{align}\nx_{t+1} &= x_t + v_x(t)\\delta t & \\mathbf{x}_{t+1} &= I\\mathbf{x}_t + \\delta t I \\mathbf{u}_t \\\\\ny_{t+1} &= y_t + v_y(t)\\delta t \\qquad \\Rightarrow & A &= I \\\\\n\\theta_{t+1} &= \\theta_t + \\omega_z(t)\\delta t & B &= \\delta t I\n\\end{align}\n\\]\n\n\n\nSimple car\n\n\n\n\n\\[\n\\begin{align}\nx_{t+1} &= x_t + v_x(t)\\cos(\\theta_t)\\delta t \\\\\ny_{t+1} &= y_t + v_x(t)\\sin(\\theta_t)\\delta t \\qquad \\Rightarrow \\\\\n\\theta_{t+1} &= \\theta_t + \\omega_z\\delta t\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#which-systems-are-linear-1",
    "href": "lecs/w05/lec05.html#which-systems-are-linear-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Which systems are linear?",
    "text": "Which systems are linear?\n\n\n\n\nOmnidirectional robot\n\n\\[\n\\begin{align}\nx_{t+1} &= x_t + v_x(t)\\delta t & \\mathbf{x}_{t+1} &= I\\mathbf{x}_t + \\delta t I \\mathbf{u}_t \\\\\ny_{t+1} &= y_t + v_y(t)\\delta t \\qquad \\Rightarrow & A &= I \\\\\n\\theta_{t+1} &= \\theta_t + \\omega_z(t)\\delta t & B &= \\delta t I\n\\end{align}\n\\]\n\nSimple car\n\n\n\\[\n\\begin{align}\nx_{t+1} &= x_t + v_x(t)\\cos(\\theta_t)\\delta t & \\mathbf{x}_{t+1} &= I\\mathbf{x}_t + \\begin{bmatrix} \\delta t\\cos(\\theta_t) & 0 & 0 \\\\ 0 & \\delta t\\sin(\\theta_t) & 0 \\\\ 0 & 0 & \\delta t \\end{bmatrix} \\mathbf{u}_t \\\\\ny_{t+1} &= y_t + v_x(t)\\sin(\\theta_t)\\delta t  \\qquad \\Rightarrow & A &= I \\\\\n\\theta_{t+1} &= \\theta_t + \\omega_z\\delta t & B &= B(\\mathbf{x}_t)\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#the-goal-of-lqr",
    "href": "lecs/w05/lec05.html#the-goal-of-lqr",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The goal of LQR",
    "text": "The goal of LQR\n \n\nStabilize the system around \\(x_t = 0\\) state with control \\(u_t = 0\\)\nThen \\(x_{t+1} = 0\\) and the system will remain at zero forever\n\n\nIf we want to stabilize around x* then let x – x* be the state"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-assumptions-1",
    "href": "lecs/w05/lec05.html#lqr-assumptions-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR: assumptions",
    "text": "LQR: assumptions\n\nYou know the dynamics model of the system\nIt is linear: \\(x_{t+1} = Ax_t + Bu_t\\)\n\n \n\nThere is an instantaneous cost associated with being at state\n\\(x_t\\) and taking the action \\(\\mathbf{u}_t : c(x_t, u_t) = x_t^T Qx_t +u_t^T Ru_t\\)\n\n\n\nQuadratic state cost:\nPenalizes deviation\nfrom the zero vector\n\n\n\nQuadratic control cost:\nPenalizes high control\nsignals"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-assumptions-2",
    "href": "lecs/w05/lec05.html#lqr-assumptions-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR: assumptions",
    "text": "LQR: assumptions\n\nYou know the dynamics model of the system\nIt is linear: \\(x_{t+1} = Ax_t + Bu_t\\)\n\n \n\nThere is an instantaneous cost associated with being at state\n\\(x_t\\) and taking the action \\(\\mathbf{u}_t : c(x_t, u_t) = x_t^T Qx_t +u_t^T Ru_t\\)\n\n\n\nSquare matrices Q and R must be positive definite:\n\\(\\color{black}Q = Q^T \\quad \\text{and} \\quad \\forall x, x^T Qx &gt; 0\\)\n\\(\\color{black}R = R^T \\quad \\text{and} \\quad \\forall u, u^T Ru &gt; 0\\)\ni.e. positive cost for ANY nonzero state and control vector"
  },
  {
    "objectID": "lecs/w05/lec05.html#finite-horizon-lqr",
    "href": "lecs/w05/lec05.html#finite-horizon-lqr",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finite-Horizon LQR",
    "text": "Finite-Horizon LQR\n\nIdea: finding controls is an optimization problem\nCompute the control variables that minimize the cumulative cost\n\n\n\n\\[\n\\begin{align}\nu_0^*, \\ldots, u_{N-1}^* &= \\operatorname*{argmin}_{u_0,\\ldots,u_N} \\quad \\sum_{t=0}^{N} c(\\mathbf{x}_t, \\mathbf{u}_t) \\\\\n\\text{s.t.} \\quad \\mathbf{x}_1 &= A\\mathbf{x}_0 + B\\mathbf{u}_0 \\\\\n\\mathbf{x}_2 &= A\\mathbf{x}_1 + B\\mathbf{u}_1 \\\\\n&\\vdots \\\\\n\\mathbf{x}_N &= A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1}\n\\end{align}\n\\]\n\n\n \nWe could solve this as a constrained\nnonlinear optimization problem. But,\nthere is a better way: we can find a\nclosed-form solution.\n\n\n\nOpen-loop plan!\nGiven first state compute\naction sequence"
  },
  {
    "objectID": "lecs/w05/lec05.html#why-not-use-pid-control",
    "href": "lecs/w05/lec05.html#why-not-use-pid-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why not use PID control?",
    "text": "Why not use PID control?\n\f\n\n\nWe could, but:\n\n\f\n\nThe gains for PID are good for a small region of state-space.\n\nSystem reaches a state outside this set -&gt; becomes unstable\nPID has no formal guarantees on the size of the set\n\n\n\f\n\nWe would need to tune PID gains for every control variable.\n\nIf the state vector has multiple dimensions it becomes harder to tune every control variable in isolation. Need to consider interactions and correlations.\n\n\n\f\n\nWe would need to tune PID gains for different regions of the state-space and guarantee smooth gain transitions\n\nThis is called gain scheduling, and it takes a lot of effort and time"
  },
  {
    "objectID": "lecs/w05/lec05.html#why-not-use-pid",
    "href": "lecs/w05/lec05.html#why-not-use-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why not use PID?",
    "text": "Why not use PID?\n\f\n\n\nWe could, but:\n\n\f\n\nThe gains for PID are good for a small region of state-space.\n\nSystem reaches a state outside this set -&gt; becomes unstable\nPID has no formal guarantees on the size of the set\n\n\n\f\n\nWe would need to tune PID gains for every control variable.\n\nIf the state vector has multiple dimensions it becomes harder to tune every control variable in isolation. Need to consider interactions and correlations.\n\n\n\f\n\nWe would need to tune PID gains for different regions of the state-space and guarantee smooth gain transitions\n\nThis is called gain scheduling, and it takes a lot of effort and time"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\nLet \\(J_n(\\mathbf{x})\\) denote the cumulative cost-to-go starting from state x and moving for n time steps.\nI.e. cumulative future cost from now till n more steps\n\\(J_0(\\mathbf{x}) = \\mathbf{x}^T Q_\\mathbf{x}\\) is the terminal cost of ending up at state x, with no actions left to perform. Recall that \\(c(\\mathbf{x}, \\mathbf{u}) = \\mathbf{x}^T Q\\mathbf{x} + {\\mathbf{u}^T R\\mathbf{u}}\\)\n\n\n\nQ: What is the optimal cumulative cost-to-go function with 1 time step left?"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-1",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\n\n\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T Q \\mathbf{x}\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-2",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\n\n\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T P_0 \\mathbf{x}\n\\end{align}\n\\]\n\n\n \n\n\nFor notational convenience later on"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-3",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\n\n\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T P_0 \\mathbf{x} \\\\\nJ_{1}(\\mathbf{x}) &= \\min_{\\mathbf{u}}\n\\underbrace{\\left[ \\mathbf{x}^T Q \\mathbf{x} + \\mathbf{u}^T R \\mathbf{u} + J_{0}(A\\mathbf{x} + B\\mathbf{u}) \\right]}_{\\color{red}\\text{ In RL this would be the state-action value function}}\n\\end{align}\n\\]\n\n\n \n\n\n\nBellman Update\nDynamic Programming\nValue Iteration"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-4",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T P_0 \\mathbf{x} \\\\\nJ_1(\\mathbf{x}) &= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + J_0(A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + (A\\mathbf{x} + B\\mathbf{u})^T P_0 (A\\mathbf{x} + B\\mathbf{u})]\n\\end{align}\n\\]\n\nQ: How do we optimize a multivariable function with respect to some variables (in our case, the controls)?"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-5",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T P_0 \\mathbf{x} \\\\\nJ_1(\\mathbf{x}) &= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + J_0(A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + (A\\mathbf{x} + B\\mathbf{u})^T P_0 (A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\mathbf{x}^T Q\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + (A\\mathbf{x} + B\\mathbf{u})^T P_0 (A\\mathbf{x} + B\\mathbf{u})]\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-6",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\n\\begin{align}\nJ_0(\\mathbf{x}) &= \\mathbf{x}^T P_0 \\mathbf{x} \\\\\nJ_1(\\mathbf{x}) &= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + J_0(A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\min_{\\mathbf{u}} [\\mathbf{x}^T Q\\mathbf{x} + \\mathbf{u}^T R\\mathbf{u} + (A\\mathbf{x} + B\\mathbf{u})^T P_0 (A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\mathbf{x}^T Q\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + (A\\mathbf{x} + B\\mathbf{u})^T P_0 (A\\mathbf{x} + B\\mathbf{u})] \\\\\n&= \\mathbf{x}^T Q\\mathbf{x} + \\mathbf{x}^T A^T P_0 A\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + 2\\mathbf{u}^T B^T P_0 A\\mathbf{x} + \\mathbf{u}^T B^T P_0 B\\mathbf{u}]\n\\end{align}\n\\]\n\n\n\nA: Take the partial derivative w.r.t. controls and set it to zero. That will give you a critical point."
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-7",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-7",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\nJ_1(\\mathbf{x}) = \\mathbf{x}^T Q\\mathbf{x} + \\mathbf{x}^T A^T P_0 A\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + 2\\mathbf{u}^T B^T P_0 A\\mathbf{x} + \\mathbf{u}^T B^T P_0 B\\mathbf{u}]\n\\]\n\n\n\n\nThe minimum is attained at:\n\\(2R\\mathbf{u} + 2B^T P_0 A\\mathbf{x} + 2B^T P_0 B\\mathbf{u} = 0\\)\n\\((R + B^T P_0 B)\\mathbf{u} = -B^T P_0 A\\mathbf{x}\\)\n\n\nQ: Is this matrix invertible? Recall R, Po are positive definite matrices.\n\nFrom calculus/algebra:\n\\[\n\\frac{\\partial}{\\partial \\mathbf{u}} (\\mathbf{u}^T M\\mathbf{u}) = (M + M^T)\\mathbf{u}\n\\]\n\\[\n\\frac{\\partial}{\\partial \\mathbf{u}} (\\mathbf{u}^T M\\mathbf{b}) = M\\mathbf{b}\n\\]\nIf M is symmetric:\n\\[\n\\frac{\\partial}{\\partial \\mathbf{u}} (\\mathbf{u}^T M\\mathbf{u}) = 2M\\mathbf{u}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-8",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-8",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\nJ_1(\\mathbf{x}) = \\mathbf{x}^T Q\\mathbf{x} + \\mathbf{x}^T A^T P_0 A\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + 2\\mathbf{u}^T B^T P_0 A\\mathbf{x} + \\mathbf{u}^T B^T P_0 B\\mathbf{u}]\n\\]\n\n\n\n\nThe minimum is attained at:\n\\(2R\\mathbf{u} + 2B^T P_0 A\\mathbf{x} + 2B^T P_0 B\\mathbf{u} = 0\\)\n\\((R + B^T P_0 B)\\mathbf{u} = -B^T P_0 A\\mathbf{x}\\)\n\n\nQ: Is this matrix invertible? Recall R, Po are positive definite matrices.\n\\(R + B^TP_0B\\) is positive definite, so it is invertible"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-9",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-9",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\[\nJ_1(\\mathbf{x}) = \\mathbf{x}^T Q\\mathbf{x} + \\mathbf{x}^T A^T P_0 A\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + 2\\mathbf{u}^T B^T P_0 A\\mathbf{x} + \\mathbf{u}^T B^T P_0 B\\mathbf{u}]\n\\]\n\n\n\n\nThe minimum is attained at:\n\\(2R\\mathbf{u} + 2B^T P_0 A\\mathbf{x} + 2B^T P_0 B\\mathbf{u} = 0\\)\n\\((R + B^T P_0 B)\\mathbf{u} = -B^T P_0 A\\mathbf{x}\\)\n\nSo, the optimal control for the last time step is:\n\\(\\mathbf{u} = -(R + B^TP_0B)^{-1} B^TP_0A_x\\)\n\\(\\mathbf{u} = K_1x\\)\nLinear controller in terms of the state"
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-10",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-10",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\\(J_0(\\mathbf{x}) = \\mathbf{x}^T P_0 \\mathbf{x}\\)\n\\[\n\\begin{align}\nJ_1(\\mathbf{x}) &= \\mathbf{x}^T Q\\mathbf{x} + \\mathbf{x}^T A^T P_0 A\\mathbf{x} + \\min_{\\mathbf{u}} [\\mathbf{u}^T R\\mathbf{u} + 2\\mathbf{u}^T B^T P_0 A\\mathbf{x} + \\mathbf{u}^T B^T P_0 B\\mathbf{u}] \\\\\n&= \\mathbf{x}^T \\underbrace{(Q + K_1^T R K_1 + (A + B K_1)^T P_0 (A + B K_1))}_{P_1} \\mathbf{x}\n\\end{align}\n\\]\n\nQ: Why is this a big deal?\nA: The cost-to-go function remains quadratic after the first recursive step."
  },
  {
    "objectID": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-11",
    "href": "lecs/w05/lec05.html#finding-the-lqr-controller-in-closed-form-by-recursion-11",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finding the LQR controller in closed-form by recursion",
    "text": "Finding the LQR controller in closed-form by recursion\n\n\n\n\\(J_0(\\mathbf{x}) = \\mathbf{x}^T P_0 \\mathbf{x}\\)\n\n\\(J_1(\\mathbf{x}) = \\mathbf{x}^T (Q + K_1^T R K_1 + (A + B K_1)^T P_0 (A + B K_1)) \\mathbf{x}\\)\n\\(\\qquad = \\mathbf{x}^T P_1 \\mathbf{x}\\)\n\n…\nJ remains quadratic in x throughout the recursion\n\n\n\\(J_n(\\mathbf{x}) = \\mathbf{x}^T (Q + K_n^T R K_n + (A + B K_n)^T P_{n-1} (A + B K_n)) \\mathbf{x}\\)\n\\(\\qquad = \\mathbf{x}^T P_n \\mathbf{x}\\)\n\n…\n\n\n\n\n\\(\\mathbf{u} = -(R + B^T P_0 B)^{-1} B^T P_0 A\\mathbf{x}\\) \\(\\mathbf{u} = K_1 \\mathbf{x}\\)\n\n\\(\\mathbf{u} = -(R + B^T P_{n-1} B)^{-1} B^T P_{n-1} A\\mathbf{x}\\) \\(\\mathbf{u} = K_n \\mathbf{x}\\)\nu remains linear in x throughout\nthe recursion"
  },
  {
    "objectID": "lecs/w05/lec05.html#finite-horizon-lqr-algorithm-summary",
    "href": "lecs/w05/lec05.html#finite-horizon-lqr-algorithm-summary",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finite-Horizon LQR: algorithm summary",
    "text": "Finite-Horizon LQR: algorithm summary\n\n\\(P_0 = Q\\)\n// n is the # of steps left\nfor n = 1…N\n\\(K_n = -(R + B^T P_{n-1} B)^{-1} B^T P_{n-1} A\\)\n\\(P_n = Q + K_n^T R K_n + (A + B K_n)^T P_{n-1} (A + B K_n)\\)\nOptimal control for time t = N – n is \\(u_t = K_t x_t\\) with cost-to-go \\(J_t(x) = x^T P_tx\\)\nwhere the states are predicted forward in time according to linear dynamics"
  },
  {
    "objectID": "lecs/w05/lec05.html#finite-horizon-lqr-algorithm-summary-1",
    "href": "lecs/w05/lec05.html#finite-horizon-lqr-algorithm-summary-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Finite-Horizon LQR: algorithm summary",
    "text": "Finite-Horizon LQR: algorithm summary\n\n\n\\(P_0 = Q\\)\n// n is the # of steps left\nfor n = 1…N\n\\(K_n = -(R + B^T P_{n-1} B)^{-1} B^T P_{n-1} A\\)\n\\(P_n = Q + K_n^T R K_n + (A + B K_n)^T P_{n-1} (A + B K_n)\\)\nOptimal control for time t = N – n is \\(u_t = K_t x_t\\) with cost-to-go \\(J_t(x) = x^T P_tx\\)\nwhere the states are predicted forward in time according to linear dynamics\n\n\nPotential problem for states of dimension &gt;&gt; 100:\nMatrix inversion is expensive: O(k^2.3) for the best\nknown algorithm and O(k^3) for Gaussian Elimination"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-summary",
    "href": "lecs/w05/lec05.html#lqr-summary",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR summary",
    "text": "LQR summary\n\nAdvantages:\n\nIf system is linear LQR gives the optimal controller that takes the system’s state to 0 (or the desired target state, same thing)\n\nDrawbacks:\n\n\nLinear dynamics\nHow can you include obstacles or constraints in the specification?\nNot easy to put bounds on control values"
  },
  {
    "objectID": "lecs/w05/lec05.html#what-happens-in-the-general-nonlinear-case",
    "href": "lecs/w05/lec05.html#what-happens-in-the-general-nonlinear-case",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What happens in the general nonlinear case?",
    "text": "What happens in the general nonlinear case?\n\\[\n\\begin{align}\nu_0^*, \\ldots, u_{N-1}^* &= \\operatorname*{argmin}_{u_0, \\ldots, u_N} \\sum_{t=0}^{N} c(\\mathbf{x}_t, \\mathbf{u}_t) \\\\\n\\text{s.t.} \\quad \\mathbf{x}_1 &= f(\\mathbf{x}_0, \\mathbf{u}_0) \\\\\n\\mathbf{x}_2 &= f(\\mathbf{x}_1, \\mathbf{u}_1) \\\\\n&\\vdots \\\\\n\\mathbf{x}_N &= f(\\mathbf{x}_{N-1}, \\mathbf{u}_{N-1})\n\\end{align}\n\\]\nArbitrary differentiable functions c, f\n\nIdea: iteratively approximate solution by solving linearized versions of the problem via LQR"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-extensions-time-varying-systems",
    "href": "lecs/w05/lec05.html#lqr-extensions-time-varying-systems",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR extensions: time-varying systems",
    "text": "LQR extensions: time-varying systems\n\nWhat can we do when \\(x_{t+1} = A_t x_t + B_t \\mathbf{u}_t\\) and \\(c(x_t, \\mathbf{u}_t) = x_t^T Q x_t + \\mathbf{u}_t^T R\\mathbf{u}_t\\)?\nTurns out, the proof and the algorithm are almost the same\n\n\\(P_0 = Q_N\\)\n// n is the # of steps left\nfor n = 1…N\n\\(K_n = -\\big( R_{N-n} + B_{N-n}^T P_{n-1} B_{N-n} \\big)^{-1} B_{N-n}^T P_{n-1} A_{N-n}\\)\n\\(P_n = Q_{N-n} + K_n^T R_{N-n} K_n + (A_{N-n} + B_{N-n} K_n)^T P_{n-1} (A_{N-n} + B_{N-n} K_n)\\)\nOptimal controller for n-step horizon is \\(u_n = K_n x_n\\) with cost-to-go \\(J_n(x) = x^T P_n x\\)"
  },
  {
    "objectID": "lecs/w05/lec05.html#examples-of-models-and-solutions-with-lqr",
    "href": "lecs/w05/lec05.html#examples-of-models-and-solutions-with-lqr",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of models and solutions with LQR",
    "text": "Examples of models and solutions with LQR"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\nSimilar to double integrator dynamical system, but with friction:\n\n\\[\nm \\mathbf{\\ddot p} = \\mathbf{u} - \\alpha \\mathbf{\\dot p}\n\\]\n\n\n\nSet \\(\\dot p = v\\) and then you get:\n\\[\nm \\mathbf{\\dot v} = \\mathbf{u} -\\alpha \\mathbf{v}\n\\]\n\n\n\n\nWe discretize by setting\n\n\n\n\n\\[\n\\frac{\\mathbf{p}_{t+1} - \\mathbf{p}_t}{\\delta t} \\simeq \\mathbf{v}_t\n\\]\n\n\n\\[\nm \\frac{\\mathbf{v}_{t+1} - \\mathbf{v}_t}{\\delta t} \\simeq \\mathbf{u}_t - \\alpha \\mathbf{v}_t\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-1",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\n\n\n\\[\n\\frac{\\mathbf{p}_{t+1} - \\mathbf{p}_t}{\\delta t} \\simeq \\mathbf{v}_t\n\\]\n\n\n\\[\nm \\frac{\\mathbf{v}_{t+1} - \\mathbf{v}_t}{\\delta t} \\simeq \\mathbf{u}_t - \\alpha \\mathbf{v}_t\n\\]\n\n\n\n\nDefine the state vector \\(\\mathbf{x}_t = \\begin{bmatrix} \\mathbf{p}_t \\\\ \\mathbf{v}_t \\end{bmatrix}\\)\n\nQ: How can we express this as a linear system?\n\n\\[\n\\mathbf{x}_{t+1} = \\begin{bmatrix} \\mathbf{p}_{t+1} \\\\ \\mathbf{v}_{t+1} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{p}_t + \\delta t \\mathbf{v}_t \\\\ \\mathbf{v}_t + \\frac{\\delta t}{m} \\mathbf{u}_t - \\frac{\\alpha \\delta t}{m} \\mathbf{v}_t \\end{bmatrix} = \\begin{bmatrix} \\mathbf{p}_t + \\delta t \\mathbf{v}_t \\\\ \\mathbf{v}_t - \\frac{\\alpha \\delta t}{m} \\mathbf{v}_t \\end{bmatrix} + \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\frac{\\delta t}{m} & 0 \\\\ 0 & \\frac{\\delta t}{m} \\end{bmatrix} \\mathbf{u}_t\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-2",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\n\n\n\\[\n\\frac{\\mathbf{p}_{t+1} - \\mathbf{p}_t}{\\delta t} \\simeq \\mathbf{v}_t\n\\]\n\n\n\\[\nm \\frac{\\mathbf{v}_{t+1} - \\mathbf{v}_t}{\\delta t} \\simeq \\mathbf{u}_t - \\alpha \\mathbf{v}_t\n\\]\n\n\n\n\nDefine the state vector \\(\\mathbf{x}_t = \\begin{bmatrix} \\mathbf{p}_t \\\\ \\mathbf{v}_t \\end{bmatrix}\\)\n\n\n\\[\n\\mathbf{x}_{t+1} = \\begin{bmatrix} \\mathbf{p}_{t+1} \\\\ \\mathbf{v}_{t+1} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{p}_t + \\delta t \\mathbf{v}_t \\\\ \\mathbf{v}_t + \\frac{\\delta t}{m} \\mathbf{u}_t - \\frac{\\alpha \\delta t}{m} \\mathbf{v}_t \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & \\delta t & 0 \\\\ 0 & 1 & 0 & \\delta t \\\\ 0 & 0 & 1 - \\alpha \\delta t/m & 0 \\\\ 0 & 0 & 0 & 1 - \\alpha \\delta t/m \\end{bmatrix} \\mathbf{x}_t + \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\frac{\\delta t}{m} & 0 \\\\ 0 & \\frac{\\delta t}{m} \\end{bmatrix} \\mathbf{u}_t\n\\]\n\n\nA\nB"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-3",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\nDefine the state vector \\(\\mathbf{x}_t = \\begin{bmatrix} \\mathbf{p}_t \\\\ \\mathbf{v}_t \\end{bmatrix}\\)\n\n\n\\[\n\\mathbf{x}_{t+1} = \\begin{bmatrix} \\mathbf{p}_{t+1} \\\\ \\mathbf{v}_{t+1} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{p}_t + \\delta t \\mathbf{v}_t \\\\ \\mathbf{v}_t + \\frac{\\delta t}{m} \\mathbf{u}_t - \\frac{\\alpha \\delta t}{m} \\mathbf{v}_t \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & \\delta t & 0 \\\\ 0 & 1 & 0 & \\delta t \\\\ 0 & 0 & 1 - \\alpha \\delta t/m & 0 \\\\ 0 & 0 & 0 & 1 - \\alpha \\delta t/m \\end{bmatrix} \\mathbf{x}_t + \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\frac{\\delta t}{m} & 0 \\\\ 0 & \\frac{\\delta t}{m} \\end{bmatrix} \\mathbf{u}_t\n\\]\n\nA\nB\n\n\n\n\nDefine the instantaneous cost function\n\n\n\n\\[\n\\begin{align}\nc(\\mathbf{x}, \\mathbf{u}) &= \\mathbf{x}^T Q \\mathbf{x} + \\mathbf{u}^T R \\mathbf{u} \\\\\n&= \\mathbf{x}^T \\mathbf{x} + \\rho\\, \\mathbf{u}^T \\mathbf{u} \\\\\n&= \\|\\mathbf{x}\\|^2 + \\rho \\|\\mathbf{u}\\|^2\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-4",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\n\nWith initial state\n\\[\n\\mathbf{x}_0 =\n\\begin{bmatrix}\n10 \\\\\n30 \\\\\n10 \\\\\n-5\n\\end{bmatrix}\n\\]\nInstantaneous cost function\n\\(c(x, \\mathbf{u}) = ||x||^2 + 100||\\mathbf{u}||^2\\)"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-5",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\n\nWith initial state\n\\[\n\\mathbf{x}_0 =\n\\begin{bmatrix}\n10 \\\\\n30 \\\\\n10 \\\\\n-5\n\\end{bmatrix}\n\\]\nInstantaneous cost function\n\\(c(x, \\mathbf{u}) = ||x||^2 + 100||\\mathbf{u}||^2\\)\n\n\n\n\nNotice how the controls tend to zero. It’s because\nthe state tends to zero as well.\n\n\nAlso note that in the current LQR framework,\nwe have not included hard constraints on the controls,\ni.e. upper or lower bounds. We only penalize large\nnorm for controls."
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-6",
    "href": "lecs/w05/lec05.html#lqr-example-1-omnidirectional-vehicle-with-friction-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #1: omnidirectional vehicle with friction",
    "text": "LQR example #1: omnidirectional vehicle with friction\n\n\nWith initial state\n\\[\n\\mathbf{x}_0 =\n\\begin{bmatrix}\n10 \\\\\n30 \\\\\n10 \\\\\n-5\n\\end{bmatrix}\n\\]\nInstantaneous cost function\n\\(c(x, \\mathbf{u}) = ||x||^2 + 100||\\mathbf{u}||^2\\)\n\n\n\nNotice how the state tends to zero."
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle",
    "href": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #2: trajectory following for omnidirectional vehicle",
    "text": "LQR example #2: trajectory following for omnidirectional vehicle"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-1",
    "href": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #2: trajectory following for omnidirectional vehicle",
    "text": "LQR example #2: trajectory following for omnidirectional vehicle\nA\nB\n\\[\n\\mathbf{x}_{t+1} = \\begin{bmatrix} \\mathbf{p}_{t+1} \\\\ \\mathbf{v}_{t+1} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & \\delta t & 0 \\\\ 0 & 1 & 0 & \\delta t \\\\ 0 & 0 & 1 - \\alpha \\delta t/m & 0 \\\\ 0 & 0 & 0 & 1 - \\alpha \\delta t/m \\end{bmatrix} \\mathbf{x}_t + \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\frac{\\delta t}{m} & 0 \\\\ 0 & \\frac{\\delta t}{m} \\end{bmatrix} \\mathbf{u}_t\n\\]\nWe are given a desired trajectory: \\(\\mathbf{p}_0^*, \\mathbf{p}_1^*, \\dots, \\mathbf{p}_T^*\\)\nInstantaneous cost: \\(c(x_t, \\mathbf{u}_t) = (\\mathbf{p}_t - \\mathbf{p}_t^*)^T Q (\\mathbf{p}_t - \\mathbf{p}_t^*) + \\mathbf{u}_t^T R \\mathbf{u}_t\\)"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-2",
    "href": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #2: trajectory following for omnidirectional vehicle",
    "text": "LQR example #2: trajectory following for omnidirectional vehicle\nA\nB\n\n\\[\n\\mathbf{x}_{t+1} = \\begin{bmatrix} \\mathbf{p}_{t+1} \\\\ \\mathbf{v}_{t+1} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & \\delta t & 0 \\\\ 0 & 1 & 0 & \\delta t \\\\ 0 & 0 & 1 - \\alpha \\delta t/m & 0 \\\\ 0 & 0 & 0 & 1 - \\alpha \\delta t/m \\end{bmatrix} \\mathbf{x}_t + \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\frac{\\delta t}{m} & 0 \\\\ 0 & \\frac{\\delta t}{m} \\end{bmatrix} \\mathbf{u}_t\n\\]\n\n\nDefine\n\\[\n\\begin{align}\n\\bar{\\mathbf{x}}_{t+1} &= \\mathbf{x}_{t+1} - \\mathbf{x}^{*}_{t+1} \\\\\n&= A \\mathbf{x}_t + B \\mathbf{u}_t - \\mathbf{x}^{*}_{t+1} \\\\\n&= A \\bar{\\mathbf{x}}_t + B \\mathbf{u}_t - \\mathbf{x}^{*}_{t+1} - A \\mathbf{x}^{*}_t\n\\end{align}\n\\]\n\nWe want \\(\\bar{\\mathbf{x}}_{t+1} = \\bar{A} \\bar{\\mathbf{x}}_t + \\bar{B} \\mathbf{u}_t\\)\n\n\n\nC\nRedefine state:\n\\[\nz_{t+1} =\n\\begin{bmatrix}\n\\bar{\\mathbf{x}}_{t+1} \\\\\n1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nA & c \\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n\\bar{\\mathbf{x}}_t \\\\\n1\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nB \\\\\n0\n\\end{bmatrix} \\mathbf{u}_t\n=\n\\bar{A} z_t + \\bar{B} \\mathbf{u}_t\n\\]\n\n\nRedefine cost function: \\(c(z_t, \\mathbf{u}_t) = z_t^{T} \\, \\bar{Q} \\, z_t + \\mathbf{u}_t^{T} R \\, \\mathbf{u}_t\\)\nIdea: augment the state"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-3",
    "href": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #2: trajectory following for omnidirectional vehicle",
    "text": "LQR example #2: trajectory following for omnidirectional vehicle\n\n\nWith initial state\n\\[\n\\mathbf{z}_0 =\n\\begin{bmatrix}\n10 \\\\\n30 \\\\\n0 \\\\\n0 \\\\\n1\n\\end{bmatrix}\n\\]\nInstantaneous cost function\n\\(c(\\mathbf{z}, \\mathbf{u}) = ||\\mathbf{z}||^2 + ||\\mathbf{u}||^2\\)"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-4",
    "href": "lecs/w05/lec05.html#lqr-example-2-trajectory-following-for-omnidirectional-vehicle-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR example #2: trajectory following for omnidirectional vehicle",
    "text": "LQR example #2: trajectory following for omnidirectional vehicle\n\n\nWith initial state\n\\[\n\\mathbf{z}_0 =\n\\begin{bmatrix}\n10 \\\\\n30 \\\\\n0 \\\\\n0 \\\\\n1\n\\end{bmatrix}\n\\]\nInstantaneous cost function\n\\(c(\\mathbf{z}, \\mathbf{u}) = ||\\mathbf{z}||^2 + ||\\mathbf{u}||^2\\)"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-extensions-trajectory-following",
    "href": "lecs/w05/lec05.html#lqr-extensions-trajectory-following",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR extensions: trajectory following",
    "text": "LQR extensions: trajectory following\n\nYou are given a reference trajectory (not just path, but states and times, or states and controls) that needs to be approximated\n\n\\[\n\\mathbf{x}_0^*, \\mathbf{x}_1^*, \\ldots, \\mathbf{x}_N^*\n\\qquad\\qquad\n\\mathbf{u}_0^*, \\mathbf{u}_1^*, \\ldots, \\mathbf{u}_N^*\n\\]\nLinearize the nonlinear dynamics \\(\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\\) around the reference point \\((\\mathbf{x}_t^*, \\mathbf{u}_t^*)\\)\n\\[\n\\mathbf{x}_{t+1} \\simeq f(\\mathbf{x}_t^*, \\mathbf{u}_t^*)\n+ \\frac{\\partial f}{\\partial \\mathbf{x}}(\\mathbf{x}_t^*, \\mathbf{u}_t^*)(\\mathbf{x}_t - \\mathbf{x}_t^*)\n+ \\frac{\\partial f}{\\partial \\mathbf{u}}(\\mathbf{x}_t^*, \\mathbf{u}_t^*)(\\mathbf{u}_t - \\mathbf{u}_t^*)\n\\]\n\n\n\n\\[\n\\begin{align}\n& \\bar{\\mathbf{x}}_{t+1} \\simeq A_t \\bar{\\mathbf{x}}_t + B_t \\bar{\\mathbf{u}}_t \\\\\n& c(\\mathbf{x}_t, \\mathbf{u}_t) = \\bar{\\mathbf{x}}_t^T Q \\bar{\\mathbf{x}}_t + \\bar{\\mathbf{u}}_t^T R \\bar{\\mathbf{u}}_t\n\\end{align}\n\\]\n\n\nwhere\n\n\n\\[\n\\begin{align}\n& \\bar{\\mathbf{x}}_t = \\mathbf{x}_t - \\mathbf{x}_t^* \\\\\n& \\bar{\\mathbf{u}}_t = \\mathbf{u}_t - \\mathbf{u}_t^*\n\\end{align}\n\\]\n\n\nTrajectory following can be implemented as a time-varying LQR approximation. Not always clear if this is the best way though."
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-with-nonlinear-dynamics-quadratic-cost",
    "href": "lecs/w05/lec05.html#lqr-with-nonlinear-dynamics-quadratic-cost",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR with nonlinear dynamics, quadratic cost",
    "text": "LQR with nonlinear dynamics, quadratic cost"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-variants-nonlinear-dynamics-quadratic-cost",
    "href": "lecs/w05/lec05.html#lqr-variants-nonlinear-dynamics-quadratic-cost",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR variants: nonlinear dynamics, quadratic cost",
    "text": "LQR variants: nonlinear dynamics, quadratic cost\nWhat can we do when \\(\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\\) but the cost is quadratic \\(c(\\mathbf{x}_t, \\mathbf{u}_t) = \\mathbf{x}_t^T Q\\mathbf{x}_t + \\mathbf{u}_t^T R \\mathbf{u}_t\\) ?\nWe want to stabilize the system around state \\(\\mathbf{x}_t = 0\\)\nBut with nonlinear dynamics we do not know if \\(\\mathbf{u}_t = 0\\) will keep the system at the zero state.\n\n-&gt; Need to compute \\(\\mathbf{u}^*\\) such that \\(\\mathbf{0}_{t+1} = f(\\mathbf{0}_t, \\mathbf{u}*)\\)\n\n\nTaylor expansion: linearize the nonlinear dynamics around the point \\((0, \\mathbf{u}^*)\\)\n\\[\n\\mathbf{x}_{t+1} \\simeq f(0, \\mathbf{u}^*) +\n\\underbrace{\\frac{\\partial f}{\\partial \\mathbf{x}}(0, \\mathbf{u}^*)}_{\\mathbf{A}}(\\mathbf{x}_t - 0) + \\underbrace{\\frac{\\partial f}{\\partial \\mathbf{u}}(0, \\mathbf{u}^*)}_{\\mathbf{B}}(\\mathbf{u}_t - \\mathbf{u}^*)\n\\]"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-variants-nonlinear-dynamics-quadratic-cost-1",
    "href": "lecs/w05/lec05.html#lqr-variants-nonlinear-dynamics-quadratic-cost-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR variants: nonlinear dynamics, quadratic cost",
    "text": "LQR variants: nonlinear dynamics, quadratic cost\nWhat can we do when \\(\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\\) but the cost is quadratic \\(c(\\mathbf{x}_t, \\mathbf{u}_t) = \\mathbf{x}_t^T Q\\mathbf{x}_t + \\mathbf{u}_t^T R \\mathbf{u}_t\\) ?\nWe want to stabilize the system around state \\(\\mathbf{x}_t = 0\\)\nBut with nonlinear dynamics we do not know if \\(\\mathbf{u}_t = 0\\) will keep the system at the zero state.\n-&gt; Need to compute \\(\\mathbf{u}^*\\) such that \\(\\mathbf{0}_{t+1} = f(\\mathbf{0}_t, \\mathbf{u}*)\\)\nTaylor expansion: linearize the nonlinear dynamics around the point \\((0, \\mathbf{u}^*)\\)\n\\[\n\\begin{align}\n& \\mathbf{x}_{t+1} \\simeq f(0, \\mathbf{u}^*) + \\frac{\\partial f}{\\partial \\mathbf{x}}(0, \\mathbf{u}^*)(\\mathbf{x}_t - 0) + \\frac{\\partial f}{\\partial \\mathbf{u}}(0, \\mathbf{u}^*)(\\mathbf{u}_t - \\mathbf{u}^*) \\\\\n& \\mathbf{x}_{t+1} \\simeq Ax_t + B(\\mathbf{u}_t - \\mathbf{u}^*)\n\\end{align}\n\\]\n\\(\\qquad\\qquad\\qquad\\) Solve this via LQR"
  },
  {
    "objectID": "lecs/w05/lec05.html#lqr-examples-code-to-replicate-these-results",
    "href": "lecs/w05/lec05.html#lqr-examples-code-to-replicate-these-results",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "LQR examples: code to replicate these results",
    "text": "LQR examples: code to replicate these results\n\nhttps://github.com/florianshkurti/csc477_fall19.git\nLook under csc477_fall19/lqr_examples/python"
  },
  {
    "objectID": "lecs/w10/lec10.html#recommended-reading",
    "href": "lecs/w10/lec10.html#recommended-reading",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nLesson 3 in https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\nChapters 4.3 and 8.3 in the Probabilistic Robotics textbook"
  },
  {
    "objectID": "lecs/w10/lec10.html#kf-vs-ekf-vs-pf",
    "href": "lecs/w10/lec10.html#kf-vs-ekf-vs-pf",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "KF vs EKF vs PF",
    "text": "KF vs EKF vs PF\n\n\n\n\n\n\n\n\n\n\nKalman Filter\nExtended Kalman Filter\nParticle Filter\n\n\n\n\nDynamics model\nLinear\nNonlinear\nNonlinear\n\n\nSensor model\nLinear\nNonlinear\nNonlinear\n\n\nNoise\nGaussian (Unimodal)\nGaussian (Unimodal)\nMultimodal"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions",
    "href": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How can we represent multimodal distributions?",
    "text": "How can we represent multimodal distributions?\n\n\n\n\n\n\nhttps://www.opsclarity.com\n\n\n\nIdea #1: Histograms\nAdvantages: the higher the number of bars the better the approximation is\nDisadvantages: exponential dependence on number of dimensions\nNote: this approach is called the Histogram Filter. It is useful for low-dimensional systems but we will not study it in this class.\n\n\n\nIdea #2: Function Approximation"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-1",
    "href": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How can we represent multimodal distributions?",
    "text": "How can we represent multimodal distributions?\n\n\n\n\n\nhttps://www.opsclarity.com\n\n\n\nIdea #1: Histograms\nAdvantages: the higher the number of bars the better the approximation is\nDisadvantages: exponential dependence on number of dimensions\nNote: this approach is called the Histogram Filter. It is useful for low-dimensional systems but we will not study it in this class.\n\nIdea #2: Function Approximation\n\nIdea #3: Weighted Particles \\(\\{(x^{[1]},w^{[1]}),...,(x^{[M]},w^{[M]})\\}\\)\nAdvantages: easy to predict/update by treating each particle as a separate hypothesis whose weight is updated.\nDisadvantages: need enough particles to “cover” the distribution"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-2",
    "href": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How can we represent multimodal distributions?",
    "text": "How can we represent multimodal distributions?\n\n\n\n\n\nhttps://www.opsclarity.com\n\n\n\n\\[\\begin{align}\nbel(x_t) &= p(x_t|z_{0:t}, u_{0:t-1}) \\\\\n&= \\sum_{m=1}^{M} \\begin{cases} w^{[m]}/W & \\text{if } x_t=x_t^{[m]} \\\\ 0 & \\text{o.w.} \\end{cases}\n\\end{align}\\]\n\nIdea #1: Histograms\nAdvantages: the higher the number of bars the better the approximation is\nDisadvantages: exponential dependence on number of dimensions\nNote: this approach is called the Histogram Filter. It is useful for low-dimensional systems but we will not study it in this class.\n\nIdea #2: Function Approximation\n\nIdea #3: Weighted Particles \\(\\{(x^{[1]},w^{[1]}),...,(x^{[M]},w^{[M]})\\}\\)\nAdvantages: easy to predict/update by treating each particle as a separate hypothesis whose weight is updated.\nDisadvantages: need enough particles to “cover” the distribution\n\n\nHigher density of\nparticles means\nhigher probability\nmass"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-3",
    "href": "lecs/w10/lec10.html#how-can-we-represent-multimodal-distributions-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How can we represent multimodal distributions?",
    "text": "How can we represent multimodal distributions?\n\n\n\n\n\nhttps://www.opsclarity.com\n\n\n\nWant particles to be drawn from the belief at time t:\n\\[x_{t}^{[m]}\\sim p(x_{t}|z_{0:t},u_{0:t-1})\\]\n\nIdea #1: Histograms\nAdvantages: the higher the number of bars the better the approximation is\nDisadvantages: exponential dependence on number of dimensions\nNote: this approach is called the Histogram Filter. It is useful for low-dimensional systems but we will not study it in this class.\n\nIdea #2: Function Approximation\n\nIdea #3: Weighted Particles \\(\\{(x^{[1]},w^{[1]}),...,(x^{[M]},w^{[M]})\\}\\)\nAdvantages: easy to predict/update by treating each particle as a separate hypothesis whose weight is updated.\nDisadvantages: need enough particles to “cover” the distribution\n\n\nHigher density of\nparticles means\nhigher probability\nmass"
  },
  {
    "objectID": "lecs/w10/lec10.html#particle-propagationprediction",
    "href": "lecs/w10/lec10.html#particle-propagationprediction",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Particle propagation/prediction",
    "text": "Particle propagation/prediction\n\n\n\n\nSimulate what is going to happen to the particle at the next time step by drawing a sample from the next state specified in the dynamics (a.k.a. one-step simulator)\n\\[x_t^{[m]} \\sim p(x_t | x_{t-1}^{[m]}, u_{t-1})\\]\nUsually\n\\[\\begin{aligned}\nx_{t}^{[m]}=f(x_{t-1}^{[m]},u_{t-1})+w_{t-1}\\\\\nw_{t-1}\\sim\\mathcal{N}(0,Q)\n\\end{aligned}\\]"
  },
  {
    "objectID": "lecs/w10/lec10.html#particle-update",
    "href": "lecs/w10/lec10.html#particle-update",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Particle Update",
    "text": "Particle Update"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nMeasurement model \\(z_t = h(x_t) + n_t = [r_1, r_2, r_3, r_4] + n_t\\)\nwith \\(r_i = \\sqrt{(p_x - l_x^{(i)})^2 + (p_y - l_y^{(i)})^2}\\) and \\(n_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\\[\\left. \\rule{0pt}{1cm} \\right\\} p(z_t|x_t) = \\mathcal{N}(z_t; r_{1:4}, \\sigma^2 \\mathbb{I}_4)\\]"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-1",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nActual measurement received: \\({\\bar{z}_t = [\\bar{r}_1, \\bar{r}_2, \\bar{r}_3, \\bar{r}_4]}\\)"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-2",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nMeasurement model \\(z_{t}=h(x_{t}^{[m]})+n_{t}=[d_{1},d_{2},d_{3},d_{4}]+n_{t}\\)\nwith \\(d_{i}=\\sqrt{(p_{x}^{[m]}-l_{x}^{(i)})^{2}+(p_{y}^{[m]}-l_{y}^{(i)})^{2}}\\) and \\(n_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\\[\\left. \\rule{0pt}{1cm} \\right\\} p(z_t|x_t^{[m]}) = \\mathcal{N}(z_t; d_{1:4}, \\sigma^2 \\mathbb{I}_4)\\]"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-3",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nQ: What is the probability of the actual measurement given the state hypothesized by the particle?\nA: \\(p(\\bar{z}_t | x_t^{[m]}) = \\mathcal{N}(\\bar{z}_t; d_{1:4}, \\sigma^2 \\mathbb{I}_4) = \\eta \\exp(-\\|\\bar{z}_t - d_{1:4}\\|^2 / \\sigma^2)\\)"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-4",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nQ: What is the probability of the actual measurement given the state hypothesized by the particle?\nA: \\(p(\\bar{z}_{t}|x_{t}^{[m]}) = \\prod_{i=1}^{4} p(\\bar{r}_{i}|x_{t}^{[m]}) = \\prod_{i=1}^{4} \\mathcal{N}(\\bar{r}_{i}; d_{i}, \\sigma^{2}) = \\prod_{i=1}^{4} \\eta \\exp(-(\\bar{r}_{i}-d_{i})/\\sigma^{2})\\)\n\n\nAssuming range measurements\nare conditionally independent\ngiven state"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-5",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nQ: What is the probability of the actual measurement given the state hypothesized by the particle?\nA: \\(p(\\bar{z}_{t}|x_{t}^{[m]}) = \\prod_{i=1}^{4} p(\\bar{r}_{i}|x_{t}^{[m]}) = \\prod_{i=1}^{4} \\mathcal{N}(\\bar{r}_{i}; d_{i}, \\sigma^{2})\\)\n\n\nIn the figure above this probability would be low\nand this particle would be unlikely."
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-6",
    "href": "lecs/w10/lec10.html#how-to-update-particle-weights-after-an-observation-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to update particle weights after an observation",
    "text": "How to update particle weights after an observation\n\n\n\n\n\n\nParticle’s (unnormalized) weight \\(\\quad w_t^{[m]} \\propto p(\\bar{z}_t | x_t^{[m]})\\)\n\n\nSee Appendix 1 for why\nthis choice was made\nfor the weight"
  },
  {
    "objectID": "lecs/w10/lec10.html#the-distribution-of-the-particles-has-not-been-updated-yet.-we-only-updated-their-weights.-to-update-the-distribution-of-particles-we-need-to-do-resampling",
    "href": "lecs/w10/lec10.html#the-distribution-of-the-particles-has-not-been-updated-yet.-we-only-updated-their-weights.-to-update-the-distribution-of-particles-we-need-to-do-resampling",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The distribution of the particles has not been updated yet. We only updated their weights. To update the distribution of particles we need to do resampling",
    "text": "The distribution of the particles has not been updated yet. We only updated their weights. To update the distribution of particles we need to do resampling\n\n\n Sample particles with repetition/replacement,\naccording to their updated weights."
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles",
    "href": "lecs/w10/lec10.html#resampling-particles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles",
    "text": "Resampling Particles\n\nMain goal : Get rid of unlikely particles (with too low weights) and focus on most likely particles (a.k.a. survival of the fittest).\nMain mechanism : Sample new set of particles from existing set, with replacement(repetition), so that same particle can be sampled more than once. Sample old particle i with probability \\(\\propto \\text{weight}_i\\)\nMany possible ways to implement it. Here we present two algorithms."
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles-algorithm-1",
    "href": "lecs/w10/lec10.html#resampling-particles-algorithm-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles: Algorithm #1",
    "text": "Resampling Particles: Algorithm #1\n\n\nnew_particles = []\nsample u ~ Uniform[0,1]\nidx = int( u * (N-1) )\nbeta = 0\nmax_w = max(weights)\n\nfor each of the N particles:\n\\(\\qquad\\) sample v ~ Uniform[0,1]\n\\(\\qquad\\) beta += v * 2* max_w\n\n\\(\\qquad\\) while beta &gt; weights[idx]:\n\\(\\qquad\\qquad\\) beta -= weights[idx]\n\\(\\qquad\\qquad\\) idx = (idx + 1) % N\n\n\\(\\qquad\\) p = particles[idx].copy() \\(\\qquad\\) new_particles.append(p)"
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles-algorithm-2",
    "href": "lecs/w10/lec10.html#resampling-particles-algorithm-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles: Algorithm #2",
    "text": "Resampling Particles: Algorithm #2\n\n\nnew_particles = []\nsample r ~ Uniform[0, 1/N]\nc = weights[0]\nidx = 0\n\nfor n = 1…N:\n\\(\\qquad\\) u = r + (n-1)/N\n\n\\(\\qquad\\) while u &gt; c:\n\\(\\qquad\\qquad\\) idx = idx + 1\n\\(\\qquad\\qquad\\) c = c + weights[idx]\n\n\\(\\qquad\\) p = particles[idx].copy()\n\\(\\qquad\\) new_particles.append(p)\n\n\n\nStochastic universal sampling\nSystematic resampling\nLinear time complexity"
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles-example",
    "href": "lecs/w10/lec10.html#resampling-particles-example",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles: Example",
    "text": "Resampling Particles: Example\n• Suppose we only have 5 particles:\n\n\n\n\n\nParticle index\nNormalized weight\n\n\n\n\n1\n0.1\n\n\n2\n0.2\n\n\n3\n0.4\n\n\n4\n0.1\n\n\n5\n0.2\n\n\n\n\nQ: What is the probability that after a round of resampling the highest probability particle (#3) is not sampled?\nA: \\(0.6^5 \\simeq 0.077\\)\n\ni.e. there is nonzero probability that we will lose the highest-probability particle \\(\\rightarrow\\) it will happen eventually"
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles-example-1",
    "href": "lecs/w10/lec10.html#resampling-particles-example-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles: Example",
    "text": "Resampling Particles: Example\n• Suppose we only have 5 particles:\n\n\n\n\n\nParticle index\nNormalized weight\n\n\n\n\n1\n0.1\n\n\n2\n0.2\n\n\n3\n0.4\n\n\n4\n0.1\n\n\n5\n0.2\n\n\n\n\nQ: What is the probability that after a round of resampling the highest probability particle (#3) is not sampled?\nA: \\(0.6^5 \\simeq 0.077\\)\n\nQ: What is the probability that after a round of resampling one of the lowest-probability particles (#1) is not sampled?\nA: \\(0.9^5 \\simeq 0.59\\)"
  },
  {
    "objectID": "lecs/w10/lec10.html#resampling-particles-consequences",
    "href": "lecs/w10/lec10.html#resampling-particles-consequences",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Resampling Particles: Consequences",
    "text": "Resampling Particles: Consequences\n\nWeak particles very likely do not survive.\n\n\n\\(\\mathbf{\\Downarrow}\\)\n\n\nVariance among the set of particles decreases , due to mostly sampling strong particles (i.e. loss of particle diversity).\n\n\n\\(\\mathbf{\\Downarrow}\\)\n\n\nLoss of particle diversity implies increased variance of the approximation error between the particles and the true distribution .\n\n\n\\(\\mathbf{\\Downarrow}\\)\n\n\nParticle deprivation: there are no particles in the vicinity of the correct state"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-address-particle-deprivation",
    "href": "lecs/w10/lec10.html#how-to-address-particle-deprivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to address particle deprivation",
    "text": "How to address particle deprivation\n\nIdea #1: don’t resample when only a few particles contribute\nIdea #2: inject random particles during resampling\nIdea #3: increase the number of particles (may be impractical depending on the computational complexity of the system)"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-address-particle-deprivation-1",
    "href": "lecs/w10/lec10.html#how-to-address-particle-deprivation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to address particle deprivation",
    "text": "How to address particle deprivation\n\nIdea #1: don’t resample when only a few particles contribute\n\nEffective sample size: \\(N_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^{N}w_{i}^{2}}\\)\nWhen all particles have equal, normalized weights (1/N) then \\(N_{\\text{eff}} = N\\)\nWhen a single particle carries the entire weight then \\(N_{\\text{eff}} = 1/N\\)\nand we have loss of particle diversity.\nResample only when \\(N_{\\text{eff}} &gt; N_{\\text{thresh}}\\)\n\nIdea #2: inject random particles during resampling\nIdea #3: increase the number of particles (may be impractical depending on the computational complexity of the system)"
  },
  {
    "objectID": "lecs/w10/lec10.html#how-to-address-particle-deprivation-2",
    "href": "lecs/w10/lec10.html#how-to-address-particle-deprivation-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How to address particle deprivation",
    "text": "How to address particle deprivation\n\nIdea #1: don’t resample when only a few particles contribute\nIdea #2: inject random particles during resampling\n\nA small percentage of the particles’ states should be set randomly\n\nPro: simple to code, reduces (but does not fix) particle deprivation\nCon: incorrect posterior estimation even when there are infinitely many particles\n\n\nIdea #3: increase the number of particles (may be impractical depending on the computational complexity of the system)"
  },
  {
    "objectID": "lecs/w10/lec10.html#particle-filter-algorithm",
    "href": "lecs/w10/lec10.html#particle-filter-algorithm",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Particle Filter Algorithm",
    "text": "Particle Filter Algorithm\n\n\n\n\\[\\begin{aligned}\n&\\text{ParticleFilter}(\\bar{z}_t, u_{t-1}) \\\\\n&\\qquad\\bar{S}_t = \\{\\} \\quad \\bar{W}_t = \\{\\} \\\\\n&\\qquad\\text{for particle index } m = 1...M \\\\\n&\\qquad\\qquad \\text{sample } x_t^{[m]} \\sim p(x_t|x_{t-1}^{[m]}, u_{t-1}) \\\\\n&\\qquad\\qquad w_t^{[m]} = p(\\bar{z}_t|x_t^{[m]}) \\\\\n&\\qquad\\qquad \\bar{S}_t.\\text{append}(x_t^{[m]}) \\\\\n&\\qquad\\qquad \\bar{W}_t.\\text{append}(w_t^{[m]}) \\\\\n\\\\\n&\\qquad S_t = \\{\\} \\\\\n&\\qquad\\text{for particle index } m = 1...M \\\\\n&\\qquad\\qquad \\text{sample particle i from } \\bar{S}_t \\text{ with probability } \\propto w_i^{[i]} \\\\\n&\\qquad\\qquad S_t.\\text{append}(x_t^{[m]}) \\\\\n\\\\\n&\\quad\\text{return } S_t\n\\end{aligned}\\]\n\n\n \n\n\n\n\n Actual observation and control received\n\n\nParticle propagation/prediction:\n noise needs to be added in order to make\nparticles differentiate from each other.\nIf propagation is deterministic then particles\nare going to collapse to a single particle after a\nfew resampling steps.\n\n\n Weight computation as measurement likelihood.\nFor each particle we compute the probability of the\nactual observation given the state is at that particle.\n\n\n Resampling step\nNote: particle deprivation heuristics are not\nshown here\n\n\n\n\nNote: here we work with a fixed number of particles\nbut in many applications, such as localization, you could work\nwith a reduced number of particles after the particles have\nconverged to the true estimate.\nSuch implementations of particle filters are called adaptive. An\nexample is the KLD-sampling adaptive particle filter, which is\nnot going to be covered here."
  },
  {
    "objectID": "lecs/w10/lec10.html#examples-1d-localization",
    "href": "lecs/w10/lec10.html#examples-1d-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples: 1D Localization",
    "text": "Examples: 1D Localization\n\n\n\n\n\n\n\n\n\n\n\n\\(p(x)\\)\n\n\\(p(z = \\text{door} | x)\\)\n\n\\(p(x|z_0 = \\text{door})\\)"
  },
  {
    "objectID": "lecs/w10/lec10.html#examples-1d-localization-1",
    "href": "lecs/w10/lec10.html#examples-1d-localization-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples: 1D Localization",
    "text": "Examples: 1D Localization\n\n\n\n\n\n\n\n\n\n\n\n\\(p(x|z_0 = \\text{door}, u_0 = \\text{right})\\)\n\n\\(p(z = \\text{door} | x)\\)\n\n\\(p(x|z_0 = \\text{door}, u_0 = \\text{right}, z_1 = \\text{door})\\)"
  },
  {
    "objectID": "lecs/w10/lec10.html#examples-monte-carlo-localization",
    "href": "lecs/w10/lec10.html#examples-monte-carlo-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples: Monte Carlo Localization",
    "text": "Examples: Monte Carlo Localization"
  },
  {
    "objectID": "lecs/w10/lec10.html#examples-monte-carlo-localization-1",
    "href": "lecs/w10/lec10.html#examples-monte-carlo-localization-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples: Monte Carlo Localization",
    "text": "Examples: Monte Carlo Localization\n\nAfter incorporating 10 ultrasound scans"
  },
  {
    "objectID": "lecs/w10/lec10.html#examples-monte-carlo-localization-2",
    "href": "lecs/w10/lec10.html#examples-monte-carlo-localization-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples: Monte Carlo Localization",
    "text": "Examples: Monte Carlo Localization\n\nAfter incorporating 65 ultrasound scans"
  },
  {
    "objectID": "lecs/w10/lec10.html#using-ceiling-maps-for-localization",
    "href": "lecs/w10/lec10.html#using-ceiling-maps-for-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Using Ceiling Maps for Localization",
    "text": "Using Ceiling Maps for Localization"
  },
  {
    "objectID": "lecs/w10/lec10.html#vision-based-localization",
    "href": "lecs/w10/lec10.html#vision-based-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Vision-based Localization",
    "text": "Vision-based Localization"
  },
  {
    "objectID": "lecs/w10/lec10.html#under-a-light",
    "href": "lecs/w10/lec10.html#under-a-light",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Under a Light",
    "text": "Under a Light\n\n\nMeasurement z:\n\n\nP(z|x):"
  },
  {
    "objectID": "lecs/w10/lec10.html#next-to-a-light",
    "href": "lecs/w10/lec10.html#next-to-a-light",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Next to a Light",
    "text": "Next to a Light\n\n\nMeasurement z:\n\n\nP(z|x):"
  },
  {
    "objectID": "lecs/w10/lec10.html#elsewhere",
    "href": "lecs/w10/lec10.html#elsewhere",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Elsewhere",
    "text": "Elsewhere\n\n\nMeasurement z:\n\n\nP(z|x):"
  },
  {
    "objectID": "lecs/w10/lec10.html#global-localization-using-vision",
    "href": "lecs/w10/lec10.html#global-localization-using-vision",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Global Localization Using Vision",
    "text": "Global Localization Using Vision"
  },
  {
    "objectID": "lecs/w10/lec10.html#appendix-1",
    "href": "lecs/w10/lec10.html#appendix-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\n\nWhy did we choose \\(w_t^{[m]} \\propto p(z_t|x_t^{[m]})\\) as the importance weight for particle m?\nMain trick: importance sampling , i.e. how to estimate properties/statistics of one distribution (f) given samples from another distribution (g)\n\n\n\n\n\n\nFor example, suppose we want to estimate the expected value of f given only samples from g.\n\n\\[\\begin{align*}\n\\mathbb{E}_{x\\sim f(x)}[x] &= \\int xf(x)dx \\qquad\\qquad\\quad \\\\\n&= \\int \\frac{g(x)}{g(x)}xf(x)dx \\qquad\\qquad\\quad \\\\\n&= \\int x\\frac{f(x)}{g(x)}g(x)dx \\qquad\\qquad\\quad \\\\\n&= \\mathbb{E}_{x\\sim g(x)}\\left[x\\frac{f(x)}{g(x)}\\right] \\qquad\\qquad\\quad \\\\\n&= \\mathbb{E}_{x\\sim g(x)}[x w(x)] \\qquad\\qquad\\quad\n\\end{align*}\\]\n\n\n\nWeights describe the mismatch\nbetween the two distributions,\ni.e. how to reweigh samples to\nobtain statistics of f from\nsamples of g"
  },
  {
    "objectID": "lecs/w10/lec10.html#appendix-1-1",
    "href": "lecs/w10/lec10.html#appendix-1-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\n\nWhy did we choose \\(w_t^{[m]} \\propto p(z_t|x_t^{[m]})\\) as the importance weight for particle m?\nMain trick: importance sampling , i.e. how to estimate properties/statistics of one distribution (f) given samples from another distribution (g)\n\n\n\n\n\nIn the case of particle filters\n\\(f(x_t) = p(x_t | z_{0:t}, u_{0:t-1}) = bel(x_t) \\qquad g(x_t) = p(x_t | z_{0:t-1}, u_{0:t-1}) = \\overline{bel}(x_t)\\)\n\nFor example, suppose we want to estimate the expected value of f given only samples from g.\n\\[\\begin{align*}\n\\mathbb{E}_{x\\sim f(x)}[x] &= \\int xf(x)dx \\qquad\\qquad\\quad \\\\\n&= \\int \\frac{g(x)}{g(x)}xf(x)dx \\qquad\\qquad\\quad \\\\\n&= \\int x\\frac{f(x)}{g(x)}g(x)dx \\qquad\\qquad\\quad \\\\\n&= \\mathbb{E}_{x\\sim g(x)}\\left[x\\frac{f(x)}{g(x)}\\right] \\qquad\\qquad\\quad \\\\\n&= \\mathbb{E}_{x\\sim g(x)}[x w(x)] \\qquad\\qquad\\quad\n\\end{align*}\\]\n\n\nWeights describe the mismatch\nbetween the two distributions,\ni.e. how to reweigh samples to\nobtain statistics of f from\nsamples of g\n\nPosterior belief after update \\(\\qquad\\qquad\\qquad\\) Belief after propagation, before update"
  },
  {
    "objectID": "lecs/w10/lec10.html#appendix-1-2",
    "href": "lecs/w10/lec10.html#appendix-1-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix 1",
    "text": "Appendix 1\n\n\nWhy did we choose \\(w_t^{[m]} \\propto p(z_t|x_t^{[m]})\\) as the importance weight for particle m?\nMain trick: importance sampling , i.e. how to estimate properties/statistics of one distribution (f) given samples from another distribution (g)\n\n\n\n\n\nIn the case of particle filters\n\\(f(x_t) = p(x_t | z_{0:t}, u_{0:t-1}) = bel(x_t) \\qquad g(x_t) = p(x_t | z_{0:t-1}, u_{0:t-1}) = \\overline{bel}(x_t)\\)\n\nFor example, suppose we want to estimate the expected value of f given only samples from g.\n\\[\\begin{align*}\nw(x_t^{[m]}) & = \\frac{f(x_t^{[m]})}{g(x_t^{[m]})} \\\\\n& \\propto \\frac{p(z_t|x_t^{[m]}) p(x_t^{[m]}|x_{t-1}^{[m]}, u_{t-1}) bel(x_{t-1}^{[m]})}{p(x_t^{[m]}|x_{t-1}^{[m]}, u_{t-1}) bel(x_t^{[m]})} \\\\\n& \\propto p(z_t|x_t^{[m]})\n\\end{align*}\\]\n\nPosterior belief after update \\(\\qquad\\qquad\\qquad\\) Belief after propagation, before update"
  },
  {
    "objectID": "lecs/w09/lec09.html#recommended-reading",
    "href": "lecs/w09/lec09.html#recommended-reading",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nChapter 3.3 in Probabilistic Robotics for EKF\nChapter 7.4 in Probabilistic Robotics for EKF-Localization\nChapter 10.2 in Probabilistic Robotics for EKF-SLAM"
  },
  {
    "objectID": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter",
    "href": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\n\\[\\begin{align}bel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}\\end{align}\\]\n\n\n\n\n\n\n\\[\\begin{align}z_t = & Hx_t + n_t \\\\\n& \\text{with noise } n_t \\sim \\mathcal{N}(0, R)\\end{align}\\]\n\n\n \n\n\n\\[\\begin{align}\nx_t &= Ax_{t-1} + Bu_{t-1} + Gw_{t-1} \\\\\n& \\text{with noise } w_{t-1} \\sim N(0,Q)\n\\end{align}\\]\n\n\n \n\n\n\\(\\qquad bel(x_0) \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter-1",
    "href": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\n\\[\\begin{align}bel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}\\end{align}\\]\n\n\n\n\n\n\n\\[\\begin{align}z_t = & h(x_t) + n_t \\\\\n& \\text{with noise } n_t \\sim \\mathcal{N}(0, R)\\end{align}\\]\n\n\n \n\n\n\\[\\begin{align}\nx_t &= f(x_{t-1}, u_{t-1}) + Gw_{t-1} \\\\\n& \\text{with noise } w_{t-1} \\sim N(0,Q)\n\\end{align}\\]\n\n\n \n\n\n\\(\\qquad bel(x_0) \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\\)\n\n\n\n\n\nSuppose you replace\nthe linear models with\nnonlinear models.\nDoes the posterior\n\\(\\color{black}bel(x_t)\\) remain\nGaussian?\n\\(\\qquad\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter-2",
    "href": "lecs/w09/lec09.html#kalman-filter-an-instance-of-bayes-filter-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kalman Filter: an instance of Bayes’ Filter",
    "text": "Kalman Filter: an instance of Bayes’ Filter\n\n\\[\\begin{align}bel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}\\end{align}\\]\n\n\n\n\n\n\n\\[\\begin{align}z_t = & h(x_t) + n_t \\\\\n& \\text{with noise } n_t \\sim \\mathcal{N}(0, R)\\end{align}\\]\n\n\n \n\n\n\\[\\begin{align}\nx_t &= f(x_{t-1}, u_{t-1}) + Gw_{t-1} \\\\\n& \\text{with noise } w_{t-1} \\sim N(0,Q)\n\\end{align}\\]\n\n\n \n\n\n\\(\\qquad bel(x_0) \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\\)\n\n\n\n\n\nSuppose you replace\nthe linear models with\nnonlinear models.\nDoes the posterior\n\\(\\color{black}bel(x_t)\\) remain\nGaussian? NO\n\\(\\qquad\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#linearity-assumption-revisited",
    "href": "lecs/w09/lec09.html#linearity-assumption-revisited",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linearity Assumption Revisited",
    "text": "Linearity Assumption Revisited\n\n\n\n\n\n\nIf \\(y = ax + b\\)\nand \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nthen \\(y \\sim \\mathcal{N}(a\\mu + b, a^2\\sigma^2)\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#nonlinear-function",
    "href": "lecs/w09/lec09.html#nonlinear-function",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Nonlinear Function",
    "text": "Nonlinear Function\n\n\n\n\n\n\nIf \\(y = g(x)\\)\nand \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nthen y is not necessarily\ndistributed as a Gaussian.\n\n\n\nHow can we approximate p(y) using a single Gaussian, without having a\nformula for p(y)?\nIDEA #1: MONTE CARLO SAMPLING\n- Draw many (e.g. 10^6) samples xi ~ p(x)\n- Pass them through the nonlinear function yi = g(xi)\n- Compute the empirical mean (m) and covariance (S) of the samples yi\n- Return Normal(m, S)\nIDEA #2: LINEARIZE THE NONLINEAR FUNCTIONS f, h\n- Then we are in the case y = Gx +c, so p(y) is a Gaussian"
  },
  {
    "objectID": "lecs/w09/lec09.html#nonlinear-function-1",
    "href": "lecs/w09/lec09.html#nonlinear-function-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Nonlinear Function",
    "text": "Nonlinear Function\n\n\n\n\n\n\nIf \\(y = g(x)\\)\nand \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nthen y is not necessarily\ndistributed as a Gaussian.\n\n\nHow can we approximate p(y) using a single Gaussian, without having a\nformula for p(y)?\nIDEA #1: MONTE CARLO SAMPLING\n- Draw many (e.g. 10^6) samples xi ~ p(x)\n- Pass them through the nonlinear function yi = g(xi)\n- Compute the empirical mean (m) and covariance (S) of the samples yi\n- Return Normal(m, S)\nIDEA #2: LINEARIZE THE NONLINEAR FUNCTIONS f, h\n- Then we are in the case y = Gx +c, so p(y) is a Gaussian"
  },
  {
    "objectID": "lecs/w09/lec09.html#linearization",
    "href": "lecs/w09/lec09.html#linearization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linearization",
    "text": "Linearization\n\n\n\n\n\n\nNotice how the Linearization\napproximation differs from the\nMonte Carlo approximation (which\nis better, provided sufficiently many\nsamples).\nThat said, the Linearization approximation\ncan be computed efficiently, and can be\nintegrated into the Kalman\nFilter estimator \\(\\rightarrow\\) Extended Kalman Filter"
  },
  {
    "objectID": "lecs/w09/lec09.html#linearization-with-low-approximation-error",
    "href": "lecs/w09/lec09.html#linearization-with-low-approximation-error",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linearization with low approximation error",
    "text": "Linearization with low approximation error\n\n\n\n \n\n\n\n\n\n\n\nThe quality of the linearization\napproximation depends on the uncertainty\nof p(x) but also on the shape of the nonlinearity\ng(x).\nIn this example p(x) has small variance so\nmost points will be concentrated around 0.5 and\nwill pass through a very small region of g(x), where\ng(x) is close to linear.\nIn this case p(y) is nearly Gaussian,\nand the Linearization approximation\nmatches the Monte Carlo approximation."
  },
  {
    "objectID": "lecs/w09/lec09.html#linearization-with-high-approximation-error",
    "href": "lecs/w09/lec09.html#linearization-with-high-approximation-error",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Linearization with high approximation error",
    "text": "Linearization with high approximation error\n\n\n\n\n\n\nThe quality of the linearization\napproximation depends on the\nuncertainty of p(x) but also on\nthe shape of the nonlinearity g(x).\nIn this example p(x) has high\nvariance so points g(x) will be\nspread out around g(0.5), where\ng(x) is not close to linear.\nIn this case p(y) is multimodal,\nand the Linearization approximation\nmatches the Monte Carlo approximation\nare both suboptimal approximations.\nAgain Monte Carlo is better, provided\nsufficient samples."
  },
  {
    "objectID": "lecs/w09/lec09.html#how-do-we-linearize",
    "href": "lecs/w09/lec09.html#how-do-we-linearize",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we linearize?",
    "text": "How do we linearize?\n\nUsing the first order Taylor expansion around the mean of the previous update step’s state estimate:\n\n\n\n\\[\\begin{align*}\nx_{t+1} &= f(x_t, u_t) + w_t \\\\\n&\\approx f(\\mu_{t|t}, u_t) + \\frac{\\partial f}{\\partial x}(\\mu_{t|t}, u_t)(x_t - \\mu_{t|t}) + w_t \\\\\n&= f(\\mu_{t|t}, u_t) + F_t(x_t - \\mu_{t|t}) + w_t \\\\\n&= F_t x_t + \\color{red}\\boxed{\\color{black}f(\\mu_{t|t}, u_t) - F_t \\mu_{t|t}} \\color{black} + w_t \\\\\n&= F_t x_t + \\bar{u}_t + w_t\n\\end{align*}\\]\n\nRecall how to compute the Jacobian matrix. For example, if\n\\(f(x_{1},x_{2},u)=[x_{1}+x_{2}^{2},x_{2}+3u,x_{1}^{4}-u^{2}]\\in\\mathbb{R}^{3}\\)\nthen the Jacobian of f with respect to \\(\\color{black}(x_1, x_2)\\) at \\(\\color{black}(u_1, u_2, u)\\) is\n\\[\\begin{align}\n\\frac{\\partial f}{\\partial x_{1:2}}(\\mu_1, \\mu_2, u_1) &= \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} \\\\ \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} \\\\ \\frac{\\partial f_3}{\\partial x_1} & \\frac{\\partial f_3}{\\partial x_2} \\end\n{bmatrix} (\\mu_1, \\mu_2, u_1) \\\\\n&= \\begin{bmatrix} 1 & 2\\mu_2 \\\\ 0 & 1 \\\\ 4\\mu_1^3 & 0 \\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w09/lec09.html#how-do-we-linearize-1",
    "href": "lecs/w09/lec09.html#how-do-we-linearize-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we linearize?",
    "text": "How do we linearize?\n\nUsing the first-order Taylor expansion around the mean of the previous prediction step’s state estimate:\n\n\n\n\\[\\begin{align*}\nz_{t+1} &= h(x_{t+1}) + n_{t+1} \\\\\n&\\approx h(\\mu_{t+1|t}) + \\frac{\\partial h}{\\partial x}(\\mu_{t+1|t})(x_t - \\mu_{t+1|t}) + n_{t+1} \\\\\n&= h(\\mu_{t+1|t}) + H_{t+1}(x_{t+1} - \\mu_{t+1|t}) + n_{t+1} \\\\\n&= H_{t+1}x_{t+1} + \\color{red}\\boxed{\\color{black}h(\\mu_{t+1|t}) - H_{t+1}\\mu_{t+1|t}} \\color{black} + n_{t+1} \\\\\n&= H_{t+1}x_{t+1} + \\bar{c}_{t+1} + n_{t+1}\n\\end{align*}\\]\n\nRecall how to compute the Jacobian matrix. For example, if\n\\(h(x_{1},x_{2}) = [x_{1}+x_{2}^{2}, x_{2}, x_{1}^{4}] \\in \\mathbb{R}^{3}\\)\nthen the Jacobian of f with respect to \\(\\color{black}(x_1, x_2)\\) at \\(\\color{black}(u_1, u_2)\\) is\n\\[\\begin{align}\n\\frac{\\partial h}{\\partial x_{1:2}}(\\mu_1, \\mu_2) &= \\begin{bmatrix} \\frac{\\partial h_1}{\\partial x_1} & \\frac{\\partial h_1}{\\partial x_2} \\\\ \\frac{\\partial h_2}{\\partial x_1} & \\frac{\\partial h_2}{\\partial x_2} \\\\ \\frac{\\partial h_3}{\\partial x_1} & \\frac{\\partial h_3}{\\partial x_2} \\end\n{bmatrix} (\\mu_1, \\mu_2) \\\\\n&= \\begin{bmatrix} 1 & 2\\mu_2 \\\\ 0 & 1 \\\\ 4\\mu_1^3 & 0 \\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "lecs/w09/lec09.html#extended-kalman-filter-an-instance-of-bayes-filter",
    "href": "lecs/w09/lec09.html#extended-kalman-filter-an-instance-of-bayes-filter",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Extended Kalman Filter: an instance of Bayes’ Filter",
    "text": "Extended Kalman Filter: an instance of Bayes’ Filter\n\n\\[\\begin{align}bel(x_t) &= p(x_t|u_{0:t-1}, z_{0:t}) \\\\\n&= \\eta p(z_t|x_t) \\int p(x_t|u_{t-1}, x_{t-1}) bel(x_{t-1}) dx_{t-1}\\end{align}\\]\n\n\n\n\n\n\n\\[\\begin{align}\nz_t = & H x_t + \\bar{c}_t + n_t \\\\\n& \\text{with noise } n_t \\sim \\mathcal{N}(0, R)\n\\end{align}\\]\n\n\n \n\n\n\\[\\begin{align}\n\\qquad x_t = & F_{t-1}x_{t-1} + \\bar{u}_{t-1} + Gw_{t-1} \\\\\n& \\text{with noise } w_{t-1} \\sim \\mathcal{N}(0, Q)\n\\end{align}\\]\n\n\n \n\n\n\\(\\qquad bel(x_0) \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#qquadquad-ekf-in-n-dimensions",
    "href": "lecs/w09/lec09.html#qquadquad-ekf-in-n-dimensions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "\\(\\qquad\\quad\\) EKF in N dimensions",
    "text": "\\(\\qquad\\quad\\) EKF in N dimensions\n\nDynamics\n\\(x_{t+1} = f(x_{t},u_{t})+Gw_{t}\\)\n\\(w_{t} \\sim \\mathcal{N}(0, Q)\\)\n\n\nMeasurements\n\\(z_t = h(x_t) + n_t\\)\n\\(n_t \\sim \\mathcal{N}(0, R)\\)\n\n\nInit \\[bel(x_0) \\sim \\mathcal{N}(\\mu_{0|0}, \\Sigma_{0|0})\\]\nPrediction Step \\[\\mu_{t+1|t} = f(\\mu_{t |t}, \\mu_t)\\] \\[\\Sigma_{t+1|t} = F_t\\Sigma_{t|t}F^T_t + GQG^T\\]\nUpdate Step\nReceived measurement \\(\\bar{z}_{t+1}\\) but expected to receive \\(\\mu_{z_{t+1}} = h(\\mu_{t+1|t})\\)\nPrediction residual is a Gaussian random variable \\(\\delta z \\sim \\mathcal{N}(\\bar{z}_{t+1} - \\mu_{z_{t+1}}, S_{t+1})\\)\nwhere the covariance of the residual is \\(S_{t+1} = H_{t+1}\\Sigma_{t+1|t}H^T_{t+1} + R\\)\nKalman Gain (optimal correction factor): \\(K_{t+1}=\\Sigma_{t+1|t}H_{t+1}^{T}S_{t+1}^{-1}\\)\n\\[\\mu_{t+1|t+1}=\\mu_{t+1|t}+K_{t+1}(\\bar{z}_{t+1}-\\mu_{z_{t+1}})\\]\n\\[\\Sigma_{t+1|t+1}=\\Sigma_{t+1|t}-K_{t+1}H_{t+1}\\Sigma_{t+1|t}\\]"
  },
  {
    "objectID": "lecs/w09/lec09.html#ekf-summary",
    "href": "lecs/w09/lec09.html#ekf-summary",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "EKF Summary",
    "text": "EKF Summary\n\nEfficient : Polynomial in measurement dimensionality k and state dimensionality n: \\[O(k^{2.376} + n^2)\\]\nNot optimal (unlike the Kalman Filter for linear systems)\nCan diverge if nonlinearities are large\nWorks surprisingly well even when all assumptions are violated\n\n\nAs in KF, inverting\nthe covariance of the\nresidual is O(k^2.376)"
  },
  {
    "objectID": "lecs/w09/lec09.html#example-1-ekf-localization",
    "href": "lecs/w09/lec09.html#example-1-ekf-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example #1: EKF-Localization",
    "text": "Example #1: EKF-Localization\n\n“Using sensory information to locate the robot in its environment is the most fundamental problem to providing a mobile robot with autonomous capabilities.” [Cox ’91]\n\n\nGiven\n\nMap of the environment.\nSequence of sensor measurements.\n\nWanted\n\nEstimate of the robot’s position.\n\nProblem classes\n\nPosition tracking\nGlobal localization\nKidnapped robot problem (recovery)"
  },
  {
    "objectID": "lecs/w09/lec09.html#landmark-based-localization",
    "href": "lecs/w09/lec09.html#landmark-based-localization",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Landmark-based Localization",
    "text": "Landmark-based Localization\n\n\n\n\n\n\n\nLandmarks, whose\nposition \\(\\color{black}(l_{x}^{(i)}, l_{y}^{(i)})\\)\nin the world is known.\n\nEach robot measures\nits range and bearing\nfrom each landmark\nto localize itself.\n\nState of a robot:\n\\(\\color{black} x_{t} = \\begin{bmatrix} p_{x}(t) \\\\ p_{y}(t) \\\\ \\theta(t) \\end{bmatrix}\\)"
  },
  {
    "objectID": "lecs/w09/lec09.html#landmark-based-localization-1",
    "href": "lecs/w09/lec09.html#landmark-based-localization-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Landmark-based Localization",
    "text": "Landmark-based Localization\n\n\n\n\n\n\n\nMeasurement at time t,\n\\(\\color{black}z_t = \\begin{bmatrix} \\dots \\\\ z_t^{(i)} \\\\ \\dots \\end{bmatrix}\\)\n\n\nis a variable-sized\nvector, depending on the\nlandmarks that are\nvisible at time t.\n\nEach measurement is\na 2D vector, containing\nrange and bearing from\nthe robot to a landmark.\n\n\n\\[z_t^{(i)} = h_i(x_t) = \\left[ \\begin{pmatrix} \\sqrt{(p_x(t)-l_x^{(i)})^2 + (p_y(t)-l_y^{(i)})^2} \\\\ \\text{atan2}(p_y(t)-l_y^{(i)}, p_x(t)-l_x^{(i)})-\\theta(t) \\end{pmatrix} \\right] + n_t\\]"
  },
  {
    "objectID": "lecs/w09/lec09.html#estimation-sequence-1",
    "href": "lecs/w09/lec09.html#estimation-sequence-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimation Sequence (1)",
    "text": "Estimation Sequence (1)"
  },
  {
    "objectID": "lecs/w09/lec09.html#estimation-sequence-2",
    "href": "lecs/w09/lec09.html#estimation-sequence-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Estimation Sequence (2)",
    "text": "Estimation Sequence (2)"
  },
  {
    "objectID": "lecs/w09/lec09.html#comparison-to-true-trajectory",
    "href": "lecs/w09/lec09.html#comparison-to-true-trajectory",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Comparison to true trajectory",
    "text": "Comparison to true trajectory"
  },
  {
    "objectID": "lecs/w09/lec09.html#example-2-ekf-slam",
    "href": "lecs/w09/lec09.html#example-2-ekf-slam",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example #2: EKF-SLAM",
    "text": "Example #2: EKF-SLAM\n\n\nA robot is exploring an unknown, static environment.\n\nGiven:\n\nThe robot’s controls\nObservations of nearby features\n\nEstimate:\n\nMap of features\nPath of the robot"
  },
  {
    "objectID": "lecs/w09/lec09.html#structure-of-landmark-based-slam",
    "href": "lecs/w09/lec09.html#structure-of-landmark-based-slam",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Structure of Landmark-based SLAM",
    "text": "Structure of Landmark-based SLAM"
  },
  {
    "objectID": "lecs/w09/lec09.html#why-is-slam-a-hard-problem",
    "href": "lecs/w09/lec09.html#why-is-slam-a-hard-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is SLAM a hard problem?",
    "text": "Why is SLAM a hard problem?\nSLAM : robot path and map are both unknown\n\nRobot path error correlates errors in the map"
  },
  {
    "objectID": "lecs/w09/lec09.html#why-is-slam-a-hard-problem-1",
    "href": "lecs/w09/lec09.html#why-is-slam-a-hard-problem-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why is SLAM a hard problem?",
    "text": "Why is SLAM a hard problem?\n\n\nIn the real world, the mapping between observations and landmarks is unknown\nPicking wrong data associations can have catastrophic consequences\nPose error correlates data associations"
  },
  {
    "objectID": "lecs/w09/lec09.html#ekf-slam",
    "href": "lecs/w09/lec09.html#ekf-slam",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "EKF-SLAM",
    "text": "EKF-SLAM\n\nMap with N landmarks: (3+2N)-dimensional Gaussian\n\n\n\n\nCan handle hundreds of dimensions"
  },
  {
    "objectID": "lecs/w09/lec09.html#appendix",
    "href": "lecs/w09/lec09.html#appendix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "lecs/w09/lec09.html#ekf-slam-1",
    "href": "lecs/w09/lec09.html#ekf-slam-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "EKF-SLAM",
    "text": "EKF-SLAM\n\n\n\n\n \n\n\nMap\n\n\nCovariance matrix"
  },
  {
    "objectID": "lecs/w09/lec09.html#ekf-slam-2",
    "href": "lecs/w09/lec09.html#ekf-slam-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "EKF-SLAM",
    "text": "EKF-SLAM\n\n\n\n\n \n\n\nMap\n\n\nCovariance matrix"
  },
  {
    "objectID": "lecs/w09/lec09.html#ekf-slam-3",
    "href": "lecs/w09/lec09.html#ekf-slam-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "EKF-SLAM",
    "text": "EKF-SLAM\n\n\n\n\n \n\n\nMap\n\n\nCovariance matrix"
  },
  {
    "objectID": "lecs/w09/lec09.html#properties-of-ekf-slam-linear-case",
    "href": "lecs/w09/lec09.html#properties-of-ekf-slam-linear-case",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Properties of EKF-SLAM (Linear Case)",
    "text": "Properties of EKF-SLAM (Linear Case)\n[Dissanayake et al., 2001]\n\nTheorem :\nThe determinant of any sub-matrix of the map covariance matrix decreases monotonically as successive observations are made.\n\nTheorem :\nIn the limit the landmark estimates become fully correlated"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda",
    "href": "lecs/w01/lec01.html#todays-agenda",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#your-tas",
    "href": "lecs/w01/lec01.html#your-tas",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Your TAs",
    "text": "Your TAs\n\n\nYewon Lee\nMSc student\nComputer Science, UofT\ncsc477-tas@cs.toronto.edu\n\nYasasa Abeysirigoonawardena\nMSc student\nComputer Science, UofT\n\ncsc477-tas@cs.toronto.edu\n\nRadian Gondokaryono\nPhD student\nComputer Science, UofT\n\ncsc477-tas@cs.toronto.edu"
  },
  {
    "objectID": "lecs/w01/lec01.html#my-lab-robot-vision-and-learning-rvl",
    "href": "lecs/w01/lec01.html#my-lab-robot-vision-and-learning-rvl",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "My lab: Robot Vision and Learning (RVL)",
    "text": "My lab: Robot Vision and Learning (RVL)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMission: create algorithms that enable robots to learn to act intelligently in outdoor environments and alongside humans"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics\n\n\n\n\n\n\nMars Exploration Rover\n\n\n\n\n \n\n\n\n\n\nRoboCup, small-sized league"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-1",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-2",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics"
  },
  {
    "objectID": "lecs/w01/lec01.html#today-you-have",
    "href": "lecs/w01/lec01.html#today-you-have",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today you have",
    "text": "Today you have"
  },
  {
    "objectID": "lecs/w01/lec01.html#factory-automation",
    "href": "lecs/w01/lec01.html#factory-automation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Factory Automation",
    "text": "Factory Automation\n\n\n\n\n\nAutonomous warehouse robots at Amazon\n\n\n\n\n\n\nAutonomous arms at Tesla"
  },
  {
    "objectID": "lecs/w01/lec01.html#pipe-inspection",
    "href": "lecs/w01/lec01.html#pipe-inspection",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pipe Inspection",
    "text": "Pipe Inspection\n\nManually-controlled inspection robots"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Fukushima Daiichi, 2011"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup-1",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Fukushima Daiichi, 2011"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup-2",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Chernobyl, 1986"
  },
  {
    "objectID": "lecs/w01/lec01.html#aerial-package-delivery",
    "href": "lecs/w01/lec01.html#aerial-package-delivery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Aerial Package Delivery",
    "text": "Aerial Package Delivery"
  },
  {
    "objectID": "lecs/w01/lec01.html#aerial-first-aid-delivery",
    "href": "lecs/w01/lec01.html#aerial-first-aid-delivery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Aerial First-Aid Delivery",
    "text": "Aerial First-Aid Delivery"
  },
  {
    "objectID": "lecs/w01/lec01.html#smart-wheelchairs",
    "href": "lecs/w01/lec01.html#smart-wheelchairs",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Smart Wheelchairs",
    "text": "Smart Wheelchairs"
  },
  {
    "objectID": "lecs/w01/lec01.html#robot-surgery",
    "href": "lecs/w01/lec01.html#robot-surgery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Robot Surgery",
    "text": "Robot Surgery\ndaVinci robot-assisted surgery"
  },
  {
    "objectID": "lecs/w01/lec01.html#precision-agriculture",
    "href": "lecs/w01/lec01.html#precision-agriculture",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Precision Agriculture",
    "text": "Precision Agriculture\n\nfarmbot.io"
  },
  {
    "objectID": "lecs/w01/lec01.html#self-driving-trucks",
    "href": "lecs/w01/lec01.html#self-driving-trucks",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Self-driving Trucks",
    "text": "Self-driving Trucks"
  },
  {
    "objectID": "lecs/w01/lec01.html#mining-operations",
    "href": "lecs/w01/lec01.html#mining-operations",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Mining Operations",
    "text": "Mining Operations"
  },
  {
    "objectID": "lecs/w01/lec01.html#oil-spill-containment",
    "href": "lecs/w01/lec01.html#oil-spill-containment",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Oil Spill Containment",
    "text": "Oil Spill Containment\n\nBP Deepwater Horizon Spill, Gulf of Mexico, 2010"
  },
  {
    "objectID": "lecs/w01/lec01.html#autonomy-vs.-remote-control",
    "href": "lecs/w01/lec01.html#autonomy-vs.-remote-control",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Autonomy vs. Remote Control",
    "text": "Autonomy vs. Remote Control\n\nQ: When is full or partial autonomy necessary?\nQ: When is remote control preferred?"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-1",
    "href": "lecs/w01/lec01.html#todays-agenda-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\n\n\n\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#prerequisites",
    "href": "lecs/w01/lec01.html#prerequisites",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\n\nSoftware Engineering\n\nLoops, conditionals, classes, modularity\nLists, hash maps/dictionaries, trees\nThreads, callbacks, remote procedure calls, serialization\n\nLinear Algebra\n\nMatrix multiplication and inversion, determinant\nSolving systems of equations, Gaussian elimination\nMatrix decompositions: Cholesky, QR\nLeast squares\n\nBasic Probability Theory\n\nMultivariate distributions, especially Gaussians\nConditional probability, Bayes’ rule\nMaximum likelihood estimation"
  },
  {
    "objectID": "lecs/w01/lec01.html#prerequisites-1",
    "href": "lecs/w01/lec01.html#prerequisites-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Prerequisites",
    "text": "Prerequisites\nCurrently\nRequired: CSC209H5; STA256H5; MAT223H5/MAT240H5; MAT232H5; CSC376\nRecommended: MAT224H5; CSC384H5; CSC311H5;"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments",
    "href": "lecs/w01/lec01.html#assignments",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "4 Assignments",
    "text": "4 Assignments\n\n~80% coding and the rest theory\nStarter code will be provided\nBonus questions will be provided\nAccepted languages: Python, C++\nYou’re going to learn ROS (Robot Operating System) and use the Gazebo simulator\nYou’re also going to learn numpy and scipy\nAbout 2 weeks to work on each"
  },
  {
    "objectID": "lecs/w01/lec01.html#ros-gazebo-simulation",
    "href": "lecs/w01/lec01.html#ros-gazebo-simulation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "ROS + Gazebo simulation",
    "text": "ROS + Gazebo simulation"
  },
  {
    "objectID": "lecs/w01/lec01.html#quizzes",
    "href": "lecs/w01/lec01.html#quizzes",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "7 Quizzes",
    "text": "7 Quizzes\n\n5-10 mins to complete them\nNot cumulative in terms of material. They cover only one lecture\nMeant to check whether you have understood basic concepts"
  },
  {
    "objectID": "lecs/w01/lec01.html#evaluation",
    "href": "lecs/w01/lec01.html#evaluation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Evaluation",
    "text": "Evaluation\nCSC477\n\n4 assignments, 15% each = 60%\n7 quizzes, 2% each = 14%\n1 final exam = 26%\n\n\nCSC2630\n\n3 assignments, 15% each = 45%\n7 quizzes, 2% each = 14%\n1 final project = 41%"
  },
  {
    "objectID": "lecs/w01/lec01.html#recommended-textbooks-optional",
    "href": "lecs/w01/lec01.html#recommended-textbooks-optional",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Recommended Textbooks (optional)",
    "text": "Recommended Textbooks (optional)"
  },
  {
    "objectID": "lecs/w01/lec01.html#recommended-online-courses-optional",
    "href": "lecs/w01/lec01.html#recommended-online-courses-optional",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Recommended Online Courses (optional)",
    "text": "Recommended Online Courses (optional)\n\nMaterial is related to 477 but not identical\nI will post links on Quercus to specific lectures that are relevant\n\n\f\n\nhttps://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\nhttps://www.edx.org/course/autonomous-mobile-robots-ethx-amrx-1\nhttps://underactuated.mit.edu/ (more advanced, little overlap with 477)"
  },
  {
    "objectID": "lecs/w01/lec01.html#office-hours-zoom",
    "href": "lecs/w01/lec01.html#office-hours-zoom",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Office Hours (Zoom)",
    "text": "Office Hours (Zoom)\n\nFlorian: Thursdays 3-4pm\nYewon: Tuesdays 11-12pm\nYasasa: Fridays 11-12pm\n\n\f\n\nOffice hours will begin next week"
  },
  {
    "objectID": "lecs/w01/lec01.html#online-communication",
    "href": "lecs/w01/lec01.html#online-communication",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Online communication",
    "text": "Online communication\n\nUse Quercus\nPlease check your course-related email frequently\nEmail us at csc477-instructor@cs.toronto.edu and csc477-tas@cs.toronto.edu\nAnonymous feedback about anything course-related: https://www.surveymonkey.com/r/H8QH65F"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-2",
    "href": "lecs/w01/lec01.html#todays-agenda-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\n\n\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#covered-qquad-qquad-qquad-not-covered",
    "href": "lecs/w01/lec01.html#covered-qquad-qquad-qquad-not-covered",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Covered \\(\\qquad \\qquad \\qquad\\) Not Covered",
    "text": "Covered \\(\\qquad \\qquad \\qquad\\) Not Covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-1",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\n\n\n\n\nMain question: what is the next state given the curent state and controls?"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-2",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\n\n\n\n\nMain question: what are the controls that will take the system from state A to B?"
  },
  {
    "objectID": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control",
    "href": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Not covered in CSC477, but related: learning for control",
    "text": "Not covered in CSC477, but related: learning for control"
  },
  {
    "objectID": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control-1",
    "href": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Not covered in CSC477, but related: learning for control",
    "text": "Not covered in CSC477, but related: learning for control"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-3",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-4",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-4",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\nKnown: robot’s position and orientation\nWant to estimate: a map of the environment from laser measurements\n\n\n\n\n\n\n\n\nOccupancy grid mapping"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-5",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-5",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#orb-slam-video",
    "href": "lecs/w01/lec01.html#orb-slam-video",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "orb slam video",
    "text": "orb slam video\nhttps://www.youtube.com/watch?v=_9VcvGybsDA"
  },
  {
    "objectID": "lecs/w01/lec01.html#lecture-topics-qquad-qquad-tutorials",
    "href": "lecs/w01/lec01.html#lecture-topics-qquad-qquad-tutorials",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Lecture topics \\(\\qquad \\qquad\\) Tutorials",
    "text": "Lecture topics \\(\\qquad \\qquad\\) Tutorials\n\n\n\n\n\n\nIntro to the Robot Operating System (ROS)\nRefresher on linear algebra and least squares\nRefresher on basic probability and continuous distributions\nHow to align 3D pointclouds. Demo of the PCL library\nHow to implement a Kalman Filter\nHow to implement a Particle Filter\nHow to approximate functions"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-1",
    "href": "lecs/w01/lec01.html#assignments-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\nA1: Designing a feedback controller for wall-following"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-2",
    "href": "lecs/w01/lec01.html#assignments-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\n\nA1: Designing a feedback controller for wall-following\n\nA2: Implementing path-planning and feedback control algorithms"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-3",
    "href": "lecs/w01/lec01.html#assignments-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n   \n\n\nA1: Designing a feedback controller for wall-following\n\nA2: Implementing path-planning and feedback control algorithms\n\nA3: Occupancy grid mapping with known robot location\nA4: Localization in a known map using particle filters"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-3",
    "href": "lecs/w01/lec01.html#todays-agenda-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\n\n\n\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-and-actuators",
    "href": "lecs/w01/lec01.html#sensors-and-actuators",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors and Actuators",
    "text": "Sensors and Actuators\n\nSensors:\n\nCharacteristics and types\nMeasurement noise\nRequired bandwidth\n\n\n\f\n\nActuators:\n\nTypes of motors\nPulse-Width Modulation"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors",
    "href": "lecs/w01/lec01.html#sensors",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors",
    "text": "Sensors\n\nDevices that can sense and measure physical properties of the environment.\nKey phenomenon is transduction (conversion of energy from one form to another). E.g.:\n\nImaging sensors: light to pixel voltages\nDepth sensors: mechanical pressure to voltage\n\nMeasurements are noisy, and difficult to interpret"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-general-characteristics",
    "href": "lecs/w01/lec01.html#sensors-general-characteristics",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors: general characteristics",
    "text": "Sensors: general characteristics\n\nSensitivity: (change of output) ÷ (change of input)\nLinearity: constancy of (output ÷ input)\nMeasurement range: [min, max] or {min, max}\nResponse time: time required for input change to cause output change\nAccuracy: difference between measurement and actual\nRepeatability/Drift: difference between repeated measures\nResolution: smallest observable increment\nBandwidth: required rate of data transfer\nSNR: signal-to-noise ratio"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-vision",
    "href": "lecs/w01/lec01.html#sensors-vision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors: vision",
    "text": "Sensors: vision\n\n\n\n\n\nCCD image sensor\n\n\n\nCCD (charge-coupled device) imaging sensors:\n\nCapacitor array accumulates electric charge proportional to light intensity.\nEach capacitor’s charge is transferred to its neighbor.\nLast capacitor’s charge gets amplified and output as voltage.\n(+) High-quality, low-noise images\n(-) Higher power consumption\n(-) Slow readout\n(-) Specialized fabrication\n\nvoltage → analog-to-digital converter → pixel value in {0, 255}\nCMOS (complementary metal-oxide semi-conductor) imaging sensors:\n\nOne amplifier per pixel\n(+) Low power\n(+) Fast readout\n(+) Easier to fabricate\n(-) Poor low-light sensitivity\n(-) Higher noise"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-vs.-rolling-shutter",
    "href": "lecs/w01/lec01.html#global-vs.-rolling-shutter",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global vs. Rolling Shutter",
    "text": "Global vs. Rolling Shutter\nShutter = mechanism that allows light to hit the imaging sensor\nShutter “speed” = Exposure time = time duration in which the sensor is exposed to light\n\n\n\n\n\n\n\nRolling shutter"
  },
  {
    "objectID": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera",
    "href": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Reading RGB images from a camera",
    "text": "Reading RGB images from a camera\n\n\n\nEach pixel contains an intensity value from 0…255\n\n\n\n\n\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels"
  },
  {
    "objectID": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera-1",
    "href": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Reading RGB images from a camera",
    "text": "Reading RGB images from a camera\n\n\n\nEach pixel contains an intensity value from 0…255\n\n\n\n\n\n\\(\\to\\) A matrix of 600 x 1000 x 3 = ~ 1.8 million numbers\n\n\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels"
  },
  {
    "objectID": "lecs/w01/lec01.html#computerrobot-vision",
    "href": "lecs/w01/lec01.html#computerrobot-vision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Computer/robot vision",
    "text": "Computer/robot vision\n\n\n\n\n\nStructured numbers\n\n\n\n\n\n\nI’m seeing a parrot\nI’m seeing a toy bicycle\nThe parrot is riding the bicycle\nThe bicycle is on top of a desk\nIs this physically plausible?\nWhere is the parrot in 3D w.r.t. the camera?\nWhere will the parrot go next?\nWhat is the speed of the parrot?\n\nConclusions/Inference/Deduction/Estimation"
  },
  {
    "objectID": "lecs/w01/lec01.html#camera-lenses",
    "href": "lecs/w01/lec01.html#camera-lenses",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Camera lenses",
    "text": "Camera lenses\n\n\n\nLens determines:\n\nimage distortion\nfocus\nsharpness or blur\n\nLens characteristics:\n\nfocal length\naperture\ndepth-of-field"
  },
  {
    "objectID": "lecs/w01/lec01.html#pinhole-camera-model",
    "href": "lecs/w01/lec01.html#pinhole-camera-model",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pinhole Camera Model",
    "text": "Pinhole Camera Model\n\n\nWe know approximately how a 3D point (X,Y,Z) projects to pixel (x,y)\nWe call this the pinhole projection model"
  },
  {
    "objectID": "lecs/w01/lec01.html#perspective-projection-xy-𝜋xyz",
    "href": "lecs/w01/lec01.html#perspective-projection-xy-𝜋xyz",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(1) Perspective projection [x,y] = 𝜋(X,Y,Z)",
    "text": "(1) Perspective projection [x,y] = 𝜋(X,Y,Z)\n\n\n\nhttp://www.cim.mcgill.ca/%7Elanger/558.html\n\nBy similar triangles: x/f = X/Z\nSo, x = f * X/Z and similarly y = f * Y/Z\nProblem: we just lost depth (Z) information by doing this projection, i.e. depth is now uncertain."
  },
  {
    "objectID": "lecs/w01/lec01.html#lens-distortion",
    "href": "lecs/w01/lec01.html#lens-distortion",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(2) Lens distortion",
    "text": "(2) Lens distortion"
  },
  {
    "objectID": "lecs/w01/lec01.html#estimating-parameters-of-lens-distortion",
    "href": "lecs/w01/lec01.html#estimating-parameters-of-lens-distortion",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(2) Estimating parameters of lens distortion",
    "text": "(2) Estimating parameters of lens distortion"
  },
  {
    "objectID": "lecs/w01/lec01.html#non-pinhole-cameras-thin-lens-model",
    "href": "lecs/w01/lec01.html#non-pinhole-cameras-thin-lens-model",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Non-pinhole cameras: thin lens model",
    "text": "Non-pinhole cameras: thin lens model\n\n\n\n\n\n\nUnlike the pinhole camera, this is able to model blur.\n\n\n\n\n\n\n\nhttp://www.cim.mcgill.ca/%7Elanger/558.html"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-1",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras\n\nDrawback: Doesn’t work underwater"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-2",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\n\n\nMain ideas:\n\nActive sensing\nProjector emits infrared light in the scene\nInfrared sensor reads the infrared light\nDeformation of the expected pattern allows computation of the depth"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-1",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nDrawbacks:\n\nDoes not work well outdoors, sunlight saturates its measurements\nMaximum range is [0.5, 8] meters\n\nAdvantages:\n\nReal-time depth estimation at 30Hz\nCheap"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-2",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nEnabled a wave of research, applications, and video games, based on real-time skeleton tracking"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-3",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nDespite their drawbacks RGBD sensors have been extensively used in robotics."
  },
  {
    "objectID": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging",
    "href": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "3D LIDAR (Light detection and ranging)",
    "text": "3D LIDAR (Light detection and ranging)\n\n\nProduces a pointcloud of 3D points and intensities\n\n(x,y,z) in the laser’s frame of reference\nIntensity is related to the material of the object that reflects the light\n\nWorks based on time-of-flight for each beam to return back to the scanner\n\nNot very robust to adverse weather conditions: rain, snow, smoke, fog etc.\nUsed in most self-driving cars today for obstacle detection. Range &lt; 100m.\n\n\n\n\nUsually around 1million points in a single pointcloud"
  },
  {
    "objectID": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging-1",
    "href": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "2D LIDAR (Light detection and ranging)",
    "text": "2D LIDAR (Light detection and ranging)\n\n\nProduces a scan of 2D points and intensities\n\n(x,y) in the laser’s frame of reference\nIntensity is related to the material of the object that reflects the light\n\nCertain surfaces are problematic for LIDAR: e.g. glass\n\n\nLots of moving parts: motors quickly rotate the laser beam and once complete (angle bound reached) a scan is returned. I.e. points are not strictly speaking time-synchronized, even though we usually treat them as such.\n\n\n\n\nUsually around 1024 points in a single scan."
  },
  {
    "objectID": "lecs/w01/lec01.html#inertial-sensors",
    "href": "lecs/w01/lec01.html#inertial-sensors",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Inertial Sensors",
    "text": "Inertial Sensors\n\nGyroscopes, Accelerometers, Magnetometers\nInertial Measurement Unit (IMU)\nPerhaps the most important sensor for 3D navigation, along with the GPS\nWithout IMUs, plane autopilots would be much harder, if not impossible, to build"
  },
  {
    "objectID": "lecs/w01/lec01.html#gyroscopes",
    "href": "lecs/w01/lec01.html#gyroscopes",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Gyroscopes",
    "text": "Gyroscopes\n\nMeasure angular velocity in the body frame\nOften affected by noise and bias\n\n\\[\nw_\\text{measured}(t) = w_\\text{true}(t) + b_g(t) + n_g(t)\n\\]\n\nWe integrate it to get 3D orientation (Euler angles, quaternions rotation matrices), but there is drift due to noise and bias"
  },
  {
    "objectID": "lecs/w01/lec01.html#accelerometers",
    "href": "lecs/w01/lec01.html#accelerometers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Accelerometers",
    "text": "Accelerometers\n\nMeasure linear acceleration relative to freefall (measured in g)\nA free-falling accelerometer in a vacuum would measure zero g\nAn accelerometer resting on the surface of the earth would measure 1g\nAlso affected by bias and noise.\nDouble integration to get position is very noisy. Errors grow quadratically with time."
  },
  {
    "objectID": "lecs/w01/lec01.html#magnetometers",
    "href": "lecs/w01/lec01.html#magnetometers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Magnetometers",
    "text": "Magnetometers\n\n\nDrawbacks:\n\nNeeds careful calibration\nNeeds to be placed away from moving metal parts, motors\n\nAdvantages:\n\nCan be used as a compass for absolute heading"
  },
  {
    "objectID": "lecs/w01/lec01.html#inertial-measurement-unit",
    "href": "lecs/w01/lec01.html#inertial-measurement-unit",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Inertial Measurement Unit",
    "text": "Inertial Measurement Unit\n\nCombines measurements from accelerometer, gyroscope, and magnetometer to output an estimate of orientation with reduced drift.\nDoes not typically provide a position estimate, due to double integration.\nRuns at 100-1000Hz\nExpect yaw drift of 5-10 deg/hour on most modern low-end IMUs"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-satellites",
    "href": "lecs/w01/lec01.html#global-positioning-system-satellites",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Satellites",
    "text": "Global Positioning System: Satellites\n\nEach GPS satellite periodically transmits:\n[Coarse/Acquisition code] A 1023-bit pseudorandom binary sequence (PRN code), which repeats every 1 ms, unique for each satellite (no correlation with other satellites).\n[Navigation frame] A 1500-bit packet that contains\n\nGPS date, time, satellite health\nDetailed orbital data for the satellite, accurate for the next ~4hrs\nPRN codes and status of all satellites in the network\nTakes 12.5mins to transmit\n\n[Precision code] A 6.2-terabit code for military use.\nCarrier frequencies are 1575.42 MHz (L1) and 1227.60 MHz (L2)"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-receivers",
    "href": "lecs/w01/lec01.html#global-positioning-system-receivers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Receivers",
    "text": "Global Positioning System: Receivers\n\nEach (civilian) GPS receiver:\n\nKnows the PRN codes for each satellite in advance\nCorrelates received PRN signal with database PRN signal → time shift → noisy distance to satellite\nIf 4 or more satellite PRN codes are received, it does trilateration to compute latitude and longitude"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-receivers-and-dilution-of-precision",
    "href": "lecs/w01/lec01.html#global-positioning-system-receivers-and-dilution-of-precision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Receivers and Dilution of Precision",
    "text": "Global Positioning System: Receivers and Dilution of Precision"
  },
  {
    "objectID": "lecs/w01/lec01.html#hall-effect-sensor",
    "href": "lecs/w01/lec01.html#hall-effect-sensor",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Hall Effect Sensor",
    "text": "Hall Effect Sensor\n\n\n\nVaries its voltage in response to a magnetic field\nUsed as a proximity switch, to measure a full rotation of a wheel for example\nUsed to measure rate of rotation of wheels"
  },
  {
    "objectID": "lecs/w01/lec01.html#rotary-encoder",
    "href": "lecs/w01/lec01.html#rotary-encoder",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Rotary Encoder",
    "text": "Rotary Encoder\n\nContains an analog to digital converter for encoding the angle of a shaft/motor/axle\nUsually outputs the discretized absolute angle of the shaft/motor/axle\n\n\n\nUseful in order to know where different shafts are relative to each to each other."
  },
  {
    "objectID": "lecs/w01/lec01.html#example-flippers-on-the-aqua-robot",
    "href": "lecs/w01/lec01.html#example-flippers-on-the-aqua-robot",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Example: flippers on the Aqua robot",
    "text": "Example: flippers on the Aqua robot"
  },
  {
    "objectID": "lecs/w01/lec01.html#actuators",
    "href": "lecs/w01/lec01.html#actuators",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Actuators",
    "text": "Actuators\n\n\n\n\n\n\nDC (direct current) motor\n\n\n\n\n\n\n\nServo motor\n\n\n\n\n\n\n\nStepper motor\n\n\n\n\n\n\nThey turn continuously at high RPM (revolutions per minute) when voltage is applied. Used in quadrotors and planes, model cars etc.\n\n\nUsually includes: DC motor, gears, control circuit, position feedback\nPrecise control without free rotation (e.g. robot arms, boat rudders) Limited turning range: 180 degrees\n\n\nPositioning feedback and no positioning errors.\nRotates by a predefined step angle.\nRequires external control circuit.\nPrecise control without free rotation.\nConstant holding torque without powering the motor (good for robot arms or weight-carrying systems)."
  },
  {
    "objectID": "lecs/w01/lec01.html#pulse-width-modulation",
    "href": "lecs/w01/lec01.html#pulse-width-modulation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pulse Width Modulation",
    "text": "Pulse Width Modulation\n\n\nUsed for creating analog/continuous behavior when voltage applied is discrete.\nMain idea: turn on and off the motor fast enough so average voltage is the desired target.\nUsed in dimming LEDs, controlling the speed of DC motors, controlling the position of servo motors."
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-4",
    "href": "lecs/w01/lec01.html#todays-agenda-4",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\n\n\n\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w06/lec6.html",
    "href": "lecs/w06/lec6.html",
    "title": "CSC477 - Fall 2024",
    "section": "",
    "text": "CSC477 Introduction to Mobile Robotics\nFlorian Shkurti\nWeek #6: Mapping\n\fToday’s agenda\n• How to represent maps • Probabilistic occupancy grid mapping\n\fCategories of maps\n• Metric\n• Map accurately represents lengths and angles\n• Topological\n• Map is reduced to a graph representation of the structure of free space\n• Topometric\n• Atlas: a combination of local metric maps (nodes) connected via edges\n• Sequence of raw time-series observations (e.g. video)\n• No metric or topological information directly represented by the map\n\fTypical operations on maps\n• Distance and direction to closest obstacle\n• Collision detection: is a given robot configuration in free space?\n• Map merging / alignment\n• Occupancy updates\n• Raytracing\n\fTypical operations on maps\n• Distance and direction to closest obstacle\n• Collision detection: is a given robot configuration in free space?\n• Map merging / alignment\n• Occupancy updates\nCommon operations in computer graphics\n• Raytracing\n\fMetric Maps\n\fOccupancy Grids\nEach cell contains either: • unknown/unexplored (grey) • probability of occupation\n\fOccupancy Grids\nAdvantages: • O(1) occupancy lookup and update • Supports image operations\nDisadvantages: • Doesn’t scale well in higher dimensions\nEach cell contains either: • unknown/unexplored (grey) • probability of occupation\n\fQuadtrees\nEach node represents a square. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has four children. Subdivision stops after some minimal square size.\n\fOctrees\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size.\n\fOctrees\nProblem 1: quadtrees and octrees are not balanced trees. So, in the worst case an occupancy query could be O(n) in the number of nodes.\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size.\n\fOctrees\nProblem 1: quadtrees and octrees are not balanced trees. So, in the worst case an occupancy query could be O(n) in the number of nodes.\nProblem 2: quadtrees and octrees are sensitive to small changes in the location of obstacles.\nEach node represents a cube. If the node is fully empty or fully occupied it has no children.\nIf it is partially occupied it has eight children. Subdivision stops after some minimal cube size.\n\fOctree Example: Octomap\nOpen source as a ROS package\n\fImplicit Surface Definitions: Signed Distance Function\nThis distance function is defined over any point in 3D space.\n\fSDF Example\n\fPointclouds\n\fPointclouds\nAdvantages: •\ncan make local changes to the map without affecting the pointcloud globally can align pointclouds\n• • nearest neighbor queries are\neasy with kd-trees or locality-sensitive hashing\nDisadvantages: • need to segment objects in the map •\nraytracing is approximate and nontrivial\n\fTopological Maps\nTopology: study of spatial properties that are preserved under continuous deformations of the space.\n\fGeneralized Voronoi Graph (GVG)\n\fGVG nodes: points that are equidistant to 3 or more obstacle points\nRetractions are also called roadmaps.\n\f\fGeneralized Voronoi Graphs (GVG)\nTurns comparison between pixels to comparison between graphs.\n\fGVG: sensitivity\n\fGVG: advantages\nCan specify whether we pass on the “left” or “right” of each obstacle on our way to the goal.\n\fGVG: advantages\n\fHow a curve winds around an obstacle\n\fHow a curve winds around an obstacle\nNote: winding angle of a path can be more than 360 degrees\n\fHomotopy classes\nTwo paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:\nwith\nare homotopic iff there exists a continuous function\nsuch that for any time t:\n\fHomotopy functions for deformations\nTwo paths with the same endpoints are homotopic or belong to the same homotopy class iff one can be deformed continuously (without hitting obstacles) into the other. Formally, the paths:\nwith\nare homotopic iff there exists a continuous function\nsuch that for any time t:\ngoal\nstart\n\fTopometric Maps\n\fTopometric maps\nOccupancy grid\nTopological map\nTopometric map\n\fTopometric maps\nEdges: rotations and translations between local maps, but also topological connectivity\nLocal, metric map\nMain advantage: allows us combine accurate local maps into a global, typically inconsistent map that nevertheless provides sufficient navigation information.\n\fMaps of Raw Observations\n\fMain Idea\n• Map = entire (unprocessed) sequence of observations, e.g. video.\n• Do not try to support distance, collision, and raytracing queries.\n• Instead, provide only a similarity/nearest neighbors query\n• “Find the image in the video that is most similar to the one I’m seeing now.”\n• History of observations determines a (set of) location(s) in the map\n\fMetric Map Alignment\na.k.a. scan matching, a.k.a. iterative closest point (ICP), a.k.a. registration\n\fProblem definition\n• Given\n• two pointclouds or • a (local) laser scan and a pointcloud (global map) or • two maps find the rotation and translation that aligns them\n\fProblem definition\n• Given\n• two pointclouds or • a (local) laser scan and a pointcloud (global map) or • two maps find the rotation and translation that aligns them\n• Assumption: We are assuming in these slides for simplicity that that rigid-body transformations are sufficient to align the scans. They might not be. We might need to also model scaling, non-uniform stretching and other nonlinear transformations.\n\fScan alignment with known correspondences\n\fScan alignment with known correspondences\nWhen correct correspondences are known we say that data association is known/unambiguous.\nIn general, data association is a real and hairy problem in robotics.\n\fScan alignment with known correspondences\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\n\fScan alignment with known correspondences\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\nQ: How do we minimize this error? A: Turns out it has a closed-form solution.\n\fClosed form solution of scan alignment with known correspondences\nNOT EXAMINABLE\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\nStep 1: compute the means of the two scans\nStep 2: subtract the means from the scans\nStep 3: form the matrix\n\fClosed form solution of scan alignment with known correspondences\nNOT EXAMINABLE\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\nStep 1: compute the means of the two scans\nStep 2: subtract the means from the scans\nStep 3: form the matrix\nStep 4: compute the SVD of the matrix W\nStep 5: if rank(W)=3, optimal solution is unique:\n\fClosed form solution of scan alignment with known correspondences\nFind the 3D rotation matrix R and the 3D translation vector t that will best align the corresponding points\nIf you’re interested, the proof of the closed-form solution can be found in: K. S. Arun, T. S. Huang, and S. D. Blostein. Least square fitting of two 3-d point sets. IEEE Transactions on Pattern Analysis and Machine Intelligence, 9(5):698 – 700, 1987\n\fScan alignment with unknown correspondences\n\fScan alignment with unknown correspondences\nMain idea for data association: •\nassociate each point in the source scan to its nearest neighbor in the target scan\nFind optimal rotation and translation for this correspondence.\nRepeat until no significant drop in error.\n\flibpointmatcher\n\fToday’s agenda\n• How to represent maps • Probabilistic occupancy grid mapping\n\fWhat we want to do\n\fTerminology\n• Pose: the rotation and translation of a robot\n• Odometry: the transformation of the body frame with respect to its initial pose\n(fixed frame of reference).\n• Dynamics model: what is the next state given current state and control?\n• Sensor measurement model: what is the expected measurement given the\nrobot’s current state?\n\fPerfect models vs. Reality\nDynamics\nNoise as a random variable\n\fPerfect models vs. Reality\nSensor Measurements\ne.g. GPS (simplified)\n\fPerfect models vs. Reality\nDynamics\nSensor Measurements\ne.g. GPS (simplified)\nprobabilistic dynamics model\nprobabilistic measurement model\n\fWhy is mapping a problem?\nDon’t we have all the information we need to build a map?\n• Two main sources of uncertainty:\n• accumulating uncertainty in the dynamics\nUncertainty in the dynamics compounds into increasing uncertainty in odometry, as time passes.\nStart\n\fWhy is mapping a problem?\nDon’t we have all the information we need to build a map?\n• Two main sources of uncertainty:\n• uncertainty in the dynamics\n• uncertainty in sensor measurements\n\fWhy is mapping a problem?\nDon’t we have all the information we need to build a map?\n• Two main sources of uncertainty:\n• uncertainty in the dynamics\n• uncertainty in sensor measurements\nTrue value: 300cm\nbut measurements have noise\nSonar\nLaser\n\fWhy is mapping a problem?\nDon’t we have all the information we need to build a map?\n• If we had no uncertainty, i.e. and\nthen mapping would be trivial.\n• Today we will assume perfect dynamics and odometry, but noisy sensor\nmeasurements.\n• We are also going to assume a static map, no moving objects\n\fDefining the problem\n• The occupancy grid map is a binary random variable\nwidth = #columns height = #rows of the occupancy grid\n\fDefining the problem\n• The occupancy grid map is a binary random variable\nwidth = #columns height = #rows of the occupancy grid\n• The path of the robot up to time t is a sequence of random variables\nwith\nOdometry coordinates\n\fDefining the problem\n• The occupancy grid map is a binary random variable\nwidth = #columns height = #rows of the occupancy grid\n• The path of the robot up to time t is a sequence of random variables\nwith\nOdometry coordinates\n• At each time step the robot makes a measurement (sonar/laser).\nMeasurements up to time t are a sequence of random variables\nwith\n(range, angle) in the laser’s local coordinates\nK = #beams, or #points in the scan\n\fThe goal of mapping\n• To estimate the probability of any map, given path and measurements\nSensor Measurements\nOdometry / Robot Poses\n\fThe goal of mapping\n• To estimate the probability of any map, given path and measurements\n• This is intractable. E.g. for a 100 x 100 grid there are possible\nbinary maps.\n\fThe goal of mapping\n• To estimate the probability of any map, given path and measurements\n• This is intractable. E.g. for a 100 x 100 grid there are possible\nbinary maps.\n• We can approximate\nApproximation ignores all dependencies between map cells, given known info. Assumes (for tractability) that cells are independent given path and measurements\n\fWhy is it an approximation?\nScenario\nNearby measurements\nResulting map when considering cells independently\nResulting map when considering cells jointly\n\fEvaluating the occupancy of a map cell\n• How do we evaluate ?\n\fEvaluating the occupancy of a map cell\n• How do we evaluate ?\nBayes’ Rule\nConditional Bayes’ Rule\n\fEvaluating the occupancy of a map cell\n• How do we evaluate ? • Using conditional Bayes’ rule we get\nBayes’ Rule\nConditional Bayes’ Rule\n\fEvaluating the occupancy of a map cell\n• How do we evaluate ? • Using conditional Bayes’ rule we get\n• And we simplify\nIf C is independent of A given B, then C provides no extra information about A after we know B\n\fEvaluating the occupancy of a map cell\n• How do we evaluate ? • Using conditional Bayes’ rule we get\n• And we simplify\nCurrent measurement only depends on current state and map cell\nCurrent state without current measurement provides no additional information about the occupancy of the map cell\n\fEvaluating the occupancy of a map cell\n• And we simplify:\n• Another way to write this:\n• Belief at time t-1 was updated to belief at time t based on likelihood\nof measurement received at time t.\n\fEvaluating the occupancy of a map cell\n• And we simplify:\n• Another way to write this:\nSo, as long as we can evaluate the measurement likelihood\nand the normalization factor\nwe can do the belief update.\n\fEvaluating the occupancy of a map cell\n• And we simplify:\n• Another way to write this:\nSo, as long as we can evaluate the measurement likelihood\nand the normalization factor\nwe can do the belief update.\nProblem: this is hard to compute. How can we avoid it?\n\fThe log-odds trick for binary random variables\n• We showed\n• Define the log odds ratio\n\fThe log-odds trick for binary random variables\n• We showed (1)\n• Define the log odds ratio\n\fThe log-odds trick for binary random variables\n• We showed (1)\n• Define the log odds ratio\n• Then (1) becomes\n\fThe log-odds trick for binary random variables\n• We showed (1)\n• Define the log odds ratio\n• Then (1) becomes\n• We can recover the original belief as\n\fThe log-odds trick for binary random variables\n• We showed (1)\n• Define the log odds ratio\n• Then (1) becomes\nSo, as long as we can evaluate the log odds ratio for the measurement likelihood:\nwe can do the belief update.\n\fLog-odds ratio for the measurement likelihood\n• We want to compute to do the belief update\n• We apply conditional Bayes’ rule again:\n\fLog-odds ratio for the measurement likelihood\n• We want to compute to do the belief update\n• We apply conditional Bayes’ rule again:\n• If we take the log-odds ratio:\n\fLog-odds ratio for the measurement likelihood\n• We want to compute to do the belief update\n• We apply conditional Bayes’ rule again:\n• If we take the log-odds ratio:\n• We can simplify further:\nKnowing the current state provides no information about whether cell is occupied, if there are no observations\n\fLog-odds ratio for the measurement likelihood\n• We want to compute to do the belief update\n• We apply conditional Bayes’ rule again:\n• If we take the log-odds ratio:\n• We can simplify further:\nPrior probability of cell being occupied. Can choose uniform distribution, for example.\n\fLog-odds ratio for the measurement likelihood\n• We want to compute to do the belief update\n• We apply conditional Bayes’ rule again:\n• If we take the log-odds ratio:\n• We can simplify further:\nInverse measurement model: what is the likelihood of the map cell being occupied given the current state and current measurement?\n\fSummary: Log-odds ratio for the measurement likelihood\n• We want to compute but it’s hard\n• Instead, we can compute the log-odds ratio of the measurement\nlikelihood in terms of the inverse measurement model:\nInverse measurement model: what is the likelihood of the map cell being occupied given the current state and current measurement?\n\fInverse sensor measurement model\nGiven map cell , the robot’s state , and beams\nFind index k of sensor beam that is closest in heading to the cell\n\fInverse sensor measurement model\nGiven map cell , the robot’s state , and beams\nFind index k of sensor beam that is closest in heading to the cell\nIf the cell is sufficiently closer than\n// Cell is most likely free Return that is well below 0.5\n\fInverse sensor measurement model\nGiven map cell , the robot’s state , and beams\nFind index k of sensor beam that is closest in heading to the cell\nIf the cell is sufficiently farther than or out of the field of view\n// We don’t have enough information to decide whether cell is occupied Return prior occupation probability\nIf the cell is sufficiently closer than\n// Cell is most likely free Return that is well below 0.5\n\fInverse sensor measurement model\nGiven map cell , the robot’s state , and beams\nFind index k of sensor beam that is closest in heading to the cell\nIf the cell is sufficiently farther than or out of the field of view\n// We don’t have enough information to decide whether cell is occupied Return prior occupation probability\nIf the cell is nearly as far as the measurement\n// Cell is most likely occupied Return that is well above 0.5\nIf the cell is sufficiently closer than\n// Cell is most likely free Return that is well below 0.5\n\finverse_sensor_measurement_model( , , ) From Probabilistic Robotics, chapter 9.2\n• Let be the center of the cell\n• Let\n• Let // Might need to ensure this angle difference is in\n• The index of the closest-in-heading beam to is\n• If or\n• Return the log odds ratio of the prior occupancy\n• If and\n• Return the log odds ratio of being occupied (corresponding to occupation probability &gt; 0.5)\n• If\n• Return the log odds ratio of being free (corresponding to occupation probability &lt; 0.5)\n\f• We wanted to compute the likelihood of any map based on known states and observations\nRecap\n\f• We wanted to compute the likelihood of any map based on known path and observations\nRecap\n• To evaluate we had to apply Bayes’ theorem, which\nrevealed a way to recursively update the belief\nVery frequent reasoning in probabilistic robotics\n\f• We wanted to compute the likelihood of any map based on known path and observations\nRecap\n• To evaluate we had to apply Bayes’ theorem, which\nrevealed a way to recursively update the belief\n• To avoid evaluating we used the log odds ratio\nCan do this for binary random variables\n\f• We wanted to compute the likelihood of any map based on known path and observations\nRecap\n• To evaluate we had to apply Bayes’ theorem, which\nrevealed a way to recursively update the belief\n• To avoid evaluating we used the log odds ratio\n• Computing the forward measurement model was hard, so we applied Bayes’ rule again, to get an inverse measurement model and an easier-to-compute log-odds ratio:\n\fOccupancy Grid Algorithm\n• Upon reception of a new laser/sonar/scan measurement\n• Let the robot’s current state be\n• Let the previous log-odds ratio of the occupancy belief be the 2D array where i is a row, j is a column\nIn the beginning we set the prior where the occupancy probability is a design decision.\n\fOccupancy Grid Algorithm\n• Upon reception of a new laser/sonar/scan measurement\n• Let the robot’s current state be\n• Let the previous log-odds ratio of the occupancy belief be the 2D array where i is a row, j is a column\nIn the beginning we set the prior where the occupancy probability is a design decision.\n• For all cells (i,j) in the grid\n•\nIf the cell (i,j) is in the field of view of the robot’s sensor at state\n•\nElse\n•\nIf asked, return the following 2D matrix of occupancy probabilities:\n\fResults\nThe maximum likelihood map is obtained by clipping the occupancy grid map at a threshold of 0.5"
  }
]