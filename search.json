[
  {
    "objectID": "course-grading.html",
    "href": "course-grading.html",
    "title": "Grading Scheme",
    "section": "",
    "text": "Assignment 1\n15%\n\n\nAssignment 2\n15%\n\n\nPanel Discussion\n10%\n\n\nProject Proposal\n10%\n\n\nProject Presentation\n25%\n\n\nFinal Project Report\n25%\n\n\n\n\nMarking rubric for panel discussion\nEvery week we will reserve 20-30 mins for a panel discussion based on the assigned reading for that day (4-5 papers). This discussion will include three types of roles: panel members, audience members, and a moderator. Each panel discussion will include 4 panel members, 1 moderator, and audience members. Panel members are responsible for answering questions, the audience is responsible for asking questions, and the moderator is responsible for steering the discussion and having backup questions if the audience is not asking any.\n\nPanel member evaluation\n\nAnswering questions from the moderator and the audience correctly / well (6 pts)\nEngaging with points of other panelists (1 pts)\nKeeping answers brief / allowing other people time to speak (2 pts)\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (1 pts)\n\n\n\nAudience member evaluation\n\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (10 pts)\n\n\n\nModerator evaluation\n\nSteering the discussion in terms of groups / themes of questions (2 pts)\nEnsuring there is time for every panel member to speak (4 pts)\nEngaging the audience / ensuring the audience has enough time to ask questions (3 pts)\nPre-submitting 1-2 questions on Quercus about the assigned papers of the day, the Thursday before lecture (1 pts)\n\n\n\n\nMarking rubric for the project proposal\n\nIntroduction (1 pts), which states the proposed problem being solved and any applications / implications.\nFigure or diagram (1 pts), showing an overview of your proposed solution, i.e. shows the overall idea in a way that is easily understandable without even reading the rest of the report.\nRelated work (1 pts) and bibliography. Highlight how your method is different from other approaches. Present other approaches in the proper light without diminishing their contributions.\nMethodology (2 pts). Describe your proposed methodology as well as any assumptions it relies on. Explain prerequisite concepts clearly and succinctly.\nEvaluation (2 pts). What experiments are you planning to do and why? What are the questions you want to answer through these experiments?\nTimeline (1 pts). What are the milestones required to complete your project and by when do you plan to complete them?\nAnticipated risks and mitigation plan (2 pts). What issues might arise with your proposed project and timeline and how will you address these issues if they occur?\n\n\n\nMarking rubric for the project presentation\n\nQuality of presentation\n\nSlide design (2 pts)\nDelivery of presentation (3 pts)\nRespecting time constraints (2 pts)\nResponse to questions (3 pts)\n\n\n\nTechnical content\n\nMotivation and definition of the problem (2 pts)\nPutting prior work into context (3 pts)\nMethodology explanation (3 pts)\nDiscussion of experiments (5 pts)\nDiscussion of limitations (2 pts)\n\n\n\n\nMarking rubric for the final project report\n\nAbstract (2 pts) that summarizes the main idea of the project and your contributions.\nIntroduction (3 pts) that states the problem being solved and any applications / implications.\nFigure or diagram (2 pts) that shows the overall idea in a way that is easily understandable.\nRelated work (2 pts) and bibliography. Highlight how your method is different from other approaches. Present other approaches in the proper light without diminishing their contributions.\nMethodology (7 pts). Describe your method in detail as well as any assumptions it relies on. Explain prerequisite concepts clearly and succinctly. Include algorithm descriptions, figures, and equations as you wish.\nEvaluation (8 pts). Include any figures or tables that illustrate your experimental results. Do not forget to include error bars if applicable. Analyze your findings, and comment on their statistical significance. In your evaluation please take into account Joelle Pineau’s ML reproducibility checklist.\nLimitations (2 pts). Describe some settings in which your approach performs poorly, and list a few ideas for how to adddress them. Describe opportunities for future work, as well as open problems.\nConclusions (1 pts). A summary of your contributions and results."
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda",
    "href": "lecs/w01/lec01.html#todays-agenda",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#your-tas",
    "href": "lecs/w01/lec01.html#your-tas",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Your TAs",
    "text": "Your TAs\n\n\nYewon Lee\nMSc student\nComputer Science, UofT\ncsc477-tas@cs.toronto.edu\n\nYasasa Abeysirigoonawardena\nMSc student\nComputer Science, UofT\n\ncsc477-tas@cs.toronto.edu\n\nRadian Gondokaryono\nPhD student\nComputer Science, UofT\n\ncsc477-tas@cs.toronto.edu"
  },
  {
    "objectID": "lecs/w01/lec01.html#my-lab-robot-vision-and-learning-rvl",
    "href": "lecs/w01/lec01.html#my-lab-robot-vision-and-learning-rvl",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "My lab: Robot Vision and Learning (RVL)",
    "text": "My lab: Robot Vision and Learning (RVL)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMission: create algorithms that enable robots to learn to act intelligently in outdoor environments and alongside humans"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics\n\n\n\n\n\n\nMars Exploration Rover\n\n\n\n\n \n\n\n\n\n\nRoboCup, small-sized league"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-1",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics"
  },
  {
    "objectID": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-2",
    "href": "lecs/w01/lec01.html#how-i-became-interested-in-robotics-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "How I became interested in robotics",
    "text": "How I became interested in robotics"
  },
  {
    "objectID": "lecs/w01/lec01.html#today-you-have",
    "href": "lecs/w01/lec01.html#today-you-have",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today you have",
    "text": "Today you have"
  },
  {
    "objectID": "lecs/w01/lec01.html#factory-automation",
    "href": "lecs/w01/lec01.html#factory-automation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Factory Automation",
    "text": "Factory Automation\n\n\n\n\n\nAutonomous warehouse robots at Amazon\n\n\n\n\n\n\nAutonomous arms at Tesla"
  },
  {
    "objectID": "lecs/w01/lec01.html#pipe-inspection",
    "href": "lecs/w01/lec01.html#pipe-inspection",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pipe Inspection",
    "text": "Pipe Inspection\n\nManually-controlled inspection robots"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Fukushima Daiichi, 2011"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup-1",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Fukushima Daiichi, 2011"
  },
  {
    "objectID": "lecs/w01/lec01.html#nuclear-disaster-cleanup-2",
    "href": "lecs/w01/lec01.html#nuclear-disaster-cleanup-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Nuclear Disaster Cleanup",
    "text": "Nuclear Disaster Cleanup\n\nRemote-controlled cleaning robot at Chernobyl, 1986"
  },
  {
    "objectID": "lecs/w01/lec01.html#aerial-package-delivery",
    "href": "lecs/w01/lec01.html#aerial-package-delivery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Aerial Package Delivery",
    "text": "Aerial Package Delivery"
  },
  {
    "objectID": "lecs/w01/lec01.html#aerial-first-aid-delivery",
    "href": "lecs/w01/lec01.html#aerial-first-aid-delivery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Aerial First-Aid Delivery",
    "text": "Aerial First-Aid Delivery"
  },
  {
    "objectID": "lecs/w01/lec01.html#smart-wheelchairs",
    "href": "lecs/w01/lec01.html#smart-wheelchairs",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Smart Wheelchairs",
    "text": "Smart Wheelchairs"
  },
  {
    "objectID": "lecs/w01/lec01.html#robot-surgery",
    "href": "lecs/w01/lec01.html#robot-surgery",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Robot Surgery",
    "text": "Robot Surgery\ndaVinci robot-assisted surgery"
  },
  {
    "objectID": "lecs/w01/lec01.html#precision-agriculture",
    "href": "lecs/w01/lec01.html#precision-agriculture",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Precision Agriculture",
    "text": "Precision Agriculture\n\nfarmbot.io"
  },
  {
    "objectID": "lecs/w01/lec01.html#self-driving-trucks",
    "href": "lecs/w01/lec01.html#self-driving-trucks",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Self-driving Trucks",
    "text": "Self-driving Trucks"
  },
  {
    "objectID": "lecs/w01/lec01.html#mining-operations",
    "href": "lecs/w01/lec01.html#mining-operations",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Mining Operations",
    "text": "Mining Operations"
  },
  {
    "objectID": "lecs/w01/lec01.html#oil-spill-containment",
    "href": "lecs/w01/lec01.html#oil-spill-containment",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Oil Spill Containment",
    "text": "Oil Spill Containment\n\nBP Deepwater Horizon Spill, Gulf of Mexico, 2010"
  },
  {
    "objectID": "lecs/w01/lec01.html#autonomy-vs.-remote-control",
    "href": "lecs/w01/lec01.html#autonomy-vs.-remote-control",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Autonomy vs. Remote Control",
    "text": "Autonomy vs. Remote Control\n\nQ: When is full or partial autonomy necessary?\nQ: When is remote control preferred?"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-1",
    "href": "lecs/w01/lec01.html#todays-agenda-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\n\n\n\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#prerequisites",
    "href": "lecs/w01/lec01.html#prerequisites",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\n\nSoftware Engineering\n\nLoops, conditionals, classes, modularity\nLists, hash maps/dictionaries, trees\nThreads, callbacks, remote procedure calls, serialization\n\nLinear Algebra\n\nMatrix multiplication and inversion, determinant\nSolving systems of equations, Gaussian elimination\nMatrix decompositions: Cholesky, QR\nLeast squares\n\nBasic Probability Theory\n\nMultivariate distributions, especially Gaussians\nConditional probability, Bayes’ rule\nMaximum likelihood estimation"
  },
  {
    "objectID": "lecs/w01/lec01.html#prerequisites-1",
    "href": "lecs/w01/lec01.html#prerequisites-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Prerequisites",
    "text": "Prerequisites\nCurrently\nRequired: CSC209H5; STA256H5; MAT223H5/MAT240H5; MAT232H5; CSC376\nRecommended: MAT224H5; CSC384H5; CSC311H5;"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments",
    "href": "lecs/w01/lec01.html#assignments",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "4 Assignments",
    "text": "4 Assignments\n\n~80% coding and the rest theory\nStarter code will be provided\nBonus questions will be provided\nAccepted languages: Python, C++\nYou’re going to learn ROS (Robot Operating System) and use the Gazebo simulator\nYou’re also going to learn numpy and scipy\nAbout 2 weeks to work on each"
  },
  {
    "objectID": "lecs/w01/lec01.html#ros-gazebo-simulation",
    "href": "lecs/w01/lec01.html#ros-gazebo-simulation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "ROS + Gazebo simulation",
    "text": "ROS + Gazebo simulation"
  },
  {
    "objectID": "lecs/w01/lec01.html#quizzes",
    "href": "lecs/w01/lec01.html#quizzes",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "7 Quizzes",
    "text": "7 Quizzes\n\n5-10 mins to complete them\nNot cumulative in terms of material. They cover only one lecture\nMeant to check whether you have understood basic concepts"
  },
  {
    "objectID": "lecs/w01/lec01.html#evaluation",
    "href": "lecs/w01/lec01.html#evaluation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Evaluation",
    "text": "Evaluation\nCSC477\n\n4 assignments, 15% each = 60%\n7 quizzes, 2% each = 14%\n1 final exam = 26%\n\n\nCSC2630\n\n3 assignments, 15% each = 45%\n7 quizzes, 2% each = 14%\n1 final project = 41%"
  },
  {
    "objectID": "lecs/w01/lec01.html#recommended-textbooks-optional",
    "href": "lecs/w01/lec01.html#recommended-textbooks-optional",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Recommended Textbooks (optional)",
    "text": "Recommended Textbooks (optional)"
  },
  {
    "objectID": "lecs/w01/lec01.html#recommended-online-courses-optional",
    "href": "lecs/w01/lec01.html#recommended-online-courses-optional",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Recommended Online Courses (optional)",
    "text": "Recommended Online Courses (optional)\n\nMaterial is related to 477 but not identical\nI will post links on Quercus to specific lectures that are relevant\n\n\f\n\nhttps://www.udacity.com/course/artificial-intelligence-for-robotics--cs373\nhttps://www.edx.org/course/autonomous-mobile-robots-ethx-amrx-1\nhttps://underactuated.mit.edu/ (more advanced, little overlap with 477)"
  },
  {
    "objectID": "lecs/w01/lec01.html#office-hours-zoom",
    "href": "lecs/w01/lec01.html#office-hours-zoom",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Office Hours (Zoom)",
    "text": "Office Hours (Zoom)\n\nFlorian: Thursdays 3-4pm\nYewon: Tuesdays 11-12pm\nYasasa: Fridays 11-12pm\n\n\f\n\nOffice hours will begin next week"
  },
  {
    "objectID": "lecs/w01/lec01.html#online-communication",
    "href": "lecs/w01/lec01.html#online-communication",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Online communication",
    "text": "Online communication\n\nUse Quercus\nPlease check your course-related email frequently\nEmail us at csc477-instructor@cs.toronto.edu and csc477-tas@cs.toronto.edu\nAnonymous feedback about anything course-related: https://www.surveymonkey.com/r/H8QH65F"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-2",
    "href": "lecs/w01/lec01.html#todays-agenda-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\n\n\n\nTopics covered by the course\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#covered-qquad-qquad-qquad-not-covered",
    "href": "lecs/w01/lec01.html#covered-qquad-qquad-qquad-not-covered",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Covered \\(\\qquad \\qquad \\qquad\\) Not Covered",
    "text": "Covered \\(\\qquad \\qquad \\qquad\\) Not Covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-1",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\n\n\n\n\nMain question: what is the next state given the curent state and controls?"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-2",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\n\n\n\n\nMain question: what are the controls that will take the system from state A to B?"
  },
  {
    "objectID": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control",
    "href": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Not covered in CSC477, but related: learning for control",
    "text": "Not covered in CSC477, but related: learning for control"
  },
  {
    "objectID": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control-1",
    "href": "lecs/w01/lec01.html#not-covered-in-csc477-but-related-learning-for-control-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Not covered in CSC477, but related: learning for control",
    "text": "Not covered in CSC477, but related: learning for control"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-3",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-4",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-4",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered\n\nKnown: robot’s position and orientation\nWant to estimate: a map of the environment from laser measurements\n\n\n\n\n\n\n\n\nOccupancy grid mapping"
  },
  {
    "objectID": "lecs/w01/lec01.html#main-topics-to-be-covered-5",
    "href": "lecs/w01/lec01.html#main-topics-to-be-covered-5",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Main topics to be covered",
    "text": "Main topics to be covered"
  },
  {
    "objectID": "lecs/w01/lec01.html#orb-slam-video",
    "href": "lecs/w01/lec01.html#orb-slam-video",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "orb slam video",
    "text": "orb slam video\nhttps://www.youtube.com/watch?v=_9VcvGybsDA"
  },
  {
    "objectID": "lecs/w01/lec01.html#lecture-topics-qquad-qquad-tutorials",
    "href": "lecs/w01/lec01.html#lecture-topics-qquad-qquad-tutorials",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Lecture topics \\(\\qquad \\qquad\\) Tutorials",
    "text": "Lecture topics \\(\\qquad \\qquad\\) Tutorials\n\n\n\n\n\n\nIntro to the Robot Operating System (ROS)\nRefresher on linear algebra and least squares\nRefresher on basic probability and continuous distributions\nHow to align 3D pointclouds. Demo of the PCL library\nHow to implement a Kalman Filter\nHow to implement a Particle Filter\nHow to approximate functions"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-1",
    "href": "lecs/w01/lec01.html#assignments-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\nA1: Designing a feedback controller for wall-following"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-2",
    "href": "lecs/w01/lec01.html#assignments-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n\n\n\nA1: Designing a feedback controller for wall-following\n\nA2: Implementing path-planning and feedback control algorithms"
  },
  {
    "objectID": "lecs/w01/lec01.html#assignments-3",
    "href": "lecs/w01/lec01.html#assignments-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\n\n   \n\n\nA1: Designing a feedback controller for wall-following\n\nA2: Implementing path-planning and feedback control algorithms\n\nA3: Occupancy grid mapping with known robot location\nA4: Localization in a known map using particle filters"
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-3",
    "href": "lecs/w01/lec01.html#todays-agenda-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\n\n\n\nSensors and Actuators\nQuiz about background and interests"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-and-actuators",
    "href": "lecs/w01/lec01.html#sensors-and-actuators",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors and Actuators",
    "text": "Sensors and Actuators\n\nSensors:\n\nCharacteristics and types\nMeasurement noise\nRequired bandwidth\n\n\n\f\n\nActuators:\n\nTypes of motors\nPulse-Width Modulation"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors",
    "href": "lecs/w01/lec01.html#sensors",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors",
    "text": "Sensors\n\nDevices that can sense and measure physical properties of the environment.\nKey phenomenon is transduction (conversion of energy from one form to another). E.g.:\n\nImaging sensors: light to pixel voltages\nDepth sensors: mechanical pressure to voltage\n\nMeasurements are noisy, and difficult to interpret"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-general-characteristics",
    "href": "lecs/w01/lec01.html#sensors-general-characteristics",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors: general characteristics",
    "text": "Sensors: general characteristics\n\nSensitivity: (change of output) ÷ (change of input)\nLinearity: constancy of (output ÷ input)\nMeasurement range: [min, max] or {min, max}\nResponse time: time required for input change to cause output change\nAccuracy: difference between measurement and actual\nRepeatability/Drift: difference between repeated measures\nResolution: smallest observable increment\nBandwidth: required rate of data transfer\nSNR: signal-to-noise ratio"
  },
  {
    "objectID": "lecs/w01/lec01.html#sensors-vision",
    "href": "lecs/w01/lec01.html#sensors-vision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Sensors: vision",
    "text": "Sensors: vision\n\n\n\n\n\nCCD image sensor\n\n\n\nCCD (charge-coupled device) imaging sensors:\n\nCapacitor array accumulates electric charge proportional to light intensity.\nEach capacitor’s charge is transferred to its neighbor.\nLast capacitor’s charge gets amplified and output as voltage.\n(+) High-quality, low-noise images\n(-) Higher power consumption\n(-) Slow readout\n(-) Specialized fabrication\n\nvoltage → analog-to-digital converter → pixel value in {0, 255}\nCMOS (complementary metal-oxide semi-conductor) imaging sensors:\n\nOne amplifier per pixel\n(+) Low power\n(+) Fast readout\n(+) Easier to fabricate\n(-) Poor low-light sensitivity\n(-) Higher noise"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-vs.-rolling-shutter",
    "href": "lecs/w01/lec01.html#global-vs.-rolling-shutter",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global vs. Rolling Shutter",
    "text": "Global vs. Rolling Shutter\nShutter = mechanism that allows light to hit the imaging sensor\nShutter “speed” = Exposure time = time duration in which the sensor is exposed to light\n\n\n\n\n\n\n\nRolling shutter"
  },
  {
    "objectID": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera",
    "href": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Reading RGB images from a camera",
    "text": "Reading RGB images from a camera\n\n\n\nEach pixel contains an intensity value from 0…255\n\n\n\n\n\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels"
  },
  {
    "objectID": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera-1",
    "href": "lecs/w01/lec01.html#reading-rgb-images-from-a-camera-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Reading RGB images from a camera",
    "text": "Reading RGB images from a camera\n\n\n\nEach pixel contains an intensity value from 0…255\n\n\n\n\n\n\\(\\to\\) A matrix of 600 x 1000 x 3 = ~ 1.8 million numbers\n\n\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels\n\n\n\n\n\n\n\n600 x 1000 pixels"
  },
  {
    "objectID": "lecs/w01/lec01.html#computerrobot-vision",
    "href": "lecs/w01/lec01.html#computerrobot-vision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Computer/robot vision",
    "text": "Computer/robot vision\n\n\n\n\n\nStructured numbers\n\n\n\n\n\n\nI’m seeing a parrot\nI’m seeing a toy bicycle\nThe parrot is riding the bicycle\nThe bicycle is on top of a desk\nIs this physically plausible?\nWhere is the parrot in 3D w.r.t. the camera?\nWhere will the parrot go next?\nWhat is the speed of the parrot?\n\nConclusions/Inference/Deduction/Estimation"
  },
  {
    "objectID": "lecs/w01/lec01.html#camera-lenses",
    "href": "lecs/w01/lec01.html#camera-lenses",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Camera lenses",
    "text": "Camera lenses\n\n\n\nLens determines:\n\nimage distortion\nfocus\nsharpness or blur\n\nLens characteristics:\n\nfocal length\naperture\ndepth-of-field"
  },
  {
    "objectID": "lecs/w01/lec01.html#pinhole-camera-model",
    "href": "lecs/w01/lec01.html#pinhole-camera-model",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pinhole Camera Model",
    "text": "Pinhole Camera Model\n\n\nWe know approximately how a 3D point (X,Y,Z) projects to pixel (x,y)\nWe call this the pinhole projection model"
  },
  {
    "objectID": "lecs/w01/lec01.html#perspective-projection-xy-𝜋xyz",
    "href": "lecs/w01/lec01.html#perspective-projection-xy-𝜋xyz",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(1) Perspective projection [x,y] = 𝜋(X,Y,Z)",
    "text": "(1) Perspective projection [x,y] = 𝜋(X,Y,Z)\n\n\n\nhttp://www.cim.mcgill.ca/%7Elanger/558.html\n\nBy similar triangles: x/f = X/Z\nSo, x = f * X/Z and similarly y = f * Y/Z\nProblem: we just lost depth (Z) information by doing this projection, i.e. depth is now uncertain."
  },
  {
    "objectID": "lecs/w01/lec01.html#lens-distortion",
    "href": "lecs/w01/lec01.html#lens-distortion",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(2) Lens distortion",
    "text": "(2) Lens distortion"
  },
  {
    "objectID": "lecs/w01/lec01.html#estimating-parameters-of-lens-distortion",
    "href": "lecs/w01/lec01.html#estimating-parameters-of-lens-distortion",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "(2) Estimating parameters of lens distortion",
    "text": "(2) Estimating parameters of lens distortion"
  },
  {
    "objectID": "lecs/w01/lec01.html#non-pinhole-cameras-thin-lens-model",
    "href": "lecs/w01/lec01.html#non-pinhole-cameras-thin-lens-model",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Non-pinhole cameras: thin lens model",
    "text": "Non-pinhole cameras: thin lens model\n\n\n\n\n\n\nUnlike the pinhole camera, this is able to model blur.\n\n\n\n\n\n\n\nhttp://www.cim.mcgill.ca/%7Elanger/558.html"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-1",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras\n\nDrawback: Doesn’t work underwater"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-2",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-infrared-cameras-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: infrared cameras",
    "text": "Beyond the visible spectrum: infrared cameras"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\n\n\nMain ideas:\n\nActive sensing\nProjector emits infrared light in the scene\nInfrared sensor reads the infrared light\nDeformation of the expected pattern allows computation of the depth"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-1",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nDrawbacks:\n\nDoes not work well outdoors, sunlight saturates its measurements\nMaximum range is [0.5, 8] meters\n\nAdvantages:\n\nReal-time depth estimation at 30Hz\nCheap"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-2",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-2",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nEnabled a wave of research, applications, and video games, based on real-time skeleton tracking"
  },
  {
    "objectID": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-3",
    "href": "lecs/w01/lec01.html#beyond-the-visible-spectrum-rgbd-cameras-3",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Beyond the visible spectrum: RGBD cameras",
    "text": "Beyond the visible spectrum: RGBD cameras\n\n\nDespite their drawbacks RGBD sensors have been extensively used in robotics."
  },
  {
    "objectID": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging",
    "href": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "3D LIDAR (Light detection and ranging)",
    "text": "3D LIDAR (Light detection and ranging)\n\n\nProduces a pointcloud of 3D points and intensities\n\n(x,y,z) in the laser’s frame of reference\nIntensity is related to the material of the object that reflects the light\n\nWorks based on time-of-flight for each beam to return back to the scanner\n\nNot very robust to adverse weather conditions: rain, snow, smoke, fog etc.\nUsed in most self-driving cars today for obstacle detection. Range &lt; 100m.\n\n\n\n\nUsually around 1million points in a single pointcloud"
  },
  {
    "objectID": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging-1",
    "href": "lecs/w01/lec01.html#d-lidar-light-detection-and-ranging-1",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "2D LIDAR (Light detection and ranging)",
    "text": "2D LIDAR (Light detection and ranging)\n\n\nProduces a scan of 2D points and intensities\n\n(x,y) in the laser’s frame of reference\nIntensity is related to the material of the object that reflects the light\n\nCertain surfaces are problematic for LIDAR: e.g. glass\n\n\nLots of moving parts: motors quickly rotate the laser beam and once complete (angle bound reached) a scan is returned. I.e. points are not strictly speaking time-synchronized, even though we usually treat them as such.\n\n\n\n\nUsually around 1024 points in a single scan."
  },
  {
    "objectID": "lecs/w01/lec01.html#inertial-sensors",
    "href": "lecs/w01/lec01.html#inertial-sensors",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Inertial Sensors",
    "text": "Inertial Sensors\n\nGyroscopes, Accelerometers, Magnetometers\nInertial Measurement Unit (IMU)\nPerhaps the most important sensor for 3D navigation, along with the GPS\nWithout IMUs, plane autopilots would be much harder, if not impossible, to build"
  },
  {
    "objectID": "lecs/w01/lec01.html#gyroscopes",
    "href": "lecs/w01/lec01.html#gyroscopes",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Gyroscopes",
    "text": "Gyroscopes\n\nMeasure angular velocity in the body frame\nOften affected by noise and bias\n\n\\[\nw_\\text{measured}(t) = w_\\text{true}(t) + b_g(t) + n_g(t)\n\\]\n\nWe integrate it to get 3D orientation (Euler angles, quaternions rotation matrices), but there is drift due to noise and bias"
  },
  {
    "objectID": "lecs/w01/lec01.html#accelerometers",
    "href": "lecs/w01/lec01.html#accelerometers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Accelerometers",
    "text": "Accelerometers\n\nMeasure linear acceleration relative to freefall (measured in g)\nA free-falling accelerometer in a vacuum would measure zero g\nAn accelerometer resting on the surface of the earth would measure 1g\nAlso affected by bias and noise.\nDouble integration to get position is very noisy. Errors grow quadratically with time."
  },
  {
    "objectID": "lecs/w01/lec01.html#magnetometers",
    "href": "lecs/w01/lec01.html#magnetometers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Magnetometers",
    "text": "Magnetometers\n\n\nDrawbacks:\n\nNeeds careful calibration\nNeeds to be placed away from moving metal parts, motors\n\nAdvantages:\n\nCan be used as a compass for absolute heading"
  },
  {
    "objectID": "lecs/w01/lec01.html#inertial-measurement-unit",
    "href": "lecs/w01/lec01.html#inertial-measurement-unit",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Inertial Measurement Unit",
    "text": "Inertial Measurement Unit\n\nCombines measurements from accelerometer, gyroscope, and magnetometer to output an estimate of orientation with reduced drift.\nDoes not typically provide a position estimate, due to double integration.\nRuns at 100-1000Hz\nExpect yaw drift of 5-10 deg/hour on most modern low-end IMUs"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-satellites",
    "href": "lecs/w01/lec01.html#global-positioning-system-satellites",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Satellites",
    "text": "Global Positioning System: Satellites\n\nEach GPS satellite periodically transmits:\n[Coarse/Acquisition code] A 1023-bit pseudorandom binary sequence (PRN code), which repeats every 1 ms, unique for each satellite (no correlation with other satellites).\n[Navigation frame] A 1500-bit packet that contains\n\nGPS date, time, satellite health\nDetailed orbital data for the satellite, accurate for the next ~4hrs\nPRN codes and status of all satellites in the network\nTakes 12.5mins to transmit\n\n[Precision code] A 6.2-terabit code for military use.\nCarrier frequencies are 1575.42 MHz (L1) and 1227.60 MHz (L2)"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-receivers",
    "href": "lecs/w01/lec01.html#global-positioning-system-receivers",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Receivers",
    "text": "Global Positioning System: Receivers\n\nEach (civilian) GPS receiver:\n\nKnows the PRN codes for each satellite in advance\nCorrelates received PRN signal with database PRN signal → time shift → noisy distance to satellite\nIf 4 or more satellite PRN codes are received, it does trilateration to compute latitude and longitude"
  },
  {
    "objectID": "lecs/w01/lec01.html#global-positioning-system-receivers-and-dilution-of-precision",
    "href": "lecs/w01/lec01.html#global-positioning-system-receivers-and-dilution-of-precision",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Global Positioning System: Receivers and Dilution of Precision",
    "text": "Global Positioning System: Receivers and Dilution of Precision"
  },
  {
    "objectID": "lecs/w01/lec01.html#hall-effect-sensor",
    "href": "lecs/w01/lec01.html#hall-effect-sensor",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Hall Effect Sensor",
    "text": "Hall Effect Sensor\n\n\n\nVaries its voltage in response to a magnetic field\nUsed as a proximity switch, to measure a full rotation of a wheel for example\nUsed to measure rate of rotation of wheels"
  },
  {
    "objectID": "lecs/w01/lec01.html#rotary-encoder",
    "href": "lecs/w01/lec01.html#rotary-encoder",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Rotary Encoder",
    "text": "Rotary Encoder\n\nContains an analog to digital converter for encoding the angle of a shaft/motor/axle\nUsually outputs the discretized absolute angle of the shaft/motor/axle\n\n\n\nUseful in order to know where different shafts are relative to each to each other."
  },
  {
    "objectID": "lecs/w01/lec01.html#example-flippers-on-the-aqua-robot",
    "href": "lecs/w01/lec01.html#example-flippers-on-the-aqua-robot",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Example: flippers on the Aqua robot",
    "text": "Example: flippers on the Aqua robot"
  },
  {
    "objectID": "lecs/w01/lec01.html#actuators",
    "href": "lecs/w01/lec01.html#actuators",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Actuators",
    "text": "Actuators\n\n\n\n\n\n\nDC (direct current) motor\n\n\n\n\n\n\n\nServo motor\n\n\n\n\n\n\n\nStepper motor\n\n\n\n\n\n\nThey turn continuously at high RPM (revolutions per minute) when voltage is applied. Used in quadrotors and planes, model cars etc.\n\n\nUsually includes: DC motor, gears, control circuit, position feedback\nPrecise control without free rotation (e.g. robot arms, boat rudders) Limited turning range: 180 degrees\n\n\nPositioning feedback and no positioning errors.\nRotates by a predefined step angle.\nRequires external control circuit.\nPrecise control without free rotation.\nConstant holding torque without powering the motor (good for robot arms or weight-carrying systems)."
  },
  {
    "objectID": "lecs/w01/lec01.html#pulse-width-modulation",
    "href": "lecs/w01/lec01.html#pulse-width-modulation",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Pulse Width Modulation",
    "text": "Pulse Width Modulation\n\n\nUsed for creating analog/continuous behavior when voltage applied is discrete.\nMain idea: turn on and off the motor fast enough so average voltage is the desired target.\nUsed in dimming LEDs, controlling the speed of DC motors, controlling the position of servo motors."
  },
  {
    "objectID": "lecs/w01/lec01.html#todays-agenda-4",
    "href": "lecs/w01/lec01.html#todays-agenda-4",
    "title": "CSC477 / CSC2630 Introduction to Mobile Robotics",
    "section": "Today’s agenda",
    "text": "Today’s agenda\n\n\nIntroduction\nAdministrivia\n\nOffice hours\nTutorials\nAssignment descriptions\nPrerequisites\n\nTopics covered by the course\nSensors and Actuators\n\n\n\nQuiz about background and interests"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-schedule.html",
    "href": "course-schedule.html",
    "title": "Fall 2024 - CSC477/CSC2630: Introduction to Mobile Robotics",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nPrepare\nSlides\nNotebooks\nAssignments\nProject\n\n\n\n\n1\nSep 14\nIntroduction\n📖\n🖥️\n\n\n\n\n\n\n\nSensors and Actuators\n📖\n\n\n\n\n\n\n2\nSep 21\nKinematics\n📖\n🖥️\n\n\n\n\n\n\n\nDynamics\n📖\n\n\n\n\n\n\n3\nSep 28\nPID Control\n📖\n🖥️\n\n\n\n\n\n\n\nArtificial Potential Fields and Obstacle Avoidance\n📖\n\n📋\n\n\n\n\n4\nOct 5\nPlanning\n📖\n🖥️\n📋\n\n\n\n\n\nOct 12\nReading Week\n\n\n\n\n\n\n\n5\nOct 19\nLinear Quadratic Regulator (LQR)\n\n🖥️\n\n\n\n\n\n6\nOct 26\nMap Representations and Map Alignment\n\n🖥️\n\n\n📂\n\n\n\n\nOccupancy Grid Mapping With Known Robot Poses\n\n\n\n\n\n\n\n7\nNov 2\nMaximum Likelihood, Least Squares Estimation, Maximum A Posteriori Estimation\n📖\n🖥️\n📋\n\n\n\n\n\n\nGraphSLAM\n📖\n\n📋\n\n\n\n\n8\nNov 9\nKalman Filter\n\n🖥️\n\n\n\n\n\n\n\nBayes’ Filter and Kalman Filter\n\n\n\n\n\n\n\n9\nNov 16\nExtended Kalman Filter (EKF)\n📖\n🖥️\n📋\n\n\n\n\n10\nNov 23\nParticle Filter\n📖\n🖥️\n📋\n\n\n\n\n\n\nImitation with a human in the loop\n📖\n\n📋\n\n\n\n\n\n\nTeleoperation\n📖\n\n📋\n\n\n\n\n11\nNov 30\nCamera Optics and Multi-view Geometry\n📖\n🖥️\n📋\n\n\n\n\n\n\nCausal confusion in imitation learning\n📖\n\n📋\n\n\n\n\n12\nDec 7\nVisual odometry and Visual SLAM\n📖\n🖥️\n📋\n\n\n\n\n\n\nGeneralization and safety guarantees for imitation\n📖\n\n📋\n\n\n\n\n13\nDec 8\nStudy break, beginning of exams",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fall 2024 - CSC477/CSC2630: Introduction to Mobile Robotics",
    "section": "",
    "text": "Course Overview\nThis cross-listed course (undergraduate version CSC477H, graduate version CSC2630H) provides an introduction to robotic systems from a computational perspective. A robot is regarded as an intelligent computer that can use sensors and act on the world. We will consider the definitional problems in robotics and look at how they are being solved in practice and by the research community. The emphasis is on algorithms, probabilistic reasoning, optimization, inference mechanisms, and behavior strategies, as opposed to electromechanical systems design. This course aims to help students improve their probabilistic modeling skills and instill the idea that a robot that explicitly accounts for its uncertainty works better than a robot that does not.\n\n\nPrerequisites\nRequired: CSC209H5; STA256H5; MAT223H5/MAT240H5; MAT232H5; CSC376\nRecommended: MAT224H5; CSC384H5; CSC311H5;\n\n\nCourse Delivery Details\n\nLectures: Wednesdays @ 3-5pm ET, MN3190 & Livstreamed on Zoom at MY580\nTutorials: Wednesdays @ 5-6pm ET, DH2020 & Livstreamed on Zoom at MY580\nOffice Hours will be delivered on Zoom. In-person office hours can be arranged by appointment.\nZoom links & Announcements will be posted on Quercus\nDiscussions will take place on Piazza\nAnonymous feedback form for suggested improvements\nCourse Syllabus",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "NOTE.html",
    "href": "NOTE.html",
    "title": "CSC477 - Fall 2024",
    "section": "",
    "text": "Index page - following quercus link give error and say it is no longer supported - piazza link leads to just defauly piazza page\nSchedule - for tutorials, noticed it was in slide format, so ask prof wether he would want it to also be converted to qmd slides"
  },
  {
    "objectID": "NOTE.html#publishing-pages",
    "href": "NOTE.html#publishing-pages",
    "title": "CSC477 - Fall 2024",
    "section": "Publishing pages",
    "text": "Publishing pages\n\nsince gh-page branch is not set up need to follow below instructions\n\ngit checkout –orphan gh-pages git reset –hard # make sure all changes are committed before running this! -&gt; git reset means resetting the current branch to the most recent commit git commit –allow-empty -m “Initialising gh-pages branch” git push origin gh-pages"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html",
    "href": "ae/ae-2-dcbikeshare.html",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-2-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-2-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#data",
    "href": "ae/ae-2-dcbikeshare.html#data",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")\n\nSee AE 1 for the first part of this analysis."
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-2-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 1\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 2\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#modeling",
    "href": "ae/ae-2-dcbikeshare.html#modeling",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 6\nUsing the data you filtered in Exercise 5, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-2-dcbikeshare.html#synthesis",
    "href": "ae/ae-2-dcbikeshare.html#synthesis",
    "title": "AE 2: Bike rentals in DC (continued)",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 7\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-0-movies.html",
    "href": "ae/ae-0-movies.html",
    "title": "Movie budgets and revenues",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is a demo only. You do not have a corresponding repository for it and you’re not expected to turn in anything for it.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(tidyverse) # for data analysis and visualisation\nlibrary(scales)    # for pretty axis labels\nlibrary(DT)        # for interactive table"
  },
  {
    "objectID": "ae/ae-0-movies.html#data",
    "href": "ae/ae-0-movies.html#data",
    "title": "Movie budgets and revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies\n\n# A tibble: 7,668 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.2 e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.3 e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# … with 7,658 more rows, and 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;,\n#   company &lt;chr&gt;, runtime &lt;dbl&gt;\n\n\nThe ___ dataset has ___ observations and ___ variables."
  },
  {
    "objectID": "ae/ae-0-movies.html#analysis",
    "href": "ae/ae-0-movies.html#analysis",
    "title": "Movie budgets and revenues",
    "section": "Analysis",
    "text": "Analysis\n\nGross over time\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\nThen, we will filter for these genres and visualize the average gross revenue over time.\n\nmovies %&gt;%\n  filter(genre %in% genre_list) %&gt;% \n  group_by(genre,year) %&gt;%\n  summarise(avg_gross = mean(gross)) %&gt;%\n  ggplot(mapping = aes(x = year, y = avg_gross, color= genre)) +\n    geom_point() + \n    geom_line() +\n    scale_color_viridis_d() +\n    scale_y_continuous(labels = label_dollar()) +\n    labs(\n      x = \"Year\",\n      y = \"Average Gross Revenue (US Dollars)\",\n      color = \"Genre\",\n      title = \"Gross Revenue Over Time\"\n    )\n\n`summarise()` has grouped output by 'genre'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 47 rows containing missing values (geom_point).\n\n\nWarning: Removed 23 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\n\n\nThe plot suggests …\n\n\nBudget and gross\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies %&gt;%\n  filter(genre %in% genre_list, budget &gt; 0) %&gt;% \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d() +\n  labs(\n    x = \"Log-transformed Budget\",\n    y = \"Log-transformed Gross Revenue\"\n  )\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 35 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 35 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-0-movies.html#exercises",
    "href": "ae/ae-0-movies.html#exercises",
    "title": "Movie budgets and revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nIn the remaining time, discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)?"
  },
  {
    "objectID": "ae/ae-0-movies.html#appendix",
    "href": "ae/ae-0-movies.html#appendix",
    "title": "Movie budgets and revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies %&gt;% \n  distinct(genre) %&gt;%\n  arrange(genre) %&gt;% \n  datatable()"
  },
  {
    "objectID": "ae/ae-9-odds.html",
    "href": "ae/ae-9-odds.html",
    "title": "AE 9: Odds",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-9-odds-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-9-odds.html#packages",
    "href": "ae/ae-9-odds.html#packages",
    "title": "AE 9: Odds",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nheart_disease &lt;- read_csv(here::here(\"ae\", \"data/framingham.csv\")) %&gt;%\n  select(totChol, TenYearCHD) %&gt;%\n  drop_na() %&gt;%\n  mutate(high_risk = as.factor(TenYearCHD)) %&gt;%\n  select(totChol, high_risk)"
  },
  {
    "objectID": "ae/ae-9-odds.html#linear-regression-vs.-logistic-regression",
    "href": "ae/ae-9-odds.html#linear-regression-vs.-logistic-regression",
    "title": "AE 9: Odds",
    "section": "Linear regression vs. logistic regression",
    "text": "Linear regression vs. logistic regression\nState whether a linear regression model or logistic regression model is more appropriate for each scenario:\n\nUse age and education to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "ae/ae-9-odds.html#heart-disease",
    "href": "ae/ae-9-odds.html#heart-disease",
    "title": "AE 9: Odds",
    "section": "Heart disease",
    "text": "Heart disease\n\nData: Framingham study\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to use the total cholesterol to predict if a randomly selected adult is high risk for heart disease in the next 10 years.\n\nhigh_risk:\n\n1: High risk of having heart disease in next 10 years\n0: Not high risk of having heart disease in next 10 years\n\ntotChol: total cholesterol (mg/dL)\n\n\n\nOutcome: high_risk\n\nggplot(data = heart_disease, aes(x = high_risk)) + \n  geom_bar() + \n  scale_x_discrete(labels = c(\"1\" = \"High risk\", \"0\" = \"Low risk\")) +\n  labs(\n    title = \"Distribution of 10-year risk of heart disease\", \n    x = NULL)\n\n\n\n\n\n\n\n\n\nheart_disease %&gt;%\n  count(high_risk)\n\n# A tibble: 2 × 2\n  high_risk     n\n  &lt;fct&gt;     &lt;int&gt;\n1 0          3555\n2 1           635\n\n\n\n\nCalculating probability and odds\n\nWhat is the probability a randomly selected person in the study is not high risk for heart disease?\nWhat are the odds a randomly selected person in the study is not high risk for heart disease?\n\n\n\nLogistic regression model\nFit a logistic regression model to understand the relationship between total cholesterol and risk for heart disease.\nLet \\(pi\\) be the probability an adult is high risk. The statistical model is\n\\[\\log\\Big(\\frac{\\pi_i}{1-\\pi_i}\\Big) = \\beta_0 + \\beta_1 TotChol_i\\]\n\nheart_disease_fit &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  fit(high_risk ~ totChol, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) %&gt;% kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-2.894\n0.230\n-12.607\n0\n\n\ntotChol\n0.005\n0.001\n5.268\n0\n\n\n\n\n\n\nWrite the regression equation. Round to 3 digits.\n\n\n\nCalculating log-odds, odds and probabilities\nBased on the model, if a randomly selected person has a total cholesterol of 250 mg/dL,\n\nWhat are the log-odds they are high risk for heart disease?\nWhat are the odds they are high risk for heart disease?\nWhat is the probability they are high risk for heart disease? Use the odds to calculate your answer.\n\n\n\nComparing observations\nSuppose a person’s cholesterol changes from 250 mg/dL to 200 mg/dL.\n\nHow do you expect the log-odds that this person is high risk for heart disease to change?\nHow do you expect the odds that this person is high risk for heart disease to change?"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html",
    "href": "ae/ae-1-dcbikeshare.html",
    "title": "AE 02: Bike rentals in DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-1-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 02: Bike rentals in DC",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#data",
    "href": "ae/ae-1-dcbikeshare.html#data",
    "title": "AE 02: Bike rentals in DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\nggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250)\n\n\n\n\n\n\n\nggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nExercise 2\nDescribe the distribution of daily bike rentals and the distribution of temperature based on the visualizations created in Exercise 1. Include the shape, center, spread, and presence of any potential outliers.\n[Add your answer here]\n\n\nExercise 3\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n[Add your answer here]\n\n\nExercise 4\nDescribe the relationship between daily bike rentals and temperature based on the visualization created in Exercise 1. Comment on how we expect the number of bike rentals to change as the temperature increases.\n[Add your answer here]\n\n\nExercise 5\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe the best fit for the data? Why or why not?\nNo."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 6\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 7\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 8\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 9\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#modeling",
    "href": "ae/ae-1-dcbikeshare.html#modeling",
    "title": "AE 02: Bike rentals in DC",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 10\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 11\nUsing the data you filtered in Exercise 10, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here\n\n\n\nExercise 12\nUse the output to write out the estimated regression equation.\n[Add your answer here]\n\n\nExercise 13\nInterpret the slope in the context of the data.\n[Add your answer here]\n\n\nExercise 14\nInterpret the intercept in the context of the data.\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#synthesis",
    "href": "ae/ae-1-dcbikeshare.html#synthesis",
    "title": "AE 02: Bike rentals in DC",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 15\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]\n\nThe following exercises will be completed only if time permits.\n\n\nExercise 16\nPick another season. Based on the visualization in Exercise 8, would you expect the slope of the relationship between temperature and daily bike rentals to be smaller or larger than the slope of the model you’ve been working with so far? Explain your reasoning.\n[Add your answer here]\n\n\nExercise 17\nFor this season you picked in Exercise 16, fit a linear model for predicting daily bike rentals from temperature. Note, you will need to filter your data for this season first. Use the output to write out the estimated regression equation and interpret the slope and the intercept of this model.\n\n# add your code here\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html",
    "href": "ae/ae-6-the-office-cv.html",
    "title": "AE 6: The Office",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-6-the-office-cv-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#packages",
    "href": "ae/ae-6-the-office-cv.html#packages",
    "title": "AE 6: The Office",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#load-data",
    "href": "ae/ae-6-the-office-cv.html#load-data",
    "title": "AE 6: The Office",
    "section": "Load data",
    "text": "Load data\n\noffice_episodes &lt;- read_csv(\"data/office_episodes.csv\")"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#split-data-into-training-and-testing",
    "href": "ae/ae-6-the-office-cv.html#split-data-into-training-and-testing",
    "title": "AE 6: The Office",
    "section": "Split data into training and testing",
    "text": "Split data into training and testing\nSplit your data into testing and training sets.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#specify-model",
    "href": "ae/ae-6-the-office-cv.html#specify-model",
    "title": "AE 6: The Office",
    "section": "Specify model",
    "text": "Specify model\nSpecify a linear regression model. Call it office_spec.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#create-recipe",
    "href": "ae/ae-6-the-office-cv.html#create-recipe",
    "title": "AE 6: The Office",
    "section": "Create recipe",
    "text": "Create recipe\nCreate the recipe from class. Call it office_rec1.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#create-workflow",
    "href": "ae/ae-6-the-office-cv.html#create-workflow",
    "title": "AE 6: The Office",
    "section": "Create workflow",
    "text": "Create workflow\nCreate the workflow that brings together the model specification and recipe. Call it office_wflow1.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#cross-validation",
    "href": "ae/ae-6-the-office-cv.html#cross-validation",
    "title": "AE 6: The Office",
    "section": "Cross validation",
    "text": "Cross validation\nConduct 10-fold cross validation.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#summarize-cv-metrics",
    "href": "ae/ae-6-the-office-cv.html#summarize-cv-metrics",
    "title": "AE 6: The Office",
    "section": "Summarize CV metrics",
    "text": "Summarize CV metrics\nSummarize metrics from your CV resamples.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-6-the-office-cv.html#another-model---model-2",
    "href": "ae/ae-6-the-office-cv.html#another-model---model-2",
    "title": "AE 6: The Office",
    "section": "Another model - Model 2",
    "text": "Another model - Model 2\nCreate a different (simpler, involving fewer variables) recipe and call it office_rec2. Conduct 10-fold cross validation and summarize metrics. Describe how the two models compare to each other based on cross validation metrics."
  },
  {
    "objectID": "ae/ae-11-volcanoes.html",
    "href": "ae/ae-11-volcanoes.html",
    "title": "AE 11: Multinomial classification",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-11-volcanoes-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#packages",
    "href": "ae/ae-11-volcanoes.html#packages",
    "title": "AE 11: Multinomial classification",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(colorblindr)"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#data",
    "href": "ae/ae-11-volcanoes.html#data",
    "title": "AE 11: Multinomial classification",
    "section": "Data",
    "text": "Data\nFor this application exercise we will work with a dataset of on volcanoes. The data come from The Smithsonian Institution via TidyTuesday.\n\nvolcano &lt;- read_csv(here::here(\"ae\", \"data/volcano.csv\"))\n\nRows: 958 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): volcano_name, primary_volcano_type, last_eruption_year, country, r...\ndbl  (8): volcano_number, latitude, longitude, elevation, population_within_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFirst, a bit of data prep:\n\nvolcano &lt;- volcano %&gt;%\n  mutate(\n    volcano_type = case_when(\n      str_detect(primary_volcano_type, \"Stratovolcano\") ~ \"Stratovolcano\",\n      str_detect(primary_volcano_type, \"Shield\") ~ \"Shield\",\n      TRUE ~ \"Other\"\n    ),\n    volcano_type = fct_relevel(volcano_type, \"Stratovolcano\", \"Shield\", \"Other\")\n  ) %&gt;%\n  select(\n    volcano_type, latitude, longitude, \n    elevation, tectonic_settings, major_rock_1\n    ) %&gt;%\n  mutate(across(where(is.character), as_factor))"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#exploratory-data-analysis",
    "href": "ae/ae-11-volcanoes.html#exploratory-data-analysis",
    "title": "AE 11: Multinomial classification",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nCreate a map of volcanoes that is faceted by volcano_type.\n\n\nworld &lt;- map_data(\"world\")\n\nworld_map &lt;- ggplot() +\n  geom_polygon(\n    data = world, \n    aes(\n      x = long, y = lat, group = group),\n      color = \"white\", fill = \"gray50\", \n      size = 0.05, alpha = 0.2\n    ) +\n  theme_minimal() +\n  coord_quickmap() +\n  labs(x = NULL, y = NULL)\n\nworld_map +\n  geom_point(\n    data = volcano,\n    aes(x = longitude, y = latitude,\n        color = volcano_type, \n        shape = volcano_type),\n    alpha = 0.5\n  ) +\n  facet_wrap(~volcano_type) +\n  scale_color_OkabeIto()"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#build-a-new-model",
    "href": "ae/ae-11-volcanoes.html#build-a-new-model",
    "title": "AE 11: Multinomial classification",
    "section": "Build a new model",
    "text": "Build a new model\n\nBuild a new model that uses a recipe that includes geographic information (latitude and longitude). How does this model compare to the original? Note:\nUse the same test/train split as well as same cross validation folds. Code for these is provided below.\n\n\n# test/train split\nset.seed(1234)\n\nvolcano_split &lt;- initial_split(volcano)\nvolcano_train &lt;- training(volcano_split)\nvolcano_test  &lt;- testing(volcano_split)\n\n# cv folds\nset.seed(9876)\n\nvolcano_folds &lt;- vfold_cv(volcano_train, v = 5)\nvolcano_folds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits            id   \n  &lt;list&gt;            &lt;chr&gt;\n1 &lt;split [574/144]&gt; Fold1\n2 &lt;split [574/144]&gt; Fold2\n3 &lt;split [574/144]&gt; Fold3\n4 &lt;split [575/143]&gt; Fold4\n5 &lt;split [575/143]&gt; Fold5\n\n\nNew recipe, including geographic information:\n\nvolcano_rec2 &lt;- recipe(volcano_type ~ ., data = volcano_train) %&gt;%\n  step_other(tectonic_settings) %&gt;%\n  step_other(major_rock_1) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_center(all_predictors())\n\nOriginal model specification and new workflow:\n\nvolcano_spec &lt;- multinom_reg() %&gt;%\n  set_engine(\"nnet\")\n\nvolcano_wflow2 &lt;- workflow() %&gt;%\n  add_recipe(volcano_rec2) %&gt;%\n  add_model(volcano_spec)\n\nvolcano_wflow2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_other()\n• step_other()\n• step_dummy()\n• step_zv()\n• step_center()\n\n── Model ───────────────────────────────────────────────────────────────────────\nMultinomial Regression Model Specification (classification)\n\nComputational engine: nnet \n\n\nFit resamples:\n\nvolcano_fit_rs2 &lt;- volcano_wflow2 %&gt;%\n  fit_resamples(\n    volcano_folds, \n    control = control_resamples(save_pred = TRUE)\n    )\n\nvolcano_fit_rs2\n\n# Resampling results\n# 5-fold cross-validation \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  &lt;list&gt;            &lt;chr&gt; &lt;list&gt;           &lt;list&gt;           &lt;list&gt;            \n1 &lt;split [574/144]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n2 &lt;split [574/144]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n3 &lt;split [574/144]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [144 × 7]&gt;\n4 &lt;split [575/143]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [143 × 7]&gt;\n5 &lt;split [575/143]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 1]&gt; &lt;tibble [143 × 7]&gt;\n\n\nCollect metrics:\n\ncollect_metrics(volcano_fit_rs2)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy multiclass 0.606     5  0.0138 Preprocessor1_Model1\n2 roc_auc  hand_till  0.695     5  0.0245 Preprocessor1_Model1\n\n\nROC curves:\n\nvolcano_fit_rs2 %&gt;%\n  collect_predictions() %&gt;%\n  group_by(id) %&gt;%\n  roc_curve(\n    truth = volcano_type,\n    .pred_Stratovolcano:.pred_Other\n  ) %&gt;%\n  autoplot()"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#roc-curves",
    "href": "ae/ae-11-volcanoes.html#roc-curves",
    "title": "AE 11: Multinomial classification",
    "section": "ROC curves",
    "text": "ROC curves\n\nRecreate the ROC curve from the slides.\n\n\nfinal_fit &lt;- last_fit(\n  volcano_wflow2, \n  split = volcano_split\n  )\n\ncollect_predictions(final_fit) %&gt;%\n  roc_curve(truth = volcano_type, .pred_Stratovolcano:.pred_Other) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = .level)) +\n  geom_path(size = 1) +\n  scale_color_OkabeIto() +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\") +\n  theme_minimal() +\n  labs(color = NULL)"
  },
  {
    "objectID": "ae/ae-11-volcanoes.html#acknowledgement",
    "href": "ae/ae-11-volcanoes.html#acknowledgement",
    "title": "AE 11: Multinomial classification",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThis exercise was inspired by https://juliasilge.com/blog/multinomial-volcano-eruptions."
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Final project submission"
  },
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week 9",
    "section": "",
    "text": "Fall reading week. No lecture.\nMath assignment 2 due."
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Slides & Recordings\nIf you are interested in both groups’ research, it is worth attending or watching both lectures this week.\nIn-person lab session: text generation with transformers lab11"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Week 10 Overview\nSlides & Recordings\nTransformer video: https://www.youtube.com/watch?v=XSSTuhyAmnI\nhttps://nlp.seas.harvard.edu/2018/04/03/attention.html\nhttp://peterbloem.nl/blog/transformers\nLast year’s A3 (a seq2seq autoencoder) http://modelai.gettysburg.edu/2021/headlines/\nIn-class Exercise & Solutions\nIn-person lab session: gradcam and input gradients lab09\nFinal Project - Deadline to form project groups on Markus, and submit a project proposal"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Week 3 Overview\nGloVe embedding demo \nVideo on autodiff\nSlides & Recordings\nIn-class Exercise & Solutions\nProf. Roger Grosse’s notes on autodiff and word embeddings\nNotes on Backpropagation https://cs231n.github.io/optimization-2/\nAutomatic Differentiation in Machine Learning: a Survey (2018) https://arxiv.org/pdf/1502.05767.pdf\nIn-person lab session: numerical gradients / word embeddings lab02\nLec3 pre-recorded videos with quizzes"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Week 4 Overview\nSlides & Recordings\nDemo: Colab Notebook\nIn-class Exercise & Solutions\nIn-person lab session: classification and medical MNIST lab03\nLecture 4 pre-recorded videos and quizzes\nMath Assignment 1 posted"
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Week 7 Overview\nSlides & Recordings\nTroubleshooting Deep Neural Networks\nIn-class Exercise & Solutions\nIn-person midterm #1 which covers weeks 1-5. Held during the tutorial / lab sessions\nMath assignment 2 posted"
  },
  {
    "objectID": "weekly-material.html",
    "href": "weekly-material.html",
    "title": "Weekly Materials",
    "section": "",
    "text": "Software Installations\n\n\n\nSlides & Recordings\n\n\n\nNo tutorials/labs this week but please complete the Pre-Requisite Math Problems\nSuggested Review :\n\nLinear Algebra review \nProbability review"
  },
  {
    "objectID": "weekly-material.html#week-1",
    "href": "weekly-material.html#week-1",
    "title": "Weekly Materials",
    "section": "",
    "text": "Software Installations\n\n\n\nSlides & Recordings\n\n\n\nNo tutorials/labs this week but please complete the Pre-Requisite Math Problems\nSuggested Review :\n\nLinear Algebra review \nProbability review"
  },
  {
    "objectID": "weekly-material.html#week-2",
    "href": "weekly-material.html#week-2",
    "title": "Weekly Materials",
    "section": "Week 2",
    "text": "Week 2\n\nLecture\nSlides & Recordings\nProf. Roger Grosse’s notes on backdrop\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: PyTorch basics with linear models lab01\n\n\nQuiz\nLec2 pre-recorded videos with quizzes"
  },
  {
    "objectID": "weekly-material.html#week-3",
    "href": "weekly-material.html#week-3",
    "title": "Weekly Materials",
    "section": "Week 3",
    "text": "Week 3\n\nLecture\nGloVe embedding demo \nVideo on autodiff\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: numerical gradients / word embeddings lab02\n\n\nQuiz\nLec3 pre-recorded videos with quizzes\n\n\nAdditional Resources\nProf. Roger Grosse’s notes on autodiff and word embeddings\nNotes on Backpropagation https://cs231n.github.io/optimization-2/\nAutomatic Differentiation in Machine Learning: a Survey (2018) https://arxiv.org/pdf/1502.05767.pdf"
  },
  {
    "objectID": "weekly-material.html#week-4",
    "href": "weekly-material.html#week-4",
    "title": "Weekly Materials",
    "section": "Week 4",
    "text": "Week 4\n\nLecture\nSlides & Recordings\nDemo: Colab Notebook\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: classification and medical MNIST lab03\n\n\nQuiz\nLecture 4 pre-recorded videos and quizzes\n\n\nAssignment\nMath Assignment 1 posted"
  },
  {
    "objectID": "weekly-material.html#week-5",
    "href": "weekly-material.html#week-5",
    "title": "Weekly Materials",
    "section": "Week 5",
    "text": "Week 5\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nTutorial: how to implement SGD with momentum neural network optimization\n\n\nQuiz\nLecture 5 pre-recorded videos and quizzes\n\n\nAdditional Resources\nTaylor Series https://www.youtube.com/watch?v=3d6DsjIBzJ4"
  },
  {
    "objectID": "weekly-material.html#week-6",
    "href": "weekly-material.html#week-6",
    "title": "Weekly Materials",
    "section": "Week 6",
    "text": "Week 6\n\nLecture\nSlides & Recordings\nEnsembling code skeleton\nThe definition of differential privacy\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: optimization and differential privacy lab05\n\n\nQuiz\nLecture 6 pre-recorded videos and quizzes\n\n\nAssignment\nMath assignment 1 due"
  },
  {
    "objectID": "weekly-material.html#week-7",
    "href": "weekly-material.html#week-7",
    "title": "Weekly Materials",
    "section": "Week 7",
    "text": "Week 7\n\nLecture\nSlides & Recordings\nTroubleshooting Deep Neural Networks\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person midterm #1 which covers weeks 1-5. Held during the tutorial / lab sessions\n\n\nAssignment\nMath assignment 2 posted"
  },
  {
    "objectID": "weekly-material.html#week-8",
    "href": "weekly-material.html#week-8",
    "title": "Weekly Materials",
    "section": "Week 8",
    "text": "Week 8\n\nLecture\nSlides\nMissing recording due to technical issue\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: transfer learning and double descent lab07\n\n\nQuiz\nLecture 8 pre-recorded videos and quizzes"
  },
  {
    "objectID": "weekly-material.html#week-9",
    "href": "weekly-material.html#week-9",
    "title": "Weekly Materials",
    "section": "Week 9",
    "text": "Week 9\nFall reading week. No lecture.\nMath assignment 2 due."
  },
  {
    "objectID": "weekly-material.html#week-10",
    "href": "weekly-material.html#week-10",
    "title": "Weekly Materials",
    "section": "Week 10",
    "text": "Week 10\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: gradcam and input gradients lab09\n\n\nFinal Project\nDeadline to form project groups on Markus, and submit a project proposal\n\n\nAdditional Resources\nTransformer video: https://www.youtube.com/watch?v=XSSTuhyAmnI\nhttps://nlp.seas.harvard.edu/2018/04/03/attention.html\nhttp://peterbloem.nl/blog/transformers\nLast year’s A3 (a seq2seq autoencoder) http://modelai.gettysburg.edu/2021/headlines/"
  },
  {
    "objectID": "weekly-material.html#week-11",
    "href": "weekly-material.html#week-11",
    "title": "Weekly Materials",
    "section": "Week 11",
    "text": "Week 11\n\nLecture\nSlides & Recordings\nAutoencoder Notebook\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person midterm #2 which covers weeks 6-9. Held during the tutorial / lab sessions\n\n\nQuiz\nLecture 10 pre-recorded videos and quizzes\n\n\nFinal Project\nWritten feedback on project proposals sent by TAs and instructors."
  },
  {
    "objectID": "weekly-material.html#week-12",
    "href": "weekly-material.html#week-12",
    "title": "Weekly Materials",
    "section": "Week 12",
    "text": "Week 12\n\nLecture\nSlides & Recordings\n\n\nExercises\nIn-class Exercise & Solutions\n\n\nTutorials/Labs\nIn-person lab session: RNN text classification lab10"
  },
  {
    "objectID": "weekly-material.html#week-13",
    "href": "weekly-material.html#week-13",
    "title": "Weekly Materials",
    "section": "Week 13",
    "text": "Week 13\n\nLecture\nSlides & Recordings\nIf you are interested in both groups’ research, it is worth attending or watching both lectures this week.\n\n\nTutorials/Labs\nIn-person lab session: text generation with transformers lab11"
  },
  {
    "objectID": "weekly-material.html#week-14",
    "href": "weekly-material.html#week-14",
    "title": "Weekly Materials",
    "section": "Week 14",
    "text": "Week 14\nFinal project submission"
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Slides & Recordings\nEnsembling code skeleton\nThe definition of differential privacy\nIn-class Exercise & Solutions\nIn-person lab session: optimization and differential privacy lab05\nLecture 6 pre-recorded videos and quizzes\nMath assignment 1 due"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Week 5 Overview\nSlides & Recordings\nIn-class Exercise & Solutions\nTaylor Series https://www.youtube.com/watch?v=3d6DsjIBzJ4\nTutorial: how to implement SGD with momentum neural network optimization\nLecture 5 pre-recorded videos and quizzes"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Read the syllabus\nWeek 1 Overview\nSoftware Installations\nLecture 1 & Recordings\nNo tutorials/labs this week but please complete the Pre-Requisite Math Problems\nSuggested Review :\n\nLinear Algebra review \nProbability review"
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Week 2 Overview\nSlides & Recordings\nProf. Roger Grosse’s notes on backdrop\nNo exercises this week\nIn-person lab session: PyTorch basics with linear models lab01\nLec2 pre-recorded videos with quizzes"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Slides & Recordings\nAutoencoder Notebook\nIn-class Exercise & Solutions\nIn-person midterm #2 which covers weeks 6-9. Held during the tutorial / lab sessions\nLecture 10 pre-recorded videos and quizzes\nFinal Project - Written feedback on project proposals sent by TAs and instructors"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Slides & Recordings\nIn-class Exercise & Solutions\nIn-person lab session: RNN text classification lab10"
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Week 8 Overview\nSlides\nMissing recording due to technical issue\nIn-class Exercise & Solutions\nIn-person lab session: transfer learning and double descent lab07\nLecture 8 pre-recorded videos and quizzes"
  },
  {
    "objectID": "ae/ae-5-the-office.html",
    "href": "ae/ae-5-the-office.html",
    "title": "AE 5: The Office",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-5-the-office-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-5-the-office.html#packages",
    "href": "ae/ae-5-the-office.html#packages",
    "title": "AE 5: The Office",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gghighlight)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-5-the-office.html#load-data",
    "href": "ae/ae-5-the-office.html#load-data",
    "title": "AE 5: The Office",
    "section": "Load data",
    "text": "Load data\n\noffice_ratings &lt;- read_csv(\"data/office_ratings.csv\")\n\nRows: 188 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): title\ndbl  (4): season, episode, imdb_rating, total_votes\ndate (1): air_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "ae/ae-5-the-office.html#exploratory-data-analysis",
    "href": "ae/ae-5-the-office.html#exploratory-data-analysis",
    "title": "AE 5: The Office",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nRecreate at least one of the exploratory visualizations from class."
  },
  {
    "objectID": "ae/ae-5-the-office.html#testtrain-split",
    "href": "ae/ae-5-the-office.html#testtrain-split",
    "title": "AE 5: The Office",
    "section": "Test/train split",
    "text": "Test/train split\nSplit your data into testing and training sets."
  },
  {
    "objectID": "ae/ae-5-the-office.html#build-a-recipe",
    "href": "ae/ae-5-the-office.html#build-a-recipe",
    "title": "AE 5: The Office",
    "section": "Build a recipe",
    "text": "Build a recipe\nBuild the recipe from class.\n\nTime permitting…"
  },
  {
    "objectID": "ae/ae-5-the-office.html#workflows-and-model-fitting",
    "href": "ae/ae-5-the-office.html#workflows-and-model-fitting",
    "title": "AE 5: The Office",
    "section": "Workflows and model fitting",
    "text": "Workflows and model fitting\nBuild the modeling workflow and fit the model to the training data after feature engineering with the recipe."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html",
    "href": "ae/ae-4-exam-1-review.html",
    "title": "AE 4: Exam 1 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-4-exam-1-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#packages",
    "href": "ae/ae-4-exam-1-review.html#packages",
    "title": "AE 4: Exam 1 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggfortify)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "href": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "title": "AE 4: Exam 1 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "href": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "title": "AE 4: Exam 1 Review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nVisualize, summarize, and describe the relationship between Party and Tip.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#modeling",
    "href": "ae/ae-4-exam-1-review.html#modeling",
    "title": "AE 4: Exam 1 Review",
    "section": "Modeling",
    "text": "Modeling\nLet’s start by fitting a model using Party to predict the Tip at this restaurant.\n\nWrite the statistical model.\nFit the regression line and write the regression equation. Name the model tips_fit and display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret the slope.\nDoes it make sense to interpret the intercept? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#inference",
    "href": "ae/ae-4-exam-1-review.html#inference",
    "title": "AE 4: Exam 1 Review",
    "section": "Inference",
    "text": "Inference\n\nInference for the slope\n\nThe following code can be used to create a bootstrap distribution for the slope (and the intercept, though we’ll focus primarily on the slope in our inference). Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\n\nset.seed(1234)\n\nboot_dist &lt;- tips %&gt;%\n  specify(Tip ~ Party) %&gt;%\n  generate(reps = 100, type = \"bootstrap\") %&gt;%\n  fit()\n\n\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the slope using bootstrapping and the percentile method and interpret it in context of the data.\n\n\n# add your code here\n\n\nConduct a hypothesis test at the equivalent significance level using permutation. State the hypotheses and the significance level you’re using explicitly. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercises 7 and 8. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\nNow repeat Exercises 7 and 8 using approaches based on mathematical models.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercise 9. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\n\nInference for a prediction\n\nBased on your model, predict the tip for a party of 4.\n\n\n# add your code here\n\n\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in Exercise 11. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\nNow construct the intervals from Exercise 12 and comment on whether your guess is confirmed.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "href": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "title": "AE 4: Exam 1 Review",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nLeverage (Outliers in x direction)\n\nWhat is the threshold used to identify observations with high leverage? Calculate the threshold and save the value as leverage_threshold.\n\n\n# add your code here\n\n\nMake a plot of the standardized residuals vs. leverage (you can do this with ggplot() or with autoplot(which = 5)). Use geom_vline() to add a vertical line to help identify points with high leverage.\n\n\n# add your code here\n\n\nLet’s dig into the data further. Which observations have high leverage? Why do these points have high leverage?\n\n\n# add your code here\n\n\n\nIdentifying outliers (outliers in y direction)\n\nMake a plot of the residuals vs. fitted values and a plot of the square root of the absolute value of standardized residuals vs. fitted (You can use autoplot(which = c(1, 3)) to display the plots side-by-side).\n\n\nHow are the plots similar? How do they differ?\nWhat is an advantage of using the plot of the residuals vs. fitted to check conditions and model diagnostics?\nWhat is an advantage of using the plot of the \\(\\sqrt{|\\text{standardized residuals}|}\\) vs. fitted to check conditions and model diagnostics?\n\n\n# add your code here\n\n\nAre there any observations that are outliers?\n\n\n# add your code here\n\n\n\nCook’s distance\n\nMake a plot to check Cook’s distance (autoplot(which = 4)). Based on this plot, are there any points that have a strong influence on the model coefficients?\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "href": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "title": "AE 4: Exam 1 Review",
    "section": "Adding another variable",
    "text": "Adding another variable\n\nAdd another variable, Alcohol, to your exploratory visualization. Describe any patterns that emerge.\n\n\n# add your code here\n\n\nFit a multiple linear regression model predicting Tip from Party and Alcohol. Display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret each of the slopes.\nDoes it make sense to interpret the intercept? Explain your reasoning.\nAccording to this model, is the rate of change in tip amount the same for various sizes of parties regardless of alcohol consumption or are they different? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#footnotes",
    "href": "ae/ae-4-exam-1-review.html#footnotes",
    "title": "AE 4: Exam 1 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html",
    "href": "ae/ae-8-rail-trail.html",
    "title": "AE 8: Rail Trail",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-8-rail-trail-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#packages-and-data",
    "href": "ae/ae-8-rail-trail.html#packages-and-data",
    "title": "AE 8: Rail Trail",
    "section": "Packages and data",
    "text": "Packages and data\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nrail_trail &lt;- read_csv(\"data/rail_trail.csv\")"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-1",
    "href": "ae/ae-8-rail-trail.html#exercise-1",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 1",
    "text": "Exercise 1\nFit a model predicting volume from hightemp and season.\n\nrt_mlr_main_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(volume ~ hightemp + season, data = rail_trail)\n\ntidy(rt_mlr_main_fit)\n\n# A tibble: 4 × 5\n  term         estimate std.error statistic       p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   -125.       71.7     -1.75  0.0841       \n2 hightemp         7.54      1.17     6.43  0.00000000692\n3 seasonSpring     5.13     34.3      0.150 0.881        \n4 seasonSummer   -76.8      47.7     -1.61  0.111        \n\n\nRecreate the following visualization which displays the three regression lines we can draw based on the results of this model.\n\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-2",
    "href": "ae/ae-8-rail-trail.html#exercise-2",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 2",
    "text": "Exercise 2\nAdd an interaction effect between hightemp and season and comment on the significance of the interaction predictors. Time permitting, visualize the interaction model as well.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-8-rail-trail.html#exercise-3",
    "href": "ae/ae-8-rail-trail.html#exercise-3",
    "title": "AE 8: Rail Trail",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model predicting volume from all available predictors.\n\nrt_full_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(volume ~ ., data = rail_trail)\n\ntidy(rt_full_fit)\n\n# A tibble: 8 × 5\n  term            estimate std.error statistic p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)        17.6      76.6      0.230 0.819  \n2 hightemp            7.07      2.42     2.92  0.00450\n3 avgtemp            -2.04      3.14    -0.648 0.519  \n4 seasonSpring       35.9      33.0      1.09  0.280  \n5 seasonSummer       24.2      52.8      0.457 0.649  \n6 cloudcover         -7.25      3.84    -1.89  0.0627 \n7 precip            -95.7      42.6     -2.25  0.0273 \n8 day_typeWeekend    35.9      22.4      1.60  0.113  \n\n\nRecreate the following visualization which displays a histogram of residuals and a normal density curve overlaid.\n\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html",
    "href": "ae/ae-12-exam-3-review.html",
    "title": "AE 12: Exam 3 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-12-exam-3-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#packages",
    "href": "ae/ae-12-exam-3-review.html#packages",
    "title": "AE 12: Exam 3 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data)\nlibrary(rms)\nlibrary(nnet)"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#data",
    "href": "ae/ae-12-exam-3-review.html#data",
    "title": "AE 12: Exam 3 Review",
    "section": "Data",
    "text": "Data\nAs part of a study of the effects of predatory intertidal crab species on snail populations, researchers measured the mean closing forces and the propodus heights of the claws on several crabs of three species.\n\n\nclaws &lt;- read_csv(here::here(\"ae\", \"data/claws.csv\"))\n\nWe will use the following variables:\n\nforce: Closing force of claw (newtons)\nheight: Propodus height (mm)\nspecies: Crab species - Cp(Cancer productus), Hn (Hemigrapsus nudus), Lb(Lophopanopeus bellus)\nlb: 1 if Lophopanopeus bellus species, 0 otherwise\nhn: 1 if Hemigrapsus nudus species, 0 otherwise\ncp: 1 if Cancer productus species, 0 otherwise\nforce_cent: mean centered force\nheight_cent: mean centered height\n\nBefore we get started, let’s make the categorical and indicator variables factors.\n\nclaws &lt;- claws %&gt;%\n  mutate(\n    species = as_factor(species),\n    lb = as_factor(lb),\n    hn = as_factor(hn),\n    cp = as_factor(cp)\n  )"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#probabilities-vs.-odds-vs.-log-odds",
    "href": "ae/ae-12-exam-3-review.html#probabilities-vs.-odds-vs.-log-odds",
    "title": "AE 12: Exam 3 Review",
    "section": "Probabilities vs. odds vs. log-odds",
    "text": "Probabilities vs. odds vs. log-odds\nWhy we use log-odds as response variable: https://sta210-s22.github.io/website/slides/lec-18.html#/do-teenagers-get-7-hours-of-sleep"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-1",
    "href": "ae/ae-12-exam-3-review.html#exercise-1",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nFill in the blanks:\n\nUse log-odds to fit the model (outcome)\nUse odds to interpret model results\nUse probabilities to make predictions for individual observations and ultimately to make classification decisions"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-2",
    "href": "ae/ae-12-exam-3-review.html#exercise-2",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose we want to use force to determine whether or not a crab is from the Lophopanopeus bellus (Lb) species. Why should we use a logistic regression model for this analysis?\n\nclaws %&gt;%\n  distinct(lb)\n\n# A tibble: 2 × 1\n  lb   \n  &lt;fct&gt;\n1 0    \n2 1"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-3",
    "href": "ae/ae-12-exam-3-review.html#exercise-3",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe will use the mean-centered variables for force in the model. The model output is below. Write the equation of the model produced by R. Don’t forget to fill in the blanks for ….\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-0.798\n0.358\n-2.233\n0.026\n-1.542\n-0.123\n\n\nforce_cent\n0.043\n0.039\n1.090\n0.276\n-0.034\n0.123\n\n\n\n\n\nLet \\(\\pi\\) be probability that a crab is from Lb species.\n\\[\n\\log\\Big(\\frac{\\hat{\\pi}}{1 - \\hat{\\pi}}\\Big) = -0.798 + 0.043 * force\\_cent\n\\]"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-4",
    "href": "ae/ae-12-exam-3-review.html#exercise-4",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nInterpret the intercept in the context of the data.\n\nmean_force &lt;- round(mean(claws$force), 2)\n\nFor crabs with average closing force (12.13 newtons), we expect odds of the crab being Lophopanopeus bellus is 0.45 (exp(-0.798))."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-5",
    "href": "ae/ae-12-exam-3-review.html#exercise-5",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nInterpret the effect of force in the context of the data.\nWhen x goes up by 1 unit, we expect y to change by (slope) units.\nFor each additional unit increase in closing force, the odds of crab being from lb species multiplies on average by a factor of 1.0439379."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-6",
    "href": "ae/ae-12-exam-3-review.html#exercise-6",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nNow let’s consider adding height_cent to the model. Fit the model that includes height_cent. Then use AIC to choose the model that best fits the data.\n\nlb_fit_2 &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  fit(lb ~ force_cent + height_cent, data = claws)\n\ntidy(lb_fit_2, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   -1.13     0.463      -2.44  0.0146  -2.17      -0.306\n2 force_cent     0.211    0.0925      2.28  0.0227   0.0563     0.424\n3 height_cent   -0.895    0.398      -2.25  0.0245  -1.82      -0.234\n\nglance(lb_fit_1)$AIC\n\n[1] 50.19535\n\nglance(lb_fit_2)$AIC\n\n[1] 44.11812"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-7",
    "href": "ae/ae-12-exam-3-review.html#exercise-7",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat do the following mean in the context of this data. Explain and calculate them.\n\nSensitivity: P(predict lb | actual lb) = 6 / 12\nSpecificity: P(predict not lb | actual not lb) = 4/ 26\nNegative predictive power: P(actual not lb | predict not lb) = 22 / 28\nPositive predictive power: P(actual lb | predict lb) = 6 / 10\n\n\n\n\nActual\nPredict lb\nPredict not lb\nTOTAL predicted\n\n\n\n\nLb\n6\n6\n12\n\n\nNot lb\n4\n22\n26\n\n\nTOTAL actual\n10\n28\n38"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-8",
    "href": "ae/ae-12-exam-3-review.html#exercise-8",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 8",
    "text": "Exercise 8\nWrite the equation of the model.\n\\[\\log\\Big(\\frac{\\hat{\\pi}_{Hn}}{\\hat{\\pi}_{Cp}}\\Big) = \\]\n\\[\\log\\Big(\\frac{\\hat{\\pi}_{Lb}}{\\hat{\\pi}_{Cp}}\\Big) = \\]"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-9",
    "href": "ae/ae-12-exam-3-review.html#exercise-9",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nInterpret the intercept for the odds a crab is Hn vs. Cp species.\nInterpret the effect of force on the odds a crab is Lb vs. Cp species."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-10",
    "href": "ae/ae-12-exam-3-review.html#exercise-10",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the effect of force on the odds a crab is in the Hn vs. Lb species.\nCAUTION: We can write an interpretation based on the estimated coefficients; however, we can’t make any inferential conclusions for this question based on the current model. We would need to refit the model with Lb as the baseline category to do so."
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#exercise-11",
    "href": "ae/ae-12-exam-3-review.html#exercise-11",
    "title": "AE 12: Exam 3 Review",
    "section": "Exercise 11",
    "text": "Exercise 11\nConditions for multinomial logistic (and logistic models as well):\n\nIndependence:\nRandomness:\nLinearity:\n\nemplogitplot1(lb ~ force, data = claws, ngroups = 10)\nemplogitplot1(lb ~ height, data = claws, ngroups = 10)\n\n\n\n\n\n\n\n\n\n\n# add code here for other species here\n\n\n\n# add code here for other species here"
  },
  {
    "objectID": "ae/ae-12-exam-3-review.html#checking-for-multicollinearity-in-logistic-and-multinomial-logistic",
    "href": "ae/ae-12-exam-3-review.html#checking-for-multicollinearity-in-logistic-and-multinomial-logistic",
    "title": "AE 12: Exam 3 Review",
    "section": "Checking for multicollinearity in logistic and multinomial logistic",
    "text": "Checking for multicollinearity in logistic and multinomial logistic\nSimilar to multiple linear regression, we can also check for multicollinearity in logistic and multinomial logistic models.\n\nUse the vif function to check for multicollinearity in logistic regression.\n\n\nThe vif function doesn’t work for the multinomial logistic regression models, so we can look at a correlation matrix of the predictors as a way to assess if the predictors are highly correlated:"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html",
    "href": "ae/ae-7-exam-2-review.html",
    "title": "AE 7: Exam 2 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-7-exam-2-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#packages",
    "href": "ae/ae-7-exam-2-review.html#packages",
    "title": "AE 7: Exam 2 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(openintro)\n\n# fix data!\nloans_full_schema &lt;- droplevels(loans_full_schema)"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#goal",
    "href": "ae/ae-7-exam-2-review.html#goal",
    "title": "AE 7: Exam 2 Review",
    "section": "Goal",
    "text": "Goal\nCreate a model for precicting interest_rate."
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#view-data",
    "href": "ae/ae-7-exam-2-review.html#view-data",
    "title": "AE 7: Exam 2 Review",
    "section": "View data",
    "text": "View data\nNote the dimensions of the data and the variable names. Review the data dictionary.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#split-data-into-training-and-testing",
    "href": "ae/ae-7-exam-2-review.html#split-data-into-training-and-testing",
    "title": "AE 7: Exam 2 Review",
    "section": "Split data into training and testing",
    "text": "Split data into training and testing\nSplit your data into testing and training sets.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#write-the-model",
    "href": "ae/ae-7-exam-2-review.html#write-the-model",
    "title": "AE 7: Exam 2 Review",
    "section": "Write the model",
    "text": "Write the model\nWrite the model for predicting interest rate (interest_rate) from debt to income ratio (debt_to_income), the term of loan (term), the number of inquiries (credit checks) into the applicant’s credit during the last 12 months (inquiries_last_12m), whether there are any bankruptcies listed in the public record for this applicant (bankrupt), and the type of application (application_type). The model should allow for the effect of to income ratio on interest rate to vary by application type.\nAdd model here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#exploration",
    "href": "ae/ae-7-exam-2-review.html#exploration",
    "title": "AE 7: Exam 2 Review",
    "section": "Exploration",
    "text": "Exploration\nExplore characteristics of the variables you’ll use for the model using the training data only.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#specify-model",
    "href": "ae/ae-7-exam-2-review.html#specify-model",
    "title": "AE 7: Exam 2 Review",
    "section": "Specify model",
    "text": "Specify model\nSpecify a linear regression model. Call it office_spec.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#create-recipe",
    "href": "ae/ae-7-exam-2-review.html#create-recipe",
    "title": "AE 7: Exam 2 Review",
    "section": "Create recipe",
    "text": "Create recipe\n\nPredict interest_rate from debt_to_income, term, inquiries_last_12m, public_record_bankrupt, and application_type.\nMean center debt_to_income.\nMake term a factor.\nCreate a new variable: bankrupt that takes on the value “no” if public_record_bankrupt is 0 and the value “yes” if public_record_bankrupt is 1 or higher. Then, remove public_record_bankrupt.\nInteract application_type with debt_to_income.\nCreate dummy variables where needed and drop any zero variance variables.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#create-workflow",
    "href": "ae/ae-7-exam-2-review.html#create-workflow",
    "title": "AE 7: Exam 2 Review",
    "section": "Create workflow",
    "text": "Create workflow\nCreate the workflow that brings together the model specification and recipe.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#cross-validation",
    "href": "ae/ae-7-exam-2-review.html#cross-validation",
    "title": "AE 7: Exam 2 Review",
    "section": "Cross validation",
    "text": "Cross validation\nConduct 10-fold cross validation.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#summarize-cv-metrics",
    "href": "ae/ae-7-exam-2-review.html#summarize-cv-metrics",
    "title": "AE 7: Exam 2 Review",
    "section": "Summarize CV metrics",
    "text": "Summarize CV metrics\nSummarize metrics from your CV resamples.\n\n# add code here\n\nWhy are we focusing on R-squared and RMSE instead of adjusted R-squared, AIC, BIC?\n[Add response here]"
  },
  {
    "objectID": "ae/ae-7-exam-2-review.html#next-steps",
    "href": "ae/ae-7-exam-2-review.html#next-steps",
    "title": "AE 7: Exam 2 Review",
    "section": "Next steps…",
    "text": "Next steps…\nDepending on time, either\n\nCreate a workflow for another model with a new recipe (omitting the interaction variable), conduct CV, do model selection between these two, and then interpret the coefficients for the selected model.\nOr interpret the coefficients for the one model you fit.\n\nMake sure to interpret the intercept and slope coefficient for at least one numerical, one categorical, and one interaction predictor."
  },
  {
    "objectID": "ae/ae-3-duke-forest.html",
    "href": "ae/ae-3-duke-forest.html",
    "title": "AE 3: Duke Forest houses",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-3-duke-forest-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#packages",
    "href": "ae/ae-3-duke-forest.html#packages",
    "title": "AE 3: Duke Forest houses",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#predict-sale-price-from-area",
    "href": "ae/ae-3-duke-forest.html#predict-sale-price-from-area",
    "title": "AE 3: Duke Forest houses",
    "section": "Predict sale price from area",
    "text": "Predict sale price from area\n\ndf_fit &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) %&gt;%\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-3-duke-forest.html#model-conditions",
    "href": "ae/ae-3-duke-forest.html#model-conditions",
    "title": "AE 3: Duke Forest houses",
    "section": "Model conditions",
    "text": "Model conditions\n\nExercise 1\nThe following code produces the residuals vs. fitted values plot for this model. Comment out the layer that defines the y-axis limits and re-create the plot. How does the plot change? Why might we want to define the limits explicitly?\n\ndf_aug &lt;- augment(df_fit$fit)\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )\n\n\n\n\n\n\n\n\n\n\nExercise 2\nImprove how the values on the axes of the plot are displayed by modifying the code below.\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html",
    "href": "ae/ae-10-flight-delays.html",
    "title": "AE 10: Flight delays",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-10-flight-delays-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#packages",
    "href": "ae/ae-10-flight-delays.html#packages",
    "title": "AE 10: Flight delays",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#data",
    "href": "ae/ae-10-flight-delays.html#data",
    "title": "AE 10: Flight delays",
    "section": "Data",
    "text": "Data\nFor this application exercise we will work with a dataset of 25,000 randomly sampled flights that departed one of three NYC airports (JFK, LGA, EWR) in 2013.\n\nflight_data &lt;- read_csv(\"data/flight-data.csv\")\n\nRows: 25000 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): origin, dest, carrier, arr_delay\ndbl  (4): dep_time, flight, air_time, distance\ndttm (1): time_hour\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nConvert arr_delay to factor with levels \"late\" (first level) and \"on_time\" (second level). This variable is our outcome and it indicates whether the flight’s arrival was more than 30 minutes.\n\n\nflight_data &lt;- flight_data %&gt;%\n  mutate(arr_delay = as.factor(arr_delay))\n\nlevels(flight_data$arr_delay)\n\n[1] \"late\"    \"on_time\"\n\n\n\nLet’s get started with some data prep: Convert all variables that are character strings to factors.\n\n\n#flight_data &lt;- flight_data %&gt;%\n#  mutate(\n#    origin = as.factor(origin),\n#    carrier = as.factor(carrier),\n#    dest = as.factor(dest)\n#    )\n\nflight_data &lt;- flight_data %&gt;%\n  #go across all columns and convert that are characters to factors\n  #go across all columns and convert if is.character = TRUE to factors\n  #go across all columns and if is.character apply as.factor\n  mutate(across(where(is.character), as.factor))"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#modeling-prep",
    "href": "ae/ae-10-flight-delays.html#modeling-prep",
    "title": "AE 10: Flight delays",
    "section": "Modeling prep",
    "text": "Modeling prep\n\nSplit the data into testing (75%) and training (25%), and save each subset.\n\n\nset.seed(222)\n\nflight_split &lt;- initial_split(flight_data)\n\nflight_train &lt;- training(flight_split)\nflight_test &lt;- testing(flight_split)\n\n\nSpecify a logistic regression model that uses the \"glm\" engine.\n\n\nflight_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\")\n\nNext, we’ll create two recipes and workflows and compare them to each other."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#model-1-everything-and-the-kitchen-sink",
    "href": "ae/ae-10-flight-delays.html#model-1-everything-and-the-kitchen-sink",
    "title": "AE 10: Flight delays",
    "section": "Model 1: Everything and the kitchen sink",
    "text": "Model 1: Everything and the kitchen sink\n\nDefine a recipe that predicts arr_delay using all variables except for flight and time_hour, which, in combination, can be used to identify a flight. Also make sure this recipe handles dummy coding as well as issues that can arise due to having categorical variables with some levels apparent in the training set but not in the testing set. Call this recipe flights_rec1.\n\n\nflights_rec1 &lt;- recipe(arr_delay ~ ., data = flight_train) %&gt;%\n  update_role(flight, time_hour, new_role = \"id\") %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())\n\n\nCreate a workflow that uses flights_rec1 and the model you specified.\n\n\nflight_wflow1 &lt;- workflow() %&gt;%\n  add_recipe(flights_rec1) %&gt;%\n  add_model(flight_spec)\n\n\nFit the this model to the training data using your workflow and display a tidy summary of the model fit.\n\n\nflight_fit1 &lt;- flight_wflow1 %&gt;%\n  fit(data = flight_train)\n\ntidy(flight_fit1)\n\n# A tibble: 119 × 5\n   term          estimate   std.error statistic   p.value\n   &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)  13.3      287.          0.0464  9.63e-  1\n 2 dep_time     -0.00164    0.0000504 -32.6     1.04e-233\n 3 air_time     -0.0349     0.00179   -19.5     1.75e- 84\n 4 distance      0.00533    0.00523     1.02    3.08e-  1\n 5 date          0.000227   0.000198    1.15    2.51e-  1\n 6 origin_JFK    0.0830     0.102       0.815   4.15e-  1\n 7 origin_LGA   -0.0360     0.0983     -0.366   7.14e-  1\n 8 dest_ACK    -12.4      287.         -0.0434  9.65e-  1\n 9 dest_ALB    -12.4      287.         -0.0433  9.65e-  1\n10 dest_ANC     -3.75     928.         -0.00404 9.97e-  1\n# … with 109 more rows\n\n\n\nPredict arr_delay for the testing data using this model.\n\n\nflight_aug1 &lt;- augment(flight_fit1, flight_test)\n\n\nPlot the ROC curve and find the area under the curve. Comment on how well you think this model has done for predicting arrival delay.\n\n\nflight_aug1 %&gt;%\n  roc_curve(\n    truth = arr_delay,\n    .pred_late\n  ) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\nflight_aug1 %&gt;%\n  roc_auc(\n    truth = arr_delay,\n    .pred_late\n  )\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.734"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#model-2-lets-be-a-bit-more-thoughtful",
    "href": "ae/ae-10-flight-delays.html#model-2-lets-be-a-bit-more-thoughtful",
    "title": "AE 10: Flight delays",
    "section": "Model 2: Let’s be a bit more thoughtful",
    "text": "Model 2: Let’s be a bit more thoughtful\n\nDefine a new recipe, flights_rec2, that, in addition to what was done in flights_rec1, adds features for day of week and month based on date and also adds indicators for all US holidays (also based on date). A list of these holidays can be found in timeDate::listHolidays(\"US\"). Once these features are added, date should be removed from the data. Then, create a new workflow, fit the same model (logistic regression) to the training data, and do predictions on the testing data. Finally, draw another ROC curve and find the area under the curve. Compare the predictive performance of this new model to the previous one. Based on the area under the curve statistic, which model does better?"
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#putting-it-altogether",
    "href": "ae/ae-10-flight-delays.html#putting-it-altogether",
    "title": "AE 10: Flight delays",
    "section": "Putting it altogether",
    "text": "Putting it altogether\n\nCreate an ROC curve that plots both models, in different colors, and adds a legend indicating which model is which."
  },
  {
    "objectID": "ae/ae-10-flight-delays.html#acknowledgement",
    "href": "ae/ae-10-flight-delays.html#acknowledgement",
    "title": "AE 10: Flight delays",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThis exercise was inspired by https://www.tidymodels.org/start/recipes/."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#data-sources",
    "href": "project-tips-resources.html#data-sources",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %&gt;%\n  count(manufacturer) %&gt;%\n  mutate(manufacturer = str_to_title(manufacturer)) %&gt;%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) %&gt;%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Fall 2024 - CSC 2626: Imitation Learning for Robotics",
    "section": "",
    "text": "Course Overview\nIn the next few decades we are going to witness millions of people, from various backgrounds and levels of technical expertise, needing to effectively interact with robotic technologies on a daily basis. As such, people will need to modify the behavior of their robots without explicitly writing code, but by providing only a small number of kinesthetic or visual demonstrations, or even natural language commands. At the same time, robots should try to infer and predict the human’s intentions and internal objectives from past interactions, in order to provide assistance before it is explicitly asked. This graduate-level course will examine some of the most important papers in imitation learning for robot control, placing more emphasis on developments in the last 10 years. Its purpose is to familiarize students with the frontiers of this research area, to help them identify open problems, and to enable them to make a research contribution.\nThis course will broadly cover the following areas:\n\nImitating the policies of demonstrators (people, expensive algorithms, optimal controllers)\nConnections between imitation learning, optimal control, and reinforcement learning\nLearning the cost functions that best explain a set of demonstrations\nShared autonomy between humans and robots for real-time control\n\n\n\nPrerequisites\nYou need to be comfortable with: introductory machine learning concepts (such as from CSC411/CSC413/ECE521 or equivalent), linear algebra, basic multivariable calculus, intro to probability. You also need to have strong programming skills in Python. Note: if you don’t meet all the prerequisites above please contact the instructor by email. Optional, but recommended: experience with neural networks, such as from CSC321, introductory-level familiarity with reinforcement learning and control.\n\n\nCourse Delivery Details\n\nLectures: In-person, Mondays @ 1pm-4pm ET, Carr Hall 404\nAnnouncements will be posted on Quercus\nDiscussions will take place on Piazza\nZoom recordings will be posted on Quercus after lectures\nAnonymous feedback form for suggested improvements"
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Instructor\n\nFlorian Shkurti is an assistant professor in computer science at the University of Toronto, where he leads the Robot Vision and Learning lab. He is a faculty member of the University of Toronto Robotics Institute, the Acceleration Consortium, and a faculty affiliate at Vector Institute. His research group develops methods that enable robots to learn to perceive, reason, plan, and act effectively and safely, particularly in dynamic environments and alongside humans. Application areas of his research include field robotics for environmental monitoring, visual navigation for autonomous vehicles, and mobile manipulation.\n\n\n\n\n\n\n\nOffice Hours\nLocation\n\n\n\n\nWednesdays 3-5pm ET\nZoom, In person office hours can be arranged by appointment\n\n\n\n\n\nTeaching Assistants\n\n\n\nTAs\nOffice Hours\nLocation\n\n\n\n\nYewoon Lee\nTuesday 11am - noon ET\nZoom\n\n\nYasasa Abeysirigoonawardena\nFriday 11am-noon ET\nZoom\n\n\nRadian Gondokaryono\nTBA\nZoom\n\n\n\nEmail : csc477-tas@cs.toronto.edu",
    "crumbs": [
      "Teaching Staff"
    ]
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Final Project Guidelines",
    "section": "",
    "text": "The project in this course is an opportunity to develop deep learning application in an area of your own choosing. It also provides the chance to complete a deep learning project that is much closer to a real-world application area, for example in medicine, finance, robotics, commerce, biology, chemistry, physics (or other sciences), social media, or other fields.\nWhile this project has some structure, you will be required to deal with the ambiguity and significant decision making that make up the life of a deep learning practitioner."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Final Project Guidelines",
    "section": "Project Proposal",
    "text": "Project Proposal\n\nLogistics\nProjects must be done in groups of 3-4. Please form groups on Markus by March 17, 10pm. Exceptions to this rule can be made only in rare cases provided there is good reason to do so. Email the instructors if this applies to you. If you do not know anyone in class feel free to post a message on Piazza. We will also set aside some time during the tutorial for students who are looking for collaborators to find each other and discuss forming a group.\nA 1-2 page project proposal is due March 21, 10pm. You will also be asked to summarize the data set that you are using for this proposal.\nEach team will submit a github repository page that describes the deep learning model built in the project. The repository should also contain the code that you wrote.\n\n\nProject Requirements\nBy default, your project must either take a sequence (of variable length) as an input, or produce a sequence as an output, or both. If you have a project proposal that does not involve sequences, please contact the instructors.\nYour model should thus involve an RNN or a Transformer component. Students who want to use methods that we have not covered in the course (e.g. diffusion models, neural ODEs) are free to do so, as long as they confirm their methodology with the instructors before they submit this project proposal. There is also flexibility for students to pursue an open research problem. If any groups want to attempt this, they need to discuss this with one of the instructors before the prject proposal deadline.\nHere are some examples of possible projects:\n\nUsing an RNN (or transformer) to classify sequences (e.g. whether a restaurant review is positive or negative)\nUsing a generative RNN to produce sequences (e.g. South Park TV scripts)\nUsing a Siamese network to determine whether two StackOverflow questions are duplicates\nPredict the next item in a sequence (e.g. Stock market)\nPredict the outcome of a patient based on some sequential factors\nPredict the dynamics of objects under contact and collision (e.g. robotics and graphics)\nGenerate molecules, or predict properties of molecules\n\nBefore choosing a project, consider whether there is data available for you. Since the project deadline is about a month away, consider tailoring your project ideas to what data is available to you.\nYou are encouraged to use transfer learning and data augmentation ideas in your project.\nYou can use deep learning packages (e.g. pytorch, huggingface). However, you should be able to explain the steps involved in the forward pass computation of your model.\n\n\nProject Proposal\nA 1-2 page project proposal is due March 21, 10pm. Please use 12-point font and standard margins. You will also be asked to summarize the data set that you are using for this proposal.\nThe proposal should:\n\nClearly describe the task that your model will perform. (2pt)\n\n2/2 for clearly describing the task using standard deep learning terminology\n1.5/2 for describing the task in a way that is understandable to the grader, but that uses non-standard terminology\n1/2 for describing the task generally (e.g. “sequence classification” without stating the exact classes)\n0/2 for a proposal that does not align with the project requirements\n\nClearly describe the model that you intend to use (2pt)\n\n2/2 for clearly describing the model using standard deep learning terminology; the grader can picture exactly how the model could be used.\n1.5/2 for describing the task in a way that is understandable to the grader, but that uses non-standard terminology\n1/2 for describing the models generally (e.g. sequence-to-sequence model, without describing which ones)\n0/2 for a model that does not align with the project requirements\n\nOutline the data set that you intend to use, and provide some statistics about the amount/type of data that is available (4pt)\n\n1 point for convincing the grader that you are able to acquire the data that you need (with the appropriate license/permission for educational use)\n1 point for convincing the grader that the type and amount of data is sufficient (e.g. via summary statistics, examples data set)\n2 points for convincing the grader that you have explored the data, and considered information about your data relevant to your model (like in A1 Q1)\n\nDiscuss any ethical implications of your model—how might the use (or misuse) of this model help or hurt people? (2pt)\n\n2/2 For a thoughtful discussion that considers the ethical implications across many groups of people (that different groups may be impacted differently).\n1/2 For a discussion that is generic, or considers the ethical implications for only one group of people.\n\nDescribe how work will be divided amongst the team members. We recommend pair-coding for parts of the project, but consider the work that it might take to load/format your data, write a first model, “overfit” to a single data point, etc… (2pt)\n\n2/2 The description provides enough detail so that if a team member is replaced, they know exactly what their responsibilities will be.\n1/2 There is clearly an attempt to describe the division of tasks, but the communication is unclear and/or only the tasks listed above are assigned.\n0/2 Only vague assertions are made (e.g. “we will divide the work equally”, “everyone will work on everything”, or “we will determine who will work on what as the project progresses).\n\nProper formatting (2pt)\n\n2/2 Proposal is 1-2 pages. The proposal is formatted so that readers can find specific information quickly (e.g. via the use of paragraphs and topic sentences)\n1/2 Proposal is slightly over the length limit. There was clearly an attempt to format the proposal, but information is still scattered in various places.\n0/2 Proposal runs extremely long. It is difficult to understand the structure of the proposal."
  },
  {
    "objectID": "project-description.html#final-project",
    "href": "project-description.html#final-project",
    "title": "Final Project Guidelines",
    "section": "Final Project",
    "text": "Final Project\n\nSubmission\nPlease submit a file called github.txt containing a link to the github repository. If your repository will be private, please email the instructors by April 7, 10pm so that TAs and instructors can be added—even if you use tokens.\n\n\nRepository Content\nThe repository should contain:\n\nThe code you used to pre-process the data, but not the data itself. It is generally a bad idea to include data in your github repository, since git is great for lots of small files, but a poor choice for sharing large files. Moreover, most groups are using data collected by other people. While you should share the source of your data, you should generally not share a copy of the data.\nThe code you used to train your model. You may opt to share model weights, or not.\nA README file with the following component:\n\n\nIntroduction that states the deep learning model that you are building\nModel:\n\nA figure/diagram of the model architecture that demonstrates understanding of the steps involved in computing the forward pass\nCount the number of parameters in the model, and a description of where the parameters come from\nExamples of how the model performs on two actual examples from the test set: one successful and one unsuccessful\n\nData:\n\nDescribe the source of your data\nProvide summary statistics of your data to help interpret your results (similar to in the proposal)\nDescribe how you transformed the data (e.g. any data augmentation techniques)\nIf appropriate to your project, describe how the train/validation/test set was split. (Note that splitting the training/validation/test set is not always straightforward!)\n\nTraining:\n\nThe training curve of your final model\nA description how you tuned hyper-parameters\n\nResults:\n\nDescribe the quantitative measure that you are using to evaluate your result\nDescribe the quantitative and qualitative results\nA justification that your implemented method performed reasonably, given the difficulty of the problem—or a hypothesis for why it doesn’t (this is extremely important)\n\nEthical Consideration:\n\nDescription of a use of the system that could give rise to ethical issues. Are there limitations of your model? Your training data?\n\nAuthors\n\nA description of how the work was split—i.e. who did what in this project.\n\n\n\n\nMarking Scheme\nHere is the marking scheme that we will use. Note that you model must be able to make reasonable predictions for your project to receive a passing project grade. In particular, without a reasonable model, you won’t be able to earn credit for Model Examples, Training Curve, Hyperparameter Tuning, Qualitative/Quantitative Results, etc.\nREADME/Writeup (70 points)\n\nIntroduction (4 points): What deep learning model are you building? We are looking for a clear and concise description that uses standard deep learning terminology. Clearly describe the type of task that you are solving, and what your input/outputs are.\nModel Figure (4 points): A figure/diagram of the model architecture that demonstrates understanding of the steps involved in computing the forward pass. We are looking to see if you understand the steps involved in the model computation (i.e. are you treating the model as a black box or do you understand what it’s doing?)\nModel Parameters(4 points): Count the number of parameters in the model, and a description of where the parameters come from. Again, we are looking to see if you understand what the model is doing, and what parameters are being tuned.\nModel Examples (4 points): Examples of how the model performs on two actual examples from the test set: one successful and one unsuccessful.\nData Source (1 point): Describe the source of your data.\nData Summary (4 points): Provide summary statistics of your data to help interpret your results, similar to in the proposal. Please review the feedback provided in the proposal for some guidance on what information is helpful for interpreting your model behaviour.\nData Transformation (3 points): Describe how you transformed the data, i.e. the steps you took to turn the data from what you downloaded, to something that a neural network can use as input. We are looking for a concise description that has just enough information for another person to replicate your process.\nData Split (2 points): If appropriate to your project, describe how the train/validation/test set was split. Note that splitting strategy is not always straightforward, so we are looking to see a split that can be justified.\nTraining Curve (4 points): The training curve of your final model. We are looking for a curve that shows both training and validation performance (if applicable). Your training curve should look reasonable for the problem that you are solving.\nHyperparamter Tuning (4 points): A description how you tuned hyper-parameters. We are looking for hyperparameter choices that makes sense.\nQuantitative Measures (2 points): A description and justification of the quantitative measure that you are using to evaluate your results. For some problems this will be straightforward. For others, please justify the measure that you chose.\nQuantitative and Qualitative Results (8 points): Describe the quantitative and qualitative results. You may choose to use a table or figure to aid in your description. We are looking for both a clear presentation, and a result that makes sense given your data summary. (As an extreme example, you should not have a result that performs worse than a model that, say, predicts the most common class.)\nJustification of Results (20 points): A justification that your implemented method performed reasonably, given the difficulty of the problem—or a hypothesis for why it doesn’t. This is extremely important. We are looking for an interpretation of the result. You may want to refer to your data summary and hyperparameter choices to make your argument.\nEthical Consideration (4 points): Description of a use of the system that could give rise to ethical issues. Are there limitations of your model? Your training data? Please review the feedback provided in the proposal for some guidance on how to think deeply about these issues.\nAuthors (2 points): A description of how the work was split—i.e. who did what in this project. If there are significant issues with the way that work is split, we may follow up with individual teams, and not award equal points to all team members.\n\nCode/Documentation (20 points) We are looking for whether TAs can generally understand what your code does, how it is organized, and the steps that needs to be taken to replicate your model and results. Your code must be in working order (otherwise the TA will not be able to replicate your results)\nAdvanced Concept (10 points). Your project involves at least one of the following:\n\nData Augmentation applied in a way that makes sense for your domain\nTransformer\nGenerative Model, Sequence-to-Sequence Architecture (e.g. that uses teacher-forcing)"
  },
  {
    "objectID": "lecs/w03/lec03.html#feedback-control",
    "href": "lecs/w03/lec03.html#feedback-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Feedback Control",
    "text": "Feedback Control\n\nMain question: what are the controls that will take the system from state A to B?"
  },
  {
    "objectID": "lecs/w03/lec03.html#example-wallline-following-at-fixed-speed",
    "href": "lecs/w03/lec03.html#example-wallline-following-at-fixed-speed",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: wall/line following at fixed speed",
    "text": "Example: wall/line following at fixed speed\n\n\n\nYou have to control the angular velocity \\(w\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#why-bother-with-wallline-following",
    "href": "lecs/w03/lec03.html#why-bother-with-wallline-following",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why bother with wall/line following?",
    "text": "Why bother with wall/line following?\n\nBecause it enables arbitrary path following where the line is the local tangent of the curved path"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-1-bang-bang-control",
    "href": "lecs/w03/lec03.html#idea-1-bang-bang-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 1: bang-bang control",
    "text": "Idea 1: bang-bang control\n\\[\n\\omega = \\begin{cases}\n\\omega_{\\text{max}} & \\text{if } \\text{CTE} &gt; 0 \\\\\n-\\omega_{\\text{max}} & \\text{if } \\text{CTE} &lt; 0 \\\\\n0\n\\end{cases}\n\\]\nWhat’s wrong with this?"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-2-proportional-p-control",
    "href": "lecs/w03/lec03.html#idea-2-proportional-p-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 2: proportional (P-)control",
    "text": "Idea 2: proportional (P-)control\n\\[\nw = K_{p}e(t)\n\\]\nWill the car reach the target line?\nWill the car overshoot the target line?\nIs the asymptotic (steady-state) error zero?"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-2-proportional-p-control-1",
    "href": "lecs/w03/lec03.html#idea-2-proportional-p-control-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 2: proportional (P-)control",
    "text": "Idea 2: proportional (P-)control\n\\[\nw = K_{p}e(t)\n\\]\n\nWill the car reach the target line? YES\nWill the car overshoot the target line? YES\nIs the asymptotic (steady-state) error zero? NO"
  },
  {
    "objectID": "lecs/w03/lec03.html#addressing-the-oscillation-problem",
    "href": "lecs/w03/lec03.html#addressing-the-oscillation-problem",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Addressing the oscillation problem",
    "text": "Addressing the oscillation problem\n\nNeed to reduce turning rate well before the line is approached\nIdea: have a small proportional gain \\(K_p\\)\nProblem: that means the car doesn’t turn very much\nIdea: need to predict the error in the near future\nThis is good, as long as the error does not oscillate at a very high frequency"
  },
  {
    "objectID": "lecs/w03/lec03.html#idea-3-proportional-derivative-pd-control",
    "href": "lecs/w03/lec03.html#idea-3-proportional-derivative-pd-control",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Idea 3: proportional-derivative (PD-)control",
    "text": "Idea 3: proportional-derivative (PD-)control\n\\[\nW = K_{p}e(t) + K_{d}\\dot e(t)\n\\]\n\nHow do we set the gains?\nWhat if there are systematic errors/biases?\nWhat if the error estimate is very noisy?"
  },
  {
    "objectID": "lecs/w03/lec03.html#handling-systematic-biases-the-integral-term",
    "href": "lecs/w03/lec03.html#handling-systematic-biases-the-integral-term",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Handling systematic biases: the integral term",
    "text": "Handling systematic biases: the integral term\n\nExamples of systematic biases:\n\nwheels are misaligned\ncar is much heavier on one side\n\nAdd integral of the error from the beginning of time: \\(\\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau\\)\n\n\n\nCan the PI-controller have nonzero error asymptotically (in steady-state)?\n\nNO. In steady state both the control \\(w_\\infty\\) and the error \\(e_\\infty\\) must be constant. If the asymptotic error is nonzero then the control is not constant: \\(\\omega_\\infty = K_p e_\\infty + K_i e_\\infty t\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-problem-integrator-windup",
    "href": "lecs/w03/lec03.html#potential-problem-integrator-windup",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential problem: integrator windup",
    "text": "Potential problem: integrator windup\n\nWhat happens if the control variable reaches the actuator’s limits?\nI.e. the car can’t turn as fast as the controller commands it.\nActuator may remain at its limit for a long time while the controller modifies its commands\nError increases, integral term winds up while controller goes back to issuing commands in the feasible region."
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-problem-integrator-windup-1",
    "href": "lecs/w03/lec03.html#potential-problem-integrator-windup-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential problem: integrator windup",
    "text": "Potential problem: integrator windup\n\nHeuristic fixes:\n\nLimit integral error values\nStop integral error while the commands are in the non feasible region\nReduce gain of integral error term"
  },
  {
    "objectID": "lecs/w03/lec03.html#pid-controller",
    "href": "lecs/w03/lec03.html#pid-controller",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "PID controller",
    "text": "PID controller\n\\[\n\\omega(t) = K_p e(t) + K_d \\dot{e}(t) + K_i \\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau\n\\]\nPerhaps the most widely used controller in industry and robotics.\nPerhaps the easiest to code.\n\f\nYou will also see it as:\n\\[\n\\omega(t) = K_p \\left[ e(t) + T_d \\dot{e}(t) + \\frac{1}{T_i} \\int_{\\tau=0}^{\\tau=t} e(\\tau) d\\tau \\right]\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-implement-pid",
    "href": "lecs/w03/lec03.html#tips-how-to-implement-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to implement PID",
    "text": "Tips: how to implement PID\n\n\nAssume time is discrete\nIdentify your error function e(t)= current_state(t)- target_state(t)\nIs the measurement of the state reliable?\nIf the measurement of the current state is very noisy you might want to smooth/filter it, using:\n\nMoving average filter with uniform weights \\[\n\\hat{x}_t = \\frac{x_t + x_{t-1} + \\ldots + x_{t-k+1}}{k} = \\hat{x}_{t-1} + \\frac{x_t - x_{t-k}}{k}\n\\]\nPotential problem: the larger the window of the filter the slower it is going to register changes.\nExponential filter \\[\n\\hat{x}_t = \\alpha \\hat{x}_{t-1} + (1 - \\alpha) x_t, \\quad \\alpha \\in [0, 1]\n\\]\nPotential problem: the closer is to 1 the slower it is going to register changes."
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-implement-pid-1",
    "href": "lecs/w03/lec03.html#tips-how-to-implement-pid-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to implement PID",
    "text": "Tips: how to implement PID\n\nApproximate the integral of error by a sum\nApproximate the derivative of error by:\n\nFinite differences \\(\\dot{e}(t_k) \\approx \\frac{e(t_k) - e(t_{k-1})}{\\delta t}\\)\nFiltered finite differences, e.g. \\(\\dot{e}(t_k) \\approx \\alpha \\dot{e}(t_{k-1}) + (1 - \\alpha) \\frac{e(t_k) - e(t_{k-1})}{\\delta t}\\)\n\nLimit the computed controls\nLimit or stop the integral term when detecting large errors and windup"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nManually:\n\nFirst, use only the proportional term. Set the other gains to zero.\nWhen you see oscillations slowly add derivative term\n\nIncreasing \\(K_d\\) increases the duration in which linear error prediction is assumed to be valid\n\nAdd a small integral gain"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-1",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nZiegler-Nichols heuristic:\n\nFirst, use only the proportional term. Set the other gains to zero.\nWhen you see consistent oscillations, record the proportional gain \\(K_u\\) and the oscillation period \\(T_u\\)"
  },
  {
    "objectID": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-2",
    "href": "lecs/w03/lec03.html#tips-how-to-tune-the-pid-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Tips: how to tune the PID",
    "text": "Tips: how to tune the PID\n\nAfter manual or Z-N tweaking you might want to use coordinate ascent to search for a better set of parameters automatically:\n\n\n\n\n\n\n\nSee Sebastian Thrun’s online class\n“AI for robotics” on Udacity for more\ndetails on this. He calls the algorithm\nTwiddle and it is in Lesson 5.\nOther names for this are\n“Self-tuning PID controllers”"
  },
  {
    "objectID": "lecs/w03/lec03.html#when-is-pid-insufficient",
    "href": "lecs/w03/lec03.html#when-is-pid-insufficient",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "When is PID insufficient?",
    "text": "When is PID insufficient?\n\nSystems with large time delays\nControllers that require completion time guarantees\n\nE.g. the system must reach target state within 2 secs\n\nSystems with high-frequency oscillations\nHigh-frequency variations on the target state"
  },
  {
    "objectID": "lecs/w03/lec03.html#example-applications-self-driving-cars",
    "href": "lecs/w03/lec03.html#example-applications-self-driving-cars",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example applications: self-driving cars",
    "text": "Example applications: self-driving cars"
  },
  {
    "objectID": "lecs/w03/lec03.html#cascading-pid",
    "href": "lecs/w03/lec03.html#cascading-pid",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Cascading PID",
    "text": "Cascading PID\n\nSometimes we have multiple error sources (e.g. multiple sensors) and one actuator to control.\nWe can use a master PID loop that sets the setpoint for the slave PID loop. Master (outer loop) runs at low rate, while slave (inner loop) runs at higher rate.\nOne way of getting hierarchical control behavior."
  },
  {
    "objectID": "lecs/w03/lec03.html#potential-fields-main-motivation",
    "href": "lecs/w03/lec03.html#potential-fields-main-motivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Potential Fields Main Motivation",
    "text": "Potential Fields Main Motivation\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?"
  },
  {
    "objectID": "lecs/w03/lec03.html#main-motivation",
    "href": "lecs/w03/lec03.html#main-motivation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main Motivation",
    "text": "Main Motivation\n\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nAssume omnidirectional robot."
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\n\n\n\n\n\n\n\\[\n\\begin{align}\nU(x) &= \\frac{1}{2}kx^2 \\\\\nF(x) &= -kx\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces-1",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\n\n\n\n\n\n\n\\[\n\\begin{align}\nU(x) &= mgx \\\\\nF(x) &= -mg\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#background-potential-energy-and-forces-2",
    "href": "lecs/w03/lec03.html#background-potential-energy-and-forces-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Background: potential energy and forces",
    "text": "Background: potential energy and forces\nIn both cases we have conversion from kinetic energy to potential energy U(x).\nIn both cases there is a force resulting from the potential field, and F(x)=-dU(x)/dx.\nThis is a general rule for conservative systems with no external forces."
  },
  {
    "objectID": "lecs/w03/lec03.html#main-motivation-1",
    "href": "lecs/w03/lec03.html#main-motivation-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main Motivation",
    "text": "Main Motivation\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields",
    "href": "lecs/w03/lec03.html#artificial-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nA: Place a repulsive potential field around obstacles"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-1",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\nQ: How do you control the robot to reach the goal state while avoiding the obstacle?\nA: Place a repulsive potential field around obstacles and an attractive potential field around the goal"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-2",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-3",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\n\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]\n\n\n \n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-1",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-2",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-3",
    "href": "lecs/w03/lec03.html#how-do-we-compute-these-distances-from-obstacles-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "How do we compute these distances from obstacles?",
    "text": "How do we compute these distances from obstacles?"
  },
  {
    "objectID": "lecs/w03/lec03.html#attractive-and-repulsive-potential-fields",
    "href": "lecs/w03/lec03.html#attractive-and-repulsive-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Attractive and Repulsive Potential Fields",
    "text": "Attractive and Repulsive Potential Fields\n\n\\(U(x) = \\alpha U\\_{\\text{attractive}}(x) + \\beta U\\_{\\text{repulsive}}(x)\\)\n\nQ1: How do we reach the goal state\nfrom an arbitrary state?\nQ2: In this example there is an unambiguous way\nto reach the goal from any state. Is this true in\ngeneral?"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]\n\n\n\n\n\\[\nF_{\\text{attractive}}(x) = -\\nabla_x U_\\text{attractive}(x) = -2(x - x_{\\text{goal}})\n\\]\n\n\n\n\n\nAttractive force makes state x go to the bottom of the potential energy bowl. Bottom=Goal = low-energy state.\n\n\n\n\n\n\nMove the robot using F=ma, for m=1: \\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]\nGradient descent down the potential bowl"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces-1",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_\\text{attractive}(x) = d(x, x_{\\text{goal}})^2\n\\]\n\n\n\n\n\\[\nF_{\\text{attractive}}(x) = -\\nabla_x U_\\text{attractive}(x) = -2(x - x_{\\text{goal}})\n\\]\n\n\n\n\n\nAttractive force makes state x go to the bottom of the potential energy bowl. Bottom=Goal = low-energy state.\n\nQ: Do you see any problems with this potential energy and force if x is far away from goal?\n\nA: The farther the robot is the stronger the force. May need to normalize the force vector. Alternatively:\n\\[\nU_{\\text{attractive}}(x) = d(x, x_{\\text{goal}}) \\Rightarrow F_{\\text{attractive}}(x) = -\\frac{(x - x_{\\text{goal}})}{d(x, x_{\\text{goal}})}\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#from-potential-fields-to-forces-2",
    "href": "lecs/w03/lec03.html#from-potential-fields-to-forces-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "From Potential Fields to Forces",
    "text": "From Potential Fields to Forces\nMake the robot move by applying forces resulting from potential fields\n\n\n\\[\nU_{\\text{repulsive}}(x) = \\begin{cases}\n\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right)^2 & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{if } d(x, \\text{obs}) \\geq r\n\\end{cases}\n\\]\n\n\n\n\n\\[\nF_{\\text{repulsive}}(x) = \\begin{cases}\n2\\left( \\frac{1}{d(x,\\text{obs})} - \\frac{1}{r} \\right) \\frac{\\nabla_x d(x,\\text{obs})}{d(x,\\text{obs})^2} & \\text{if } d(x, \\text{obs}) &lt; r \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\n\n\nRepulsive force makes state x go away from the obstacle to lower potential energy states. Free space = {low-energy states}\n\n\n\n\n\nMove the robot using F=ma, for m=1:\n\\[\n\\dot x_{t+1} = \\dot x_t + \\delta t F(x_t)\n\\]\nGradient descent until obstacle is cleared"
  },
  {
    "objectID": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces",
    "href": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining Attractive and Repulsive Forces",
    "text": "Combining Attractive and Repulsive Forces\n\nPotential energy\n\\[\nU_{\\text{total}}(x) = \\alpha U_{\\text{attractive}}(x) + \\beta U_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nresults in forces\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nmakes robot accelerate\n\\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-example",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-example",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields: Example",
    "text": "Artificial Potential Fields: Example\n\n\nAdvantages of potential fields:\n\nCan handle moving obstacles\nFast and easy to compute\nFairly reactive"
  },
  {
    "objectID": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces-1",
    "href": "lecs/w03/lec03.html#combining-attractive-and-repulsive-forces-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining Attractive and Repulsive Forces",
    "text": "Combining Attractive and Repulsive Forces\n\nPotential energy\n\\[\nU_{\\text{total}}(x) = \\alpha U_{\\text{attractive}}(x) + \\beta U_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nresults in forces\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x)\n\\]\n\n\n\n\n\nmakes robot accelerate\n\\[\n\\dot{x}_{t+1} = \\dot{x}_t + \\delta t F(x_t)\n\\]\n\nQ: What’s a possible problem\nwith addition of forces?"
  },
  {
    "objectID": "lecs/w03/lec03.html#artificial-potential-fields-4",
    "href": "lecs/w03/lec03.html#artificial-potential-fields-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Artificial Potential Fields",
    "text": "Artificial Potential Fields\n\n\n\n\n\nWhat’s the total potential here?\n\nIt’s zero. The repulsive force is exactly the opposite of the attractive force (assuming alpha = beta)\n\n\n\\[\nF_{\\text{total}}(x) = \\alpha F_{\\text{attractive}}(x) + \\beta F_{\\text{repulsive}}(x) = 0\n\\]\nProblem: gradient descent gets stuck"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Stuck",
    "text": "Local Minima on the Potential Field: Getting Stuck\nStates of zero total force correspond to local minima in the potential function:"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck-1",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-stuck-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Stuck",
    "text": "Local Minima on the Potential Field: Getting Stuck\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min"
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-randomly",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-randomly",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Unstuck Randomly",
    "text": "Local Minima on the Potential Field: Getting Unstuck Randomly\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min\nSolution #1: Do random move in case\nit helps you get unstuck."
  },
  {
    "objectID": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-by-backing-up",
    "href": "lecs/w03/lec03.html#local-minima-on-the-potential-field-getting-unstuck-by-backing-up",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Local Minima on the Potential Field: Getting Unstuck By Backing Up",
    "text": "Local Minima on the Potential Field: Getting Unstuck By Backing Up\nStates of zero total force correspond to local minima in the potential function:\n\nProblem: If you end up here gradient descent\ncan’t help you. All local moves seem\nidentical in terms of value \\(\\rightarrow\\) local min\nSolution #2: back up and get out from\nthe dead end, just like you entered it."
  },
  {
    "objectID": "lecs/w03/lec03.html#drawbacks-of-potential-fields",
    "href": "lecs/w03/lec03.html#drawbacks-of-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Drawbacks of potential fields",
    "text": "Drawbacks of potential fields\n\nLocal minima\n\nAttractive and repulsive forces can balance, so robot makes no progress.\nClosely spaced obstacles, or dead end.\n\nUnstable oscillation\n\nThe dynamics of the robot/environment system can become unstable.\nHigh speeds, narrow corridors, sudden changes"
  },
  {
    "objectID": "lecs/w03/lec03.html#avoiding-local-minima-on-the-potential-field-navigation-functions",
    "href": "lecs/w03/lec03.html#avoiding-local-minima-on-the-potential-field-navigation-functions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Avoiding Local Minima on the Potential Field: Navigation Functions",
    "text": "Avoiding Local Minima on the Potential Field: Navigation Functions\nPotential energy function \\(\\phi(x)\\) with a single global minimum at the goal, and no local minima.\nFor any state x there exists a neighboring state x’ such that \\(\\phi(x') &lt; \\phi(x)\\)\n\n\n\nSo far not used in practice very much because they are usually as hard to compute as a planned path from the current state to the goal."
  },
  {
    "objectID": "lecs/w03/lec03.html#addressing-the-drawbacks-of-potential-fields",
    "href": "lecs/w03/lec03.html#addressing-the-drawbacks-of-potential-fields",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Addressing the Drawbacks of Potential Fields",
    "text": "Addressing the Drawbacks of Potential Fields\n\nVector Field Histogram (VFH)\nDynamic Window Approach\n\nBoth methods for local obstacle avoidance"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-1",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)\n\n\n\n\n\n\n\n\n\n\n\nHigh risk for cells with high probability of being occupied.\nRisk inversely proportional to distance."
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-2",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-3",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#vfh-vector-field-histogram-4",
    "href": "lecs/w03/lec03.html#vfh-vector-field-histogram-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "VFH (Vector Field Histogram)",
    "text": "VFH (Vector Field Histogram)"
  },
  {
    "objectID": "lecs/w03/lec03.html#dwa-dynamic-window-approach",
    "href": "lecs/w03/lec03.html#dwa-dynamic-window-approach",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "DWA (Dynamic Window Approach)",
    "text": "DWA (Dynamic Window Approach)\n\n\nLocal, reactive controller\n\nSample a set of controls for x,y,theta\nSimulate where each control is going to take the robot\nEliminate those that lead to collisions.\nReward those that agree with a navigation plan.\nReward high-speeds\nReward proximity to goal.\nPick control with highest score that doesn’t lead to collision."
  },
  {
    "objectID": "lecs/w02/lec02.html#section",
    "href": "lecs/w02/lec02.html#section",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "Today’s slides borrow parts of Paul Furgale’s “Representing robot pose” presentation:\nhttp://paulfurgale.info/news/2014/6/9/representing-robot-pose-the-good-the-bad-and-the-ugly\nYou should absolutely read it."
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda",
    "href": "lecs/w02/lec02.html#todays-agenda",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n• Frames of reference\n• Ways to represent rotations\n• Simplified models of vehicles\n• Forward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#d-frames-of-reference-are-everywhere-in-robotics",
    "href": "lecs/w02/lec02.html#d-frames-of-reference-are-everywhere-in-robotics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "3D frames of reference are everywhere in robotics",
    "text": "3D frames of reference are everywhere in robotics"
  },
  {
    "objectID": "lecs/w02/lec02.html#right-handed-vs-left-handed-frames",
    "href": "lecs/w02/lec02.html#right-handed-vs-left-handed-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Right-handed vs left-handed frames",
    "text": "Right-handed vs left-handed frames\n\n\nUnless otherwise specified,\nwe use right-handed\nframes in robotics"
  },
  {
    "objectID": "lecs/w02/lec02.html#why-do-we-need-to-use-so-many-frames",
    "href": "lecs/w02/lec02.html#why-do-we-need-to-use-so-many-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why do we need to use so many frames?",
    "text": "Why do we need to use so many frames?\n\n\n\nBecause we want to reason and express quantities relative to their local configuration.\nFor example: “grab the bottle behind the cereal bowl”\nThis lecture is about defining and representing frames of reference and reasoning about how to express quantities in one frame to quantities in the other."
  },
  {
    "objectID": "lecs/w02/lec02.html#rigid-body-motion",
    "href": "lecs/w02/lec02.html#rigid-body-motion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rigid-body motion",
    "text": "Rigid-body motion\n\nMotion that can be described by a rotation and translation.\nAll the parts making up the body move in unison, and there are no deformations.\nRepresenting rotations, translations, and vectors in a given frame of reference is often a source of frustration and bugs in robot software because there are so many options."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-answer-is-meaningless-unless-i-provide-a-definition-of-the-coordinate-frames",
    "href": "lecs/w02/lec02.html#the-answer-is-meaningless-unless-i-provide-a-definition-of-the-coordinate-frames",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The answer is meaningless unless I provide a definition of the coordinate frames",
    "text": "The answer is meaningless unless I provide a definition of the coordinate frames"
  },
  {
    "objectID": "lecs/w02/lec02.html#section-2",
    "href": "lecs/w02/lec02.html#section-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "",
    "text": "Color convention\nfor frames\n\n\nMoving body (robot) frame\n\n\nFixed world frame"
  },
  {
    "objectID": "lecs/w02/lec02.html#always-provide-a-frame-diagram",
    "href": "lecs/w02/lec02.html#always-provide-a-frame-diagram",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Always provide a frame diagram",
    "text": "Always provide a frame diagram"
  },
  {
    "objectID": "lecs/w02/lec02.html#inertial-frames-of-reference",
    "href": "lecs/w02/lec02.html#inertial-frames-of-reference",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inertial frames of reference",
    "text": "Inertial frames of reference\n\nG, the global frame of reference is fixed, i.e. with zero velocity in our previous example.\nBut, in general it can move as long as it has zero acceleration. Such a frame is called an “inertial” frame of reference.\nNewton’s laws hold for inertial reference frames only. For reference frames with non-constant velocity we need the theory of General Relativity.\nSo, make sure that your global frame of reference is inertial, preferably fixed."
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda-1",
    "href": "lecs/w02/lec02.html#todays-agenda-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\n\nFrames of reference\n\n\n\nWays to represent rotations\nSimplified models of vehicles\nForward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-euler-angles",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-euler-angles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Euler Angles",
    "text": "Representing Rotations in 3D: Euler Angles"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\nNeed to specify the axes which each angle refers to.\nThere are 12 different valid combinations of fundamental rotations. Here are the possible axes:\nz-x-z, x-y-x, y-z-y, z-y-z, x-z-x, y-x-y\nx-y-z, y-z-x, z-y-x, x-z-y, z-y-x, y-x-z\n\n\n\nE.g.: x-y-z rotation with Euler angles \\((\\theta, \\phi, \\psi)\\) means the rotation can be expressed as a sequence of simple rotations \\(R_x(\\theta) R_y(\\phi) R_z(\\psi)\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-1",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\nSimple rotations can be counter-clockwise or clockwise. This gives another 2 possibilities.\n\\[\n\\mathbf{R}_z(\\alpha) :=\n\\begin{bmatrix}\n\\cos\\alpha & -\\sin\\alpha & 0 \\\\\n\\sin\\alpha & \\cos\\alpha  & 0 \\\\\n0          & 0           & 1\n\\end{bmatrix}\n\\qquad\n\\mathbf{C}_z(\\alpha) :=\n\\begin{bmatrix}\n\\cos\\alpha & \\sin\\alpha  & 0 \\\\\n-\\sin\\alpha & \\cos\\alpha & 0 \\\\\n0           & 0          & 1\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-2",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\n\nYou need to specify whether the rotation rotates from the world frame to the body frame, or the other way around.\nAnother 2 possibilities. More possibilities if you have more frames.\nDegrees or radians? Another 2 possibilities"
  },
  {
    "objectID": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-3",
    "href": "lecs/w02/lec02.html#specification-ambiguities-in-euler-angles-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Specification ambiguities in Euler Angles",
    "text": "Specification ambiguities in Euler Angles\n\nNeed to specify the ordering of the three parameters.\n1-2-3, 1-3-2, 2-1-3, 2-3-1, 3-1-2, 3-2-1\nAnother 6 different valid combinations"
  },
  {
    "objectID": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock",
    "href": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Another problem with Euler angles: Gimbal Lock",
    "text": "Another problem with Euler angles: Gimbal Lock"
  },
  {
    "objectID": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock-1",
    "href": "lecs/w02/lec02.html#another-problem-with-euler-angles-gimbal-lock-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Another problem with Euler angles: Gimbal Lock",
    "text": "Another problem with Euler angles: Gimbal Lock\n\nWhy should roboticists care about this?\nBecause when it happens Euler angle representations lose one degree of freedom.\nThey cannot represent the entire range of rotations any more.\nThey get “locked” into a subset of the space of possible rotations."
  },
  {
    "objectID": "lecs/w02/lec02.html#so-we-need-other-representations-aside-from-euler-angles.-even-though-they-are-a-minimal-representation.",
    "href": "lecs/w02/lec02.html#so-we-need-other-representations-aside-from-euler-angles.-even-though-they-are-a-minimal-representation.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "So, we need other representations aside from Euler angles. Even though they are a minimal representation.",
    "text": "So, we need other representations aside from Euler angles. Even though they are a minimal representation."
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-axis-angle",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-axis-angle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Axis-Angle",
    "text": "Representing Rotations in 3D: Axis-Angle\n\n\n\n\n\n4-number representation (angle, 3D axis)\n2 ambiguities: (-angle, -axis) is the same as (angle, axis)"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-rotation-matrix",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Rotation Matrix",
    "text": "Representing Rotations in 3D: Rotation Matrix\n\nThe royalty of rotation representations\n3x3-number representation, very redundant\nNo ambiguities, as long as source frame and target frame are specified correctly. For example, define your notation this way:\nRotation from Body frame to World frame: \\(\\mathbf{R}_{BW}\\)\nOr you can define it this way: \\(_B^W \\mathbf{R}\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#inverse-rotation-matrix",
    "href": "lecs/w02/lec02.html#inverse-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inverse Rotation Matrix",
    "text": "Inverse Rotation Matrix\n\\[\n_B^W\\mathbf{R}^{-1} = _B^W\\mathbf{R}^t = _W^B\\mathbf{R}\n\\]\nRotation matrices are orthogonal matrices: their transpose is their inverse and they do not change the length of a vector, they just rotate it in space.\n\\[{}^W_B\\mathbf{R}^{t} {}^W_B\\mathbf{R} = \\mathbf{I}\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#converting-axis-angle-to-rotation-matrix",
    "href": "lecs/w02/lec02.html#converting-axis-angle-to-rotation-matrix",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Converting axis-angle to rotation matrix",
    "text": "Converting axis-angle to rotation matrix\n\nGiven angle theta and axis v the equivalent rotation matrix is\n\n\\[\n\\mathbf{R} = \\mathbf{I}\\cos\\theta + (1 - \\cos\\theta)\\mathbf{v}\\mathbf{v}^t + [\\mathbf{v}]_\\times\n\\]\n\nWhere I is the 3x3 identity and \\[[\\mathbf{a}]_\\times \\stackrel{\\text{def}}{=} \\begin{bmatrix} 0 & -a_3 & a_2 \\\\ a_3 & 0 & -a_1 \\\\ -a_2 & a_1 & 0 \\end{bmatrix}\\]\nThis is called the “Rodrigues formula”"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-a-rotation-matrix-that-rotates-one-vector-to-another",
    "href": "lecs/w02/lec02.html#example-finding-a-rotation-matrix-that-rotates-one-vector-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding a rotation matrix that rotates one vector to another",
    "text": "Example: finding a rotation matrix that rotates one vector to another\n\n\n\n\n\\[\n_C^D\\mathbf{R} = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix}\n\\]\n\nThis matrix transforms the x-axis of frame C to the z-axis of frame D. Same for y and z axes."
  },
  {
    "objectID": "lecs/w02/lec02.html#rotation-multiplication-vs-addition-3d-vs-2d",
    "href": "lecs/w02/lec02.html#rotation-multiplication-vs-addition-3d-vs-2d",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rotation multiplication vs addition: 3D vs 2D",
    "text": "Rotation multiplication vs addition: 3D vs 2D\n\nIn 2D adding angles with wraparound at 360 degrees is a valid operation.\nRotation matrices can be added, but the result is not necessarily a valid rotation. Rotations are not closed under the operation of addition.\nRotations are closed under the operation of multiplication. To compose a sequence of simple rotations we need to multiply them."
  },
  {
    "objectID": "lecs/w02/lec02.html#compound-rotations",
    "href": "lecs/w02/lec02.html#compound-rotations",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Compound rotations",
    "text": "Compound rotations\n\n\\[\n_C^E \\mathbf{R} = _D^E \\mathbf{R} _C^D \\mathbf{R}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#representing-rotations-in-3d-quaternions",
    "href": "lecs/w02/lec02.html#representing-rotations-in-3d-quaternions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Representing Rotations in 3D: Quaternions",
    "text": "Representing Rotations in 3D: Quaternions\n\nBased on axis-angle representation, but more computationally efficient.\nThe main workhorse of rotation representations.\nUsed almost everywhere in robotics, aerospace, aviation.\nVery important to master in this course. You will need it for the first assignment and for working with ROS in general."
  },
  {
    "objectID": "lecs/w02/lec02.html#converting-axis-angle-to-quaternion",
    "href": "lecs/w02/lec02.html#converting-axis-angle-to-quaternion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Converting axis-angle to quaternion",
    "text": "Converting axis-angle to quaternion\n\nGiven angle theta and axis v the equivalent quaternion representation is\n\n\\[\n\\mathbf{q} = [\\sin(\\theta/2)v_1, \\sin(\\theta/2)v_2, \\sin(\\theta/2)v_3, \\cos(\\theta/2)]\n\\]\n\\[\\mathbf{q} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k} + w\\]\n\nJust like in the case of rotation matrices we denote the source and target frames of the rotation quaternion: \\(_B^W \\mathbf{q}\\)\n\n\n\nWe always work with unit length (normalized) quaternions."
  },
  {
    "objectID": "lecs/w02/lec02.html#examples-of-quaternions",
    "href": "lecs/w02/lec02.html#examples-of-quaternions",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Examples of quaternions",
    "text": "Examples of quaternions\n\n90 degree rotation about the z-axis\n\n\\[\n\\mathbf{q} = [0, 0, \\sin(\\pi / 4)v_3, cos(\\pi / 4)]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-multiplication",
    "href": "lecs/w02/lec02.html#quaternion-multiplication",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion multiplication",
    "text": "Quaternion multiplication\n\nDefined algebraically by\n\\[ \\begin{align}\nQ = q_0 + q_1i + q_2j q_sk \\\\\ni^2 = j^2 = k^2 = ijk = -1 \\\\\nij = k, jk = i, ki = j\n\\end{align}\n\\]\nand usually denoted by the circular cross symbol. For example:\n\\[\n_F^W\\mathbf{q} = _C^W\\mathbf{q} \\otimes {} _F^C\\mathbf{q}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-multiplication-1",
    "href": "lecs/w02/lec02.html#quaternion-multiplication-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion multiplication",
    "text": "Quaternion multiplication\n\\[{}^W_F\\mathbf{q} = {}^W_C\\mathbf{q} \\otimes {}^C_F\\mathbf{q}\\]\nDirect correspondence with matrix multiplication:\n\\[\n_F^W\\mathbf{R(q)} = _C^W\\mathbf{R(q)} _F^C\\mathbf{R(q)}\n\\]\nNOTE: the quaternion to matrix conversion will not be given here.\nIt is usually present in all numerical algebra libraries. At the moment we’ll take it for granted."
  },
  {
    "objectID": "lecs/w02/lec02.html#quaternion-inversion",
    "href": "lecs/w02/lec02.html#quaternion-inversion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Quaternion inversion",
    "text": "Quaternion inversion\n\\[\n\\mathbf{q}^{-1} = -x\\mathbf{i} - y\\mathbf{j} -z\\mathbf{k} + w\n\\]\n\n\\[\n[0,0,0,1] = \\mathbf{q}^{-1} \\otimes \\mathbf{q}\n\\]\nDirect correspondence with matrix inversion:  \\[\n\\mathbf{I} = \\mathbf{R(q^{-1})R(q)}\n\\]\n\\[\n\\mathbf{I} = \\mathbf{R(q)^{-1} R(q)}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-updating-orientation-based-on-angular-velocity",
    "href": "lecs/w02/lec02.html#example-updating-orientation-based-on-angular-velocity",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: updating orientation based on angular velocity",
    "text": "Example: updating orientation based on angular velocity\n\nIf the angular velocity of the Body frame is \\(^Bw\\) and the body-to-world rotation at time t is \\(_B^W\\mathbf{q}(t)\\)\nThen, at time t+dt the new body-to-world rotation will be \\[{}^W_{B(t+dt)}\\mathbf{q} = {}^W_{B(t)}\\mathbf{q} \\otimes {}^{B(t)}_{B(t+dt)}\\mathbf{q}\\]\n\nwhere \\({}^{B(t)}_{B(t+dt)}\\mathbf{q}\\) has unit axis \\(\\frac{{}^B\\omega}{||{}^B\\omega||}\\) and angle \\(||{}^B\\omega|| dt\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#main-ambiguities-of-quaternion-representation",
    "href": "lecs/w02/lec02.html#main-ambiguities-of-quaternion-representation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main ambiguities of quaternion representation",
    "text": "Main ambiguities of quaternion representation\n\nThe ones inherited from the axis-angle representation, but also:"
  },
  {
    "objectID": "lecs/w02/lec02.html#be-clear-about-your-orientation-representation.",
    "href": "lecs/w02/lec02.html#be-clear-about-your-orientation-representation.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Be clear about your orientation representation.",
    "text": "Be clear about your orientation representation."
  },
  {
    "objectID": "lecs/w02/lec02.html#suggested-minimum-documentation",
    "href": "lecs/w02/lec02.html#suggested-minimum-documentation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Suggested minimum documentation",
    "text": "Suggested minimum documentation\n\nFrame diagram\nFull description of how to build a transformation matrix from the provided scalars and down to the scalar level.\nA clear statement of which transformation matrix it is."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code.\n\nCode has the same requirements as notation\nRotation matrices have two frame decorations:\n\nto\nfrom\n\nCoordinates of vectors have three decorations:\n\nto\nfrom\nexpressed in"
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-1",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-2",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-3",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-4",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-4",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-5",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-5",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code."
  },
  {
    "objectID": "lecs/w02/lec02.html#lets-talk-about-code.-6",
    "href": "lecs/w02/lec02.html#lets-talk-about-code.-6",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Lets talk about code.",
    "text": "Lets talk about code.\nChoose an expressive coding style.\nExplain it clearly.\nStick with it."
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another",
    "href": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding quaternion that rotates one vector into another",
    "text": "Example: finding quaternion that rotates one vector into another\n\nSuppose you have a vector in frame A, and a vector in frame B\nYou want to find a quaternion that transforms \\(^A\\mathbf{v}\\) to \\(^B\\mathbf{v}\\)\nIdea: use axis-angle and convert it to quaternion\nCan rotate from \\(^A\\mathbf{v}\\) to \\(^B\\mathbf{v}\\) along an axis that is perpendicular to both of them. How do we find that?"
  },
  {
    "objectID": "lecs/w02/lec02.html#cross-product",
    "href": "lecs/w02/lec02.html#cross-product",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Cross Product",
    "text": "Cross Product\n\n\n\n\n\\[\n\\mathbf{a} \\times \\mathbf{b} = ||\\mathbf{a}|| ||\\mathbf{b}|| \\sin(\\theta) \\mathbf{n}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another-1",
    "href": "lecs/w02/lec02.html#example-finding-quaternion-that-rotates-one-vector-into-another-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Example: finding quaternion that rotates one vector into another",
    "text": "Example: finding quaternion that rotates one vector into another\n\\(\\mathbf{v}_\\text{rot axis} = ^A\\mathbf{v} \\times ^B\\mathbf{v}\\) is perpendicular to both of them\n\\(\\theta_{\\text{rot angle}} = \\text{acos}(^A\\mathbf{v} \\cdot ^B\\mathbf{v})\\)\nAssuming the two vectors are unit length"
  },
  {
    "objectID": "lecs/w02/lec02.html#rotating-a-vector-via-a-quaternion",
    "href": "lecs/w02/lec02.html#rotating-a-vector-via-a-quaternion",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Rotating a vector via a quaternion",
    "text": "Rotating a vector via a quaternion\n\nLet \\(^A\\mathbf{v}\\) be given and a quaternion \\(_A^B\\mathbf{q}\\)\nTo obtain \\(^B\\mathbf{v}\\) you have two choices:\nEither use the rotation matrix \\(^B\\mathbf{v} = _A^B\\mathbf{R(q)} ^A\\mathbf{v}\\)\nOr use quaternion multiplication directly\n\n\\[\n[^B\\mathbf{v}, 0] = _A^B\\mathbf{q} \\otimes [^A\\mathbf{v}, 0] \\otimes _B^A\\mathbf{q}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#transforming-points-from-one-frame-to-another",
    "href": "lecs/w02/lec02.html#transforming-points-from-one-frame-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Transforming points from one frame to another",
    "text": "Transforming points from one frame to another\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nSuppose you have a point in the Body frame,\\(^B\\mathbf{p}\\) which you want to transform/express in the World frame. Then you can do any of the two following options:\n\n\\[{}^W\\mathbf{p} = {}^W_B\\mathbf{R} {}^B\\mathbf{p} + {}^W\\mathbf{t}_{WB} \\qquad {}^W\\mathbf{p} = {}^W_B\\mathbf{R}({}^B\\mathbf{p} - {}^B\\mathbf{t}_{BW})\\]\n\nThink of it as first rotating the point to be in the World frame and then adding to it the translation from Body to World."
  },
  {
    "objectID": "lecs/w02/lec02.html#transforming-vectors-from-one-frame-to-another",
    "href": "lecs/w02/lec02.html#transforming-vectors-from-one-frame-to-another",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Transforming vectors from one frame to another",
    "text": "Transforming vectors from one frame to another\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nSuppose you have a vector in the Body frame, \\(^B\\mathbf{v}\\) which you want to transform/express in the World frame. Then\n\n\\[\n^W\\mathbf{v} = _B^W\\mathbf{R} ^B_\\mathbf{v}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#combining-rotations-and-translation-into-one-transformation",
    "href": "lecs/w02/lec02.html#combining-rotations-and-translation-into-one-transformation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Combining rotations and translation into one transformation",
    "text": "Combining rotations and translation into one transformation\n\n\nVERY IMPORTANT AND USEFUL\n\n\n\nMany times we combine the rotation and translation of a rigid motion into a 4x4 homogeneous matrix\n\n\\[\n_B^W\\mathbf{T} = \\begin{bmatrix}\n_B^W\\mathbf{R} & ^W\\mathbf{t}_{WB}  \\\\\n0 & 1   \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#main-advantage-of-homogeneous-transformations-easy-composition",
    "href": "lecs/w02/lec02.html#main-advantage-of-homogeneous-transformations-easy-composition",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Main advantage of homogeneous transformations: easy composition",
    "text": "Main advantage of homogeneous transformations: easy composition\n\\[\n_B^W\\mathbf{T} = _A^W\\mathbf{T} _B^A\\mathbf{T}\n\\]\nComposing rigid motions now becomes a series of matrix multiplications"
  },
  {
    "objectID": "lecs/w02/lec02.html#inverting-a-homogeneous-transformation",
    "href": "lecs/w02/lec02.html#inverting-a-homogeneous-transformation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Inverting a homogeneous transformation",
    "text": "Inverting a homogeneous transformation\n\nBe careful:\n\n\\[\n_B^W\\mathbf{T}^{-1} \\neq _A^W\\mathbf{T}^t\n\\]\nas was the case with rotation matrices."
  },
  {
    "objectID": "lecs/w02/lec02.html#physical-models-of-how-systems-move",
    "href": "lecs/w02/lec02.html#physical-models-of-how-systems-move",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Physical models of how systems move",
    "text": "Physical models of how systems move"
  },
  {
    "objectID": "lecs/w02/lec02.html#todays-agenda-2",
    "href": "lecs/w02/lec02.html#todays-agenda-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\n\nFrames of reference\nWays to represent rotations\n\n\n\nSimplified models of vehicles\nForward and inverse kinematics"
  },
  {
    "objectID": "lecs/w02/lec02.html#why-simplified",
    "href": "lecs/w02/lec02.html#why-simplified",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Why simplified?",
    "text": "Why simplified?\n\n“All models are wrong, but some are useful” – George Box (statistician)\nModel: a function that describes a physical phenomenon or a system, i.e. how a set of input variables cause a set of output variables.\nModels are useful if they can predict reality up to some degree .\nMismatch between model prediction and reality = error / noise"
  },
  {
    "objectID": "lecs/w02/lec02.html#noise",
    "href": "lecs/w02/lec02.html#noise",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Noise",
    "text": "Noise\n\nAnything that we do not bother modelling with our model\nExample 1: “assume frictionless surface”\nExample 2: Taylor series expansion (only first few terms are dominant)\nWith models, can be thought of as approximation error."
  },
  {
    "objectID": "lecs/w02/lec02.html#simplified-physical-models-of-robotic-vehicles",
    "href": "lecs/w02/lec02.html#simplified-physical-models-of-robotic-vehicles",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Simplified physical models of robotic vehicles",
    "text": "Simplified physical models of robotic vehicles\n\nOmnidirectional motion\nDubins car\nDifferential drive steering\nAckerman steering\nUnicycle\nCartpole\nQuadcopter"
  },
  {
    "objectID": "lecs/w02/lec02.html#omnidirectional-robots",
    "href": "lecs/w02/lec02.html#omnidirectional-robots",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Omnidirectional Robots",
    "text": "Omnidirectional Robots"
  },
  {
    "objectID": "lecs/w02/lec02.html#omnidirectional-robots-1",
    "href": "lecs/w02/lec02.html#omnidirectional-robots-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Omnidirectional Robots",
    "text": "Omnidirectional Robots"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#the-state-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of an omnidirectional robot",
    "text": "The state of an omnidirectional robot\nState := Configuration := \\(\\mathbf{X}\\) := vector of physical quantities of interest about the system\n\n\n\n\n\\[\n\\mathbf{X} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the robot’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame C with respect to frame G."
  },
  {
    "objectID": "lecs/w02/lec02.html#control-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#control-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Control of an omnidirectional robot",
    "text": "Control of an omnidirectional robot\nControl := \\(\\mathbf{u}\\) := a vector of input commands that can modify the state of the system\n\n\n\n\n\\[\n\\mathbf{u} = [^Cv_x, ^Cv_y, ^Cw_z]\n\\]\nControl = [Linear velocity, Angular velocity]\nLinear and angular velocity of the robot’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of frame C."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-an-omnidirectional-robot",
    "href": "lecs/w02/lec02.html#dynamics-of-an-omnidirectional-robot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of an omnidirectional robot",
    "text": "Dynamics of an omnidirectional robot\nDynamical System : = Dynamics := a function that describes the time evolution of the state in response to a control signal\n\n\n\n\nContinuous case:\n\\[\n\\begin{align}\n\\frac{dx}{dt} &= \\dot{x} = f(x, u) \\\\\n\\dot{p}_x &= v_x \\\\\n\\dot{p}_y &= v_y \\\\\n\\dot{\\theta} &= \\omega_z\n\\end{align}\n\\]\nNote: reference frames have been removed for readability."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-state-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a simple car",
    "text": "The state of a simple car\n\nState = [Position and orientation]\nPosition of the car’s frame of reference C with respect to a fixed frame of reference G, expressed in frame G.\nThe angle is the orientation of frame C with respect to G.\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-controls-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-controls-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The controls of a simple car",
    "text": "The controls of a simple car\n\nControls = [Forward speed and angular velocity]\nLinear velocity and angular velocity of the car’s frame of reference C with respect to a fixed frame of reference G, expressed in coordinates of C.\n\\[\n\\mathbf{u} = [^Cv_x, ^Cw_z]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-dynamical-system-of-a-simple-car",
    "href": "lecs/w02/lec02.html#the-dynamical-system-of-a-simple-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The dynamical system of a simple car",
    "text": "The dynamical system of a simple car\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= v_x \\cos(\\theta) \\\\\n\\dot{p}_y &= v_x \\sin(\\theta) \\\\\n\\dot{\\theta} &= \\omega_z\n\\end{align}\n\\]\nNote: reference frames have been removed for readability."
  },
  {
    "objectID": "lecs/w02/lec02.html#kinematics-vs-dynamics",
    "href": "lecs/w02/lec02.html#kinematics-vs-dynamics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Kinematics vs Dynamics",
    "text": "Kinematics vs Dynamics\n\nKinematics considers models of locomotion independently of external forces and control.\nFor example, it describes how the speed of a car affects the state without considering what the required control commands required to generate those speeds are.\nDynamics considers models of locomotion as functions of their control inputs and state."
  },
  {
    "objectID": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car",
    "href": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Special case of simple car: Dubins car",
    "text": "Special case of simple car: Dubins car\n\n\n\nCan only go forward\nConstant speed\n\n\\[\n^Cv_x = \\text{const} &gt; 0\n\\]\n\nYou only control the angular velocity"
  },
  {
    "objectID": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car-1",
    "href": "lecs/w02/lec02.html#special-case-of-simple-car-dubins-car-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Special case of simple car: Dubins car",
    "text": "Special case of simple car: Dubins car\n\n\n\nCan only go forward\nConstant speed\n\n\\[\n^Cv_x = \\text{const} &gt; 0\n\\]\n\nYou only control the angular velocity"
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-motion-primitives",
    "href": "lecs/w02/lec02.html#dubins-car-motion-primitives",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car: motion primitives",
    "text": "Dubins car: motion primitives\nThe path of the car can be decomposed to L(eft), R(ight), S(traight) segments.\n\n\n\n\nRSR path"
  },
  {
    "objectID": "lecs/w02/lec02.html#instantaneous-center-of-rotation",
    "href": "lecs/w02/lec02.html#instantaneous-center-of-rotation",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Instantaneous Center of Rotation",
    "text": "Instantaneous Center of Rotation\n\n\n\n\n\n\nIC = Instantaneous Center of Rotation\nThe center of the circle circumscribed by the turning path.\nUndefined for straight path segments."
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-boat",
    "href": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-boat",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins boat",
    "text": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins boat\n\nWhy do we care about a car that can only go forward?\nBecause we can also model idealized airplanes and boats\nDubins boat = Dubins car"
  },
  {
    "objectID": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-airplane-in-3d",
    "href": "lecs/w02/lec02.html#dubins-car-colorbluerightarrow-dubins-airplane-in-3d",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins airplane in 3D",
    "text": "Dubins car \\(\\color{blue}{\\Rightarrow}\\) Dubins airplane in 3D\n\nPitch angle \\(\\phi\\) and forward velocity determine descent rate\nYaw angle \\(\\theta\\) and forward velocity determine turning rate\n\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= v_x \\cos(\\theta) \\sin(\\phi) \\\\\n\\dot{p}_y &= v_x \\sin(\\theta) \\sin(\\phi) \\\\\n\\dot{p}_z &= v_x \\cos(\\phi) \\\\\n\\dot{\\theta} &= \\omega_z \\\\\n\\dot{\\phi} &= \\omega_y\n\\end{align}\n\\]\n\n\\(\\theta\\) is yaw\n\\(\\phi\\) is pitch"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-unicycle",
    "href": "lecs/w02/lec02.html#the-state-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a unicycle",
    "text": "The state of a unicycle\n\n\n\nTop view of a unicycle\n\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the unicycle’s frame of reference U with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame U with respect to frame G.\nQ: Would you put the radius of the unicycle to be part of the state?\n\nA: Most likely not, because it is a constant quantity that we can measure beforehand. But, if we couldn’t measure it, we need to make it part of the state in order to estimate it."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-unicycle",
    "href": "lecs/w02/lec02.html#controls-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a unicycle",
    "text": "Controls of a unicycle\n\n\n\n\n\\[\n\\mathbf{u} = [^Uw_z, ^Uw_y]\n\\]\nControls = [Yaw rate, and pedaling rate]\nYaw and pedaling rates describe the angular velocities of the respective axes of the unicycle’s frame of reference U with respect to a fixed frame of reference G, expressed in coordinates of U."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-unicycle",
    "href": "lecs/w02/lec02.html#dynamics-of-a-unicycle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a unicycle",
    "text": "Dynamics of a unicycle\n\n\n\n\n\\[\n\\begin{align}\n\\dot{p}_x &= rw_y\\cos(\\theta) \\\\\n\\dot{p}_y &= rw_y\\sin(\\theta) \\\\\n\\dot{\\theta} &= w_z \\\\\n\\end{align}\n\\]\nr = the radius of the wheel\n\\(rw_y\\) is the forward velocity of the unicycle"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#the-state-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a differential drive vehicle",
    "text": "The state of a differential drive vehicle\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x, ^Gp_y, ^G\\theta]\n\\]\nState = [Position, Orientation]\nPosition of the vehicle’s frame of reference D with respect to a fixed frame of reference G, expressed in coordinates of frame G. Angle is the orientation of frame D with respect to frame G."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#controls-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a differential drive vehicle",
    "text": "Controls of a differential drive vehicle\n\n\n\nICR = Instantaneous Center of Rotation\n\n\\[\n\\mathbf{u} = [u_l, u_r]\n\\]\nControls = [Left wheel and right wheel turning rates]\nWheel turning rates determine the linear velocities of the respective wheels of the vehicle’s frame of reference D with respect to a fixed frame of reference G, expressed in coordinates of D.\n\\[\n\\begin{align}\nv_1 &= (W - H/2)w \\\\\nv_r &= (W + H/2)w \\\\\nv_x &= (v_1 + v_r)/2\n\\end{align}\n\\]\n\\(v_1 = Ru_l\\) R is the wheel radius\n\\(v_r = Ru_r\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle",
    "href": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a differential drive vehicle",
    "text": "Dynamics of a differential drive vehicle\n\n\n\nICR = Instantaneous Center of Rotation\n\n\n\\[\n\\begin{bmatrix}\np_x(t+1) \\\\\np_y(t+1) \\\\\n\\theta(t+1)\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\cos(\\omega \\delta t) & -\\sin(\\omega \\delta t) & 0 \\\\\n\\sin(\\omega \\delta t) & \\cos(\\omega \\delta t) & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\np_x(t) - \\text{ICR}_x \\\\\np_y(t) - \\text{ICR}_y \\\\\n\\theta(t)\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\text{ICR}_x \\\\\n\\text{ICR}_y \\\\\n\\omega \\delta t\n\\end{bmatrix}\n\\]\n\n\\[\n\\text{ICR} = [p_x - W\\sin\\theta, p_y + W\\cos\\theta]\n\\]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle-1",
    "href": "lecs/w02/lec02.html#dynamics-of-a-differential-drive-vehicle-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a differential drive vehicle",
    "text": "Dynamics of a differential drive vehicle\n\n\n\n\n\n\\[\n\\begin{bmatrix}\np_x(t+1) \\\\\np_y(t+1) \\\\\n\\theta(t+1)\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\cos(\\omega \\delta t) & -\\sin(\\omega \\delta t) & 0 \\\\\n\\sin(\\omega \\delta t) & \\cos(\\omega \\delta t) & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\np_x(t) - \\text{ICR}_x \\\\\np_y(t) - \\text{ICR}_y \\\\\n\\theta(t)\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\text{ICR}_x \\\\\n\\text{ICR}_y \\\\\n\\omega \\delta t\n\\end{bmatrix}\n\\]\n\n\\[\n\\text{ICR} = [p_x - W\\sin\\theta, p_y + W\\cos\\theta]\n\\]\nSpecial cases:\n\nmoving straight \\(v_l = v_r\\)\nin-place rotation \\(v_l = -v_r\\)\nrotation about the left wheel \\(v_l = 0\\)"
  },
  {
    "objectID": "lecs/w02/lec02.html#ackerman-steering",
    "href": "lecs/w02/lec02.html#ackerman-steering",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Ackerman steering",
    "text": "Ackerman steering\n\n\nhttps://www.youtube.com/watch?v=i6uBwudwA5o"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "href": "lecs/w02/lec02.html#the-state-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a double-link inverted pendulum (a.k.a. Acrobot)",
    "text": "The state of a double-link inverted pendulum (a.k.a. Acrobot)\n\n\n\n\n\\[\n\\mathbf{x} = [\\theta_1, \\theta_2, \\dot\\theta_1, \\dot\\theta_2]\n\\]\nState = [angle of joint 1, joint 2, joint velocities]\nAngle of joint 2 is expressed with respect to joint 1. Angle of joint 1 is expressed compared to down vector."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "href": "lecs/w02/lec02.html#controls-of-a-double-link-inverted-pendulum-a.k.a.-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a double-link inverted pendulum (a.k.a. Acrobot)",
    "text": "Controls of a double-link inverted pendulum (a.k.a. Acrobot)\n\n\n\n\n\\[\n\\mathbf{u} = [\\tau_1]\n\\]\nControls = [torque applied to joint 1]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)",
    "text": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)\n\\[\n\\begin{align}\n\\ddot{\\theta}_1 &= -d_1^{-1}(d_2\\ddot{\\theta}_2 + \\phi_1) \\\\\n\\ddot{\\theta}_2 &= \\left(m_2l_{c2}^2 + I_2 - \\frac{d_2^2}{d_1}\\right)^{-1}\\left(\\tau + \\frac{d_2}{d_1}\\phi_1 - m_2gl_1l_{c2}\\dot{\\theta}_1^2\\sin\\theta_2 - \\phi_2\\right) \\\\\nd_1 &= m_1l_{c1}^2 + m_2(l_1^2 + l_{c2}^2 + 2l_1l_{c2}\\cos\\theta_2) + I_1 + I_2) \\\\\nd_2 &= m_2(l_{c2}^2 + l_1l_{c2}\\cos\\theta_2) + I_2 \\\\\n\\phi_1 &= -m_2l_1l_{c2}\\dot{\\theta}_2^2\\sin\\theta_2 - 2m_2l_1l_{c2}\\dot{\\theta}_2\\dot{\\theta}_1\\sin\\theta_2\n+ (m_1l_{c1} + m_2l_1)g\\cos(\\theta_1 - \\pi/2) + \\phi_2 \\\\\n\\phi_2 &= m_2l_{c2}g\\cos(\\theta_1 + \\theta_2 - \\pi/2)\n\\end{align}\n\\]\n\nProvided here just for reference and completeness. You are not expected to know this."
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot-1",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-link-inverted-pendulum-a.k.a-acrobot-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)",
    "text": "Dynamics of a double-link inverted pendulum (a.k.a Acrobot)"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-single-link-cartpole",
    "href": "lecs/w02/lec02.html#the-state-of-a-single-link-cartpole",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a single-link cartpole",
    "text": "The state of a single-link cartpole\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x, ^G{\\dot p_x}, ^G\\theta, ^G\\dot\\theta]\n\\]\nState = [Position and velocity of cart, orientation and angular velocity of pole]"
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-single-link-cartpole",
    "href": "lecs/w02/lec02.html#controls-of-a-single-link-cartpole",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a single-link cartpole",
    "text": "Controls of a single-link cartpole\n\n\n\n\n\\[\n\\mathbf{u} = [f]\n\\]\nControls = [Horizontal force applied to cart]"
  },
  {
    "objectID": "lecs/w02/lec02.html#balancing-a-triple-link-pendulum-on-a-cart",
    "href": "lecs/w02/lec02.html#balancing-a-triple-link-pendulum-on-a-cart",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Balancing a triple-link pendulum on a cart",
    "text": "Balancing a triple-link pendulum on a cart"
  },
  {
    "objectID": "lecs/w02/lec02.html#extreme-balancing",
    "href": "lecs/w02/lec02.html#extreme-balancing",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Extreme Balancing",
    "text": "Extreme Balancing"
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#the-state-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a double integrator",
    "text": "The state of a double integrator\n\n\n\n\n\\[\n\\mathbf{x} = [^Gp_x]\n\\]\nState = [Position along x-axis]"
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#controls-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a double integrator",
    "text": "Controls of a double integrator\n\n\n\n\n\\[\n\\mathbf{x} = [^Gu_x]\n\\]\nControls = [Force along x-axis]"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-double-integrator",
    "href": "lecs/w02/lec02.html#dynamics-of-a-double-integrator",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a double integrator",
    "text": "Dynamics of a double integrator\n\n\n\n\n\\[\n\\ddot x = F\n\\] This corresponds to applying force to a brick of mass 1 to move on frictionless ice. Where is the brick going to end up? Similar to curling."
  },
  {
    "objectID": "lecs/w02/lec02.html#the-state-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#the-state-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "The state of a quadrotor",
    "text": "The state of a quadrotor\n\n\n\n\n\n\\[\n\\mathbf{x} = [^G\\phi, ^G\\theta, ^G\\psi, ^G\\dot\\phi, ^G\\dot\\theta, ^G\\dot\\psi]\n\\]\nState = [Roll, pitch, yaw, and roll rate, pitch rate, roll rate]\nAngles are with respect to the global frame."
  },
  {
    "objectID": "lecs/w02/lec02.html#controls-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#controls-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controls of a quadrotor",
    "text": "Controls of a quadrotor\n\n\n\n\n\\[\n\\mathbf{u} = [T_1, T_2, T_3, T_4]\n\\]\nControls = [Thrusts of four motors]\nOR \\[\n\\mathbf{u} = [M_1, M_2, M_3, M_4]\n\\]\nControls = [Torques of four motors]\nNotice how adjacent motors spin in opposite ways. Why?"
  },
  {
    "objectID": "lecs/w02/lec02.html#what-if-all-four-motors-spin-the-same-direction",
    "href": "lecs/w02/lec02.html#what-if-all-four-motors-spin-the-same-direction",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "What if all four motors spin the same direction?",
    "text": "What if all four motors spin the same direction?"
  },
  {
    "objectID": "lecs/w02/lec02.html#dynamics-of-a-quadrotor",
    "href": "lecs/w02/lec02.html#dynamics-of-a-quadrotor",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Dynamics of a quadrotor",
    "text": "Dynamics of a quadrotor"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators",
    "href": "lecs/w02/lec02.html#manipulators",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\n\n\nRobot arms, industrial robot\n\nRigid bodies(links) connected by joints\nJoints: revolute or prismatic\nDrive: electric or hydraulic\nEnd-effector (tool) mounted on a flange or plate secured to the wrist joint of robot"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-1",
    "href": "lecs/w02/lec02.html#manipulators-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-2",
    "href": "lecs/w02/lec02.html#manipulators-2",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\nMotion Control Methods\n\nPoint to point control\n\na sequence of discrete points\nspot welding, pick-and-place, loading & unloading\n\nContinuous path control\n\nfollow a prescribed path, controlled-path motion\nSpray painting, Arc welding, Gluing"
  },
  {
    "objectID": "lecs/w02/lec02.html#manipulators-3",
    "href": "lecs/w02/lec02.html#manipulators-3",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Manipulators",
    "text": "Manipulators\n\n\n\nRobot Specifications\n\nNumber of Axes\n\nMajor axes, (1-3) =&gt; Position the wrist\nMinor axes, (4-6) =&gt; Orient the tool\nRedundant, (7-n) =&gt; reaching around obstacles, avoiding undesirable configuration\n\nDegree of Freedom (DOF)\nWorkspace\nPayload (load capacity)\nPrecision v.s. Repeatability\n\n\n\n\nWhich one is more important?"
  },
  {
    "objectID": "lecs/w02/lec02.html#forward-and-inverse-kinematics",
    "href": "lecs/w02/lec02.html#forward-and-inverse-kinematics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Forward and Inverse Kinematics",
    "text": "Forward and Inverse Kinematics\n\n\nhttps://slideplayer.com/slide/4239432/"
  },
  {
    "objectID": "lecs/w02/lec02.html#controllability",
    "href": "lecs/w02/lec02.html#controllability",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Controllability",
    "text": "Controllability\n\nA system is controllable if there exist control sequences that can bring the system from any state to any other state, in finite time.\nFor example, even though cars are subject to non-holonomic constraints (can’t move sideways directly), they are controllable, They can reach sideways states by parallel parking."
  },
  {
    "objectID": "lecs/w02/lec02.html#passive-dynamics",
    "href": "lecs/w02/lec02.html#passive-dynamics",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Passive Dynamics",
    "text": "Passive Dynamics\n\nDynamics of systems that operate without drawing (a lot of) energy from a power supply.\n\n\n\n\nInteresting because biological locomotion systems are more efficient than current robotic systems."
  },
  {
    "objectID": "lecs/w02/lec02.html#passive-dynamics-1",
    "href": "lecs/w02/lec02.html#passive-dynamics-1",
    "title": "CSC477 Introduction to Mobile Robotics",
    "section": "Passive Dynamics",
    "text": "Passive Dynamics\n\nDynamics of systems that operate without drawing (a lot of) energy from a power supply.\n\n\n\n\nUsually propelled by their own weight.\nInteresting because biological locomotion systems are more efficient than current robotic systems.\n\n\n\nSteve Collins & Andy Ruina, Cornell, 2001"
  },
  {
    "objectID": "lecs/w01/notes.html",
    "href": "lecs/w01/notes.html",
    "title": "CSC477 - Fall 2024",
    "section": "",
    "text": "Missing resources\nVideo missing slides:\n\naerial package delivery\nRobot Surgery daVinci robot-assisted surgery\nORB SLAM video (can find the videos that have the exact same starting slide but content is diff https://www.youtube.com/results?search_query=ORB+-+SLAM+Ra%C3%BAl+Mur-Artal%2C+J.+M.+M.+Montiel+and+Juan+D.+Tard%C3%B3s+Universidad+Zaragoza , videos by this user : https://www.youtube.com/@raulmurartal2764 )\nBeyond the visible spectrum: infrared cameras\n (seems to look like a video thumbnail)\n : also seems to look like a video thumbnail\nnext slide after Inertial Sensors\nExample: flippers on the Aqua robot"
  }
]